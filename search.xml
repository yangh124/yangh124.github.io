<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>Docker常用命令</title>
    <url>/2021/07/31/Docker%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/</url>
    <content><![CDATA[<h1 id="Docker简介"><a href="#Docker简介" class="headerlink" title="Docker简介"></a>Docker简介</h1><pre><code>Docker是一个开源的应用容器引擎，让开发者可以打包应用及依赖包到一个可移植的镜像中，然后发布到任何流行的Linux或Windows机器上。使用Docker可以更方便地打包、测试以及部署应用程序。
</code></pre>
<span id="more"></span>

<h1 id="Docker环境安装（Linux）"><a href="#Docker环境安装（Linux）" class="headerlink" title="Docker环境安装（Linux）"></a>Docker环境安装（Linux）</h1><h2 id="1-安装yum-utils；"><a href="#1-安装yum-utils；" class="headerlink" title="1. 安装yum-utils；"></a>1. 安装yum-utils；</h2><pre><code>yum install -y yum-utils device-mapper-persistent-data lvm2
</code></pre>
<h2 id="2-为yum源添加docker仓库位置；"><a href="#2-为yum源添加docker仓库位置；" class="headerlink" title="2. 为yum源添加docker仓库位置；"></a>2. 为yum源添加docker仓库位置；</h2><pre><code>yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo
</code></pre>
<h2 id="3-安装dokcer服务；"><a href="#3-安装dokcer服务；" class="headerlink" title="3. 安装dokcer服务；"></a>3. 安装dokcer服务；</h2><pre><code>yum install docker-ce
</code></pre>
<h2 id="4-启动docker服务；"><a href="#4-启动docker服务；" class="headerlink" title="4. 启动docker服务；"></a>4. 启动docker服务；</h2><pre><code>systemctl start docker
</code></pre>
<h1 id="Docker常用镜像命令"><a href="#Docker常用镜像命令" class="headerlink" title="Docker常用镜像命令"></a>Docker常用镜像命令</h1><h2 id="搜索镜像"><a href="#搜索镜像" class="headerlink" title="搜索镜像"></a>搜索镜像</h2><pre><code>docker search xxx
</code></pre>
<h2 id="下载镜像"><a href="#下载镜像" class="headerlink" title="下载镜像"></a>下载镜像</h2><pre><code>dockr pull xxx
</code></pre>
<h2 id="查看镜像版本"><a href="#查看镜像版本" class="headerlink" title="查看镜像版本"></a>查看镜像版本</h2><pre><code>由于docker search命令只能查找出是否有该镜像，不能找到该镜像支持的版本，所以我们需要通过Docker Hub来搜索支持的版本。
进入Docker Hub的官网，地址：[https://hub.docker.com](https://hub.docker.com/)
</code></pre>
<h2 id="列出镜像"><a href="#列出镜像" class="headerlink" title="列出镜像"></a>列出镜像</h2><p>docker images</p>
<h2 id="删除镜像"><a href="#删除镜像" class="headerlink" title="删除镜像"></a>删除镜像</h2><h3 id="1-指定名称删除镜像"><a href="#1-指定名称删除镜像" class="headerlink" title="1. 指定名称删除镜像"></a>1. 指定名称删除镜像</h3><pre><code>docker rmi java:8.0
</code></pre>
<h3 id="2-指定名称强制删除镜像"><a href="#2-指定名称强制删除镜像" class="headerlink" title="2. 指定名称强制删除镜像"></a>2. 指定名称强制删除镜像</h3><pre><code>docker rmi -f java:8.0
</code></pre>
<h3 id="3-删除所有没有引用的镜像"><a href="#3-删除所有没有引用的镜像" class="headerlink" title="3. 删除所有没有引用的镜像"></a>3. 删除所有没有引用的镜像</h3><pre><code>docker rmi `docker images | grep none | awk  &#39;&#123;print $3&#125;&#39;`
</code></pre>
<h3 id="4-强制删除所有镜像"><a href="#4-强制删除所有镜像" class="headerlink" title="4. 强制删除所有镜像"></a>4. 强制删除所有镜像</h3><pre><code>docker rmi -f $(docker images)
</code></pre>
<h2 id="构建镜像"><a href="#构建镜像" class="headerlink" title="构建镜像"></a>构建镜像</h2><pre><code>-t 表示指定镜像仓库名称/镜像名称:镜像标签 .表示使用当前目录下的Dockerfile文件 
docker build -t yh124/test-porject:1.0-SNAPSHOT .
</code></pre>
<h1 id="Docker容器常用命令"><a href="#Docker容器常用命令" class="headerlink" title="Docker容器常用命令"></a>Docker容器常用命令</h1><h2 id="新建并启动容器"><a href="#新建并启动容器" class="headerlink" title="新建并启动容器"></a>新建并启动容器</h2><pre><code>docker run -p 80:80 --name nginx \ -e TZ=&quot;Asia/Shanghai&quot; \ -v /mydata/nginx/html:/usr/share/nginx/html \ -d nginx:1.17.0

1. -p：将宿主机和容器端口进行映射，格式为：宿主机端口:容器端口。
2. --name：自定义容器名称，之后可以通过容器名称进行操作。
3. -e：设置容器的环境变量，这里设置的时区。
4. -v：将宿主机的文件挂载到容器中，格式为：宿主机文件目录:容器文件目录。
5. -d：表示容器以后台方式运行
</code></pre>
<h2 id="列出容器"><a href="#列出容器" class="headerlink" title="列出容器"></a>列出容器</h2><h3 id="1-列出运行中的所有容器"><a href="#1-列出运行中的所有容器" class="headerlink" title="1. 列出运行中的所有容器"></a>1. 列出运行中的所有容器</h3><pre><code>docker ps
</code></pre>
<h3 id="2-列出所有容器"><a href="#2-列出所有容器" class="headerlink" title="2. 列出所有容器"></a>2. 列出所有容器</h3><pre><code>docker ps -a
</code></pre>
<h2 id="停止容器"><a href="#停止容器" class="headerlink" title="停止容器"></a>停止容器</h2><pre><code>docker stop \$containerName(or \$containerID)
</code></pre>
<h2 id="强制停止容器"><a href="#强制停止容器" class="headerlink" title="强制停止容器"></a>强制停止容器</h2><pre><code>docker kill xxx
</code></pre>
<h2 id="启动容器"><a href="#启动容器" class="headerlink" title="启动容器"></a>启动容器</h2><pre><code>docker start xxx
</code></pre>
<h2 id="进入容器"><a href="#进入容器" class="headerlink" title="进入容器"></a>进入容器</h2><h3 id="1-先查出容器pid"><a href="#1-先查出容器pid" class="headerlink" title="1. 先查出容器pid"></a>1. 先查出容器pid</h3><pre><code>docker inspect --format &quot;&#123;&#123;.State.Pid&#125;&#125;&quot; $ContainerName
</code></pre>
<h3 id="2-根据容器pid进入容器"><a href="#2-根据容器pid进入容器" class="headerlink" title="2. 根据容器pid进入容器"></a>2. 根据容器pid进入容器</h3><pre><code>nsenter --target &quot;$pid&quot; --mount --uts --ipc --net --pid
</code></pre>
<h2 id="删除容器"><a href="#删除容器" class="headerlink" title="删除容器"></a>删除容器</h2><h3 id="1-删除指定容器"><a href="#1-删除指定容器" class="headerlink" title="1. 删除指定容器"></a>1. 删除指定容器</h3><pre><code>docker rm $ContainerName
</code></pre>
<h3 id="2-按名称通配符删除容器，比如删除以名称test-开头的容器"><a href="#2-按名称通配符删除容器，比如删除以名称test-开头的容器" class="headerlink" title="2. 按名称通配符删除容器，比如删除以名称test-开头的容器"></a>2. 按名称通配符删除容器，比如删除以名称test-开头的容器</h3><pre><code>docker rm &#39;docker ps -a | grep test-* | awk &#123;print $1&#125;&#39;
</code></pre>
<h3 id="3-强制删除所有容器"><a href="#3-强制删除所有容器" class="headerlink" title="3. 强制删除所有容器"></a>3. 强制删除所有容器</h3><pre><code>docker rm -f $(docker ps -a -q)
</code></pre>
<h2 id="查看容器日志"><a href="#查看容器日志" class="headerlink" title="查看容器日志"></a>查看容器日志</h2><h3 id="1-查看容器产生的全部日志"><a href="#1-查看容器产生的全部日志" class="headerlink" title="1. 查看容器产生的全部日志"></a>1. 查看容器产生的全部日志</h3><pre><code>docker logs $ContainerName
</code></pre>
<h3 id="2-动态查看日志"><a href="#2-动态查看日志" class="headerlink" title="2. 动态查看日志"></a>2. 动态查看日志</h3><pre><code>docker logs -f -t --tail=100 $ContainerName
</code></pre>
<h2 id="查看容器的IP地址"><a href="#查看容器的IP地址" class="headerlink" title="查看容器的IP地址"></a>查看容器的IP地址</h2><pre><code>docker inspect --format &#39;&#123;&#123;.NetworkSettings.IPAddress&#125;&#125;&#39; $ContainerName
</code></pre>
<h2 id="修改容器的启动方式"><a href="#修改容器的启动方式" class="headerlink" title="修改容器的启动方式"></a>修改容器的启动方式</h2><h3 id="1-将容器启动方式改为always"><a href="#1-将容器启动方式改为always" class="headerlink" title="1. 将容器启动方式改为always"></a>1. 将容器启动方式改为always</h3><pre><code>    docker container update --restart=always $ContainerName 
</code></pre>
<h3 id="2-关闭自动重启"><a href="#2-关闭自动重启" class="headerlink" title="2. 关闭自动重启"></a>2. 关闭自动重启</h3><pre><code>    docker container update --restart=no $ContainerName
</code></pre>
<h2 id="同步宿主机时间到容器"><a href="#同步宿主机时间到容器" class="headerlink" title="同步宿主机时间到容器"></a>同步宿主机时间到容器</h2><pre><code>docker cp /etc/localtime $ContainerName:/etc
</code></pre>
<h2 id="指定容器时区"><a href="#指定容器时区" class="headerlink" title="指定容器时区"></a>指定容器时区</h2><pre><code>docker run -p 80:80 --name nginx \ -e TZ=&quot;Asia/Shanghai&quot; \ -d nginx:1.17.0
</code></pre>
<h2 id="查看容器资源占用状况"><a href="#查看容器资源占用状况" class="headerlink" title="查看容器资源占用状况"></a>查看容器资源占用状况</h2><h3 id="1-查看指定容器资源占用状况，比如cpu，网络，内存，IO状态"><a href="#1-查看指定容器资源占用状况，比如cpu，网络，内存，IO状态" class="headerlink" title="1. 查看指定容器资源占用状况，比如cpu，网络，内存，IO状态"></a>1. 查看指定容器资源占用状况，比如cpu，网络，内存，IO状态</h3><pre><code>docker stats $ContainerName
</code></pre>
<h3 id="2-查看所有容器医院占用情况"><a href="#2-查看所有容器医院占用情况" class="headerlink" title="2. 查看所有容器医院占用情况"></a>2. 查看所有容器医院占用情况</h3><pre><code>docker stats -a
</code></pre>
<h2 id="查看磁盘使用情况"><a href="#查看磁盘使用情况" class="headerlink" title="查看磁盘使用情况"></a>查看磁盘使用情况</h2><pre><code>docker system df
</code></pre>
<h2 id="执行容器内部命令（进入容器）"><a href="#执行容器内部命令（进入容器）" class="headerlink" title="执行容器内部命令（进入容器）"></a>执行容器内部命令（进入容器）</h2><pre><code>docker exec -it $ContainerName /bin/bash
</code></pre>
<h2 id="指定账号进入容器内部"><a href="#指定账号进入容器内部" class="headerlink" title="指定账号进入容器内部"></a>指定账号进入容器内部</h2><pre><code>使用root账号进入容器内部 
docker exec -it --user root $ContainerName /bin/bash
</code></pre>
<h2 id="查看所有网络"><a href="#查看所有网络" class="headerlink" title="查看所有网络"></a>查看所有网络</h2><pre><code>docker network ls
</code></pre>
<h2 id="创建外部网络"><a href="#创建外部网络" class="headerlink" title="创建外部网络"></a>创建外部网络</h2><pre><code>docker network create -d bridge my-bridge-network
</code></pre>
<h2 id="指定容器网络"><a href="#指定容器网络" class="headerlink" title="指定容器网络"></a>指定容器网络</h2><pre><code>docker run -p 80:80 --name nginx \ --network my-bridge-network \ -d nginx:1.17.0
</code></pre>
<h2 id="修改镜像的存放位置"><a href="#修改镜像的存放位置" class="headerlink" title="修改镜像的存放位置"></a>修改镜像的存放位置</h2><h3 id="1-查看镜像的存放位置"><a href="#1-查看镜像的存放位置" class="headerlink" title="1. 查看镜像的存放位置"></a>1. 查看镜像的存放位置</h3><pre><code>docker info | grep &quot;Docker Root Dir&quot;
</code></pre>
<h3 id="2-关闭docker-服务"><a href="#2-关闭docker-服务" class="headerlink" title="2. 关闭docker 服务"></a>2. 关闭docker 服务</h3><pre><code>systemctl stop docker
</code></pre>
<h3 id="3-先将原镜像目录移动到目标目录"><a href="#3-先将原镜像目录移动到目标目录" class="headerlink" title="3. 先将原镜像目录移动到目标目录"></a>3. 先将原镜像目录移动到目标目录</h3><pre><code>mv /var/lib/docker /mydata/docker
</code></pre>
<h3 id="4-建立软连接"><a href="#4-建立软连接" class="headerlink" title="4. 建立软连接"></a>4. 建立软连接</h3><pre><code>ln -s /mydata/docker /var/lib/docker
</code></pre>
<h2 id="Docker容器清理"><a href="#Docker容器清理" class="headerlink" title="Docker容器清理"></a>Docker容器清理</h2><h3 id="1-查看Docker占用磁盘空间"><a href="#1-查看Docker占用磁盘空间" class="headerlink" title="1. 查看Docker占用磁盘空间"></a>1. 查看Docker占用磁盘空间</h3><pre><code>docker system df
</code></pre>
<h3 id="2-删除所有关闭的容器"><a href="#2-删除所有关闭的容器" class="headerlink" title="2. 删除所有关闭的容器"></a>2. 删除所有关闭的容器</h3><pre><code>docker ps -a | grep Exit | cut -d &#39; &#39; -f 1 | xargs docker rm
</code></pre>
<h3 id="3-删除所有dangling镜像（没有Tag的镜像）"><a href="#3-删除所有dangling镜像（没有Tag的镜像）" class="headerlink" title="3. 删除所有dangling镜像（没有Tag的镜像）"></a>3. 删除所有dangling镜像（没有Tag的镜像）</h3><pre><code>docker rmi $(docker images | grep &quot;^&lt;none&gt;&quot; | awk &quot;&#123;print $3&#125;&quot;)
</code></pre>
<h3 id="4-删除所有dangling-数据卷（即无用的volume）"><a href="#4-删除所有dangling-数据卷（即无用的volume）" class="headerlink" title="4. 删除所有dangling 数据卷（即无用的volume）"></a>4. 删除所有dangling 数据卷（即无用的volume）</h3><pre><code>docker volume rm $(docker volume ls -qf dangling=true)
</code></pre>
<h1 id="Docker-Compose"><a href="#Docker-Compose" class="headerlink" title="Docker Compose"></a>Docker Compose</h1><h2 id="常用命令"><a href="#常用命令" class="headerlink" title="常用命令"></a>常用命令</h2><h3 id="构建、创建、启动相关容器"><a href="#构建、创建、启动相关容器" class="headerlink" title="构建、创建、启动相关容器"></a>构建、创建、启动相关容器</h3><pre><code>docker-compose up -d #指定yaml文件 -f 指定文件(file) -d 后台运行 docker-compose -f docker-compose.yml up -d
</code></pre>
<h3 id="停止所有相关容器"><a href="#停止所有相关容器" class="headerlink" title="停止所有相关容器"></a>停止所有相关容器</h3><pre><code>docker-compose stop
</code></pre>
<h3 id="列出所有容器信息"><a href="#列出所有容器信息" class="headerlink" title="列出所有容器信息"></a>列出所有容器信息</h3><pre><code>docker-compose ps
</code></pre>
]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title>Dubbo</title>
    <url>/2021/08/03/Dubbo/</url>
    <content><![CDATA[<h1 id="基础知识"><a href="#基础知识" class="headerlink" title="基础知识"></a>基础知识</h1><h2 id="分布式基础理论"><a href="#分布式基础理论" class="headerlink" title="分布式基础理论"></a>分布式基础理论</h2><h3 id="什么是分布式系统"><a href="#什么是分布式系统" class="headerlink" title="什么是分布式系统"></a>什么是分布式系统</h3><p>《分布式系统原理和与范例》定义：分布式系统是若干个独立计算机的集合，这些计算机对于用户来说就像单个相关系统。分布式系统（distributed system）是建立在网络之上的软件系统。</p>
<p>随着互联网的发展，网络应用的规模不断扩大，常规的垂直架构已无法应对，分布式服务架构以及流动计算机架构势在必行，急需一个治理系统确保架构有条不紊的演进。</p>
<h3 id="发展演变"><a href="#发展演变" class="headerlink" title="发展演变"></a>发展演变</h3><p><img src="https://yh-blog-files.oss-cn-hangzhou.aliyuncs.com/2021/08/03/16279957380049.jpg"></p>
<h3 id="RPC"><a href="#RPC" class="headerlink" title="RPC"></a>RPC</h3><h4 id="什么是RPC"><a href="#什么是RPC" class="headerlink" title="什么是RPC"></a>什么是RPC</h4><p>RPC（remote procedure call）是指远程过程调用，是一种进程间通信方式，它是一种技术的思想，而不是规范。它允许程序调用另一个地址空间（通常是共享网络的另一台机器上）的过程或函数，而不用显示的编码这个远程调用的细节。即程序员无论是调用本地的还是远程的函数，本质上编写的代码基本相同。<br><img src="https://yh-blog-files.oss-cn-hangzhou.aliyuncs.com/2021/08/03/16279967265162.jpg"></p>
<p>一次完整的RPC调用流程（同步调用，异步另说）如下：<br>    1. 服务消费者（client）调用以本地调用方式调用服务；<br>    2. client stub接收到调用后负责将方法、参数等组装成能够进行网络传输的消息体；<br>    3. client stub找到消息服务地址，并将消息发送到服务端；<br>    4. server stub找到消息后进行解码；<br>    5. server stub根据解码结果调用本地服务；<br>    6. 本地服务执行并将结果返回给server stub；<br>    7. server stub将返回结果打包成消息并发送至消费方；<br>    8. client stub接收消息，并进行解码；<br>    9. 服务消费方得到最终结果。<br>RPC框架的目的就是将2～8这些步骤都封装起来，这些细节对用户来说是不可见的。</p>
<h2 id="netty通信原理"><a href="#netty通信原理" class="headerlink" title="netty通信原理"></a>netty通信原理</h2><p>Netty是一个异步事件驱动的网络应用程序框架。用于快速开发可维护的高性能协议服务器和客户端。它极大的简化了TCP和UDP套接字服务器等网络编程。</p>
<ul>
<li>BIO<br>  <img src="https://yh-blog-files.oss-cn-hangzhou.aliyuncs.com/2021/08/11/16286904434850.jpg"></li>
<li>NIO（Non-Blocking IO）<br><img src="https://yh-blog-files.oss-cn-hangzhou.aliyuncs.com/2021/08/11/16286910957505.jpg" alt="16286910957505"><br>  Selector一般称为选择器，也可以翻译为多路复用器；<br>  Connect（连接就绪）、Accept（接受就绪）、Read（读就绪）、Write（写就绪）<h2 id="Netty基本原理"><a href="#Netty基本原理" class="headerlink" title="Netty基本原理"></a>Netty基本原理</h2><h2 id="Dubbo原理"><a href="#Dubbo原理" class="headerlink" title="Dubbo原理"></a>Dubbo原理</h2><h3 id="框架设计"><a href="#框架设计" class="headerlink" title="框架设计"></a>框架设计</h3><img src="https://yh-blog-files.oss-cn-hangzhou.aliyuncs.com/2021/08/16/16291190919038.jpg" alt="16291190919038"><h3 id="启动解析、加载配置"><a href="#启动解析、加载配置" class="headerlink" title="启动解析、加载配置"></a>启动解析、加载配置</h3><h3 id="服务暴露"><a href="#服务暴露" class="headerlink" title="服务暴露"></a>服务暴露</h3><h3 id="服务引用"><a href="#服务引用" class="headerlink" title="服务引用"></a>服务引用</h3><h3 id="服务调用"><a href="#服务调用" class="headerlink" title="服务调用"></a>服务调用</h3></li>
</ul>
]]></content>
      <categories>
        <category>后端</category>
      </categories>
      <tags>
        <tag>微服务</tag>
      </tags>
  </entry>
  <entry>
    <title>ElasticSearch</title>
    <url>/2021/08/31/ElasticSearch/</url>
    <content><![CDATA[<h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p>Elasticsearch是一个基于Lucene的搜索服务器，他提供了一个分布式全文搜索引擎，基于restful web接口。</p>
<p>Elasticsearch是用Java语言开发的，基于Apache协议的开源项目，是目前最受欢迎的企业搜索引擎。Elasticsearch广泛运用于云计算中，能够达到实时搜索，具有稳定，可靠，快速的特点。</p>
<span id="more"></span>
<h1 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h1><p>Elasticsearch，Kibana，IKAnalyzer中文分词器。版本要一致</p>
<h1 id="相关概念"><a href="#相关概念" class="headerlink" title="相关概念"></a>相关概念</h1><ol>
<li>Never Realation（近实时）：Elasticsearch是一个近乎实时的搜索平台，这意味着从索引文档到可搜索文档之间只有轻微的延迟（通常是一秒钟）。</li>
<li>Cluster（集群）：集群是一个或多个节点的集合，它们一起保存整个数据，并提供所有节点的联合索引和搜索功能。每个集群都有自己的唯一集群名称，节点通过名称加入集群。</li>
<li>Node（节点）：节点是指属于集群的单个Elasticsearch实例，存储数据并参与集群的索引的搜索功能。可以将节点配置为按集群名称加入特定集群，默认情况下，每个节点都设置为加入一个名为elasticsearch的集群。</li>
<li><strong>Index（索引）</strong>：索引是一些具有相似特征的文档集合，类似于Mysql中数据库的概念。</li>
<li><strong>Type（类型）</strong>：类型是索引的逻辑类别分区，通常，为具有一组公共字段的文档类型，类似Mysql中表的概念。（在ES6及之后的版本，一个索引只能包含一个类型，ES7中标记为过时的，ES8中将移除Type）。</li>
<li><strong>Document（文档）</strong>：文档是可被搜索的基本信息单位，以JSON格式表示，类似于Mysql中的行。</li>
<li>Shards（分片）：当索引存储大量数据时，可能会超出当个节点的硬件设置，为了解决这个问题，ES提供了将索引细分为分片的概念。分片机制赋予了索引水平扩容的能力、并允许跨分片分发和并行化操作，从而提高性能和吞吐量。</li>
<li>Replicas（副本）：在可能出现故障的网络的环境中，需要有一个故障切换机制，ES提供了将索引的分片复制为一个或多个副本的功能，副本在某些节点失效的情况下提供高可用性。</li>
</ol>
<h1 id="集群状态查看"><a href="#集群状态查看" class="headerlink" title="集群状态查看"></a>集群状态查看</h1><ol>
<li><p>查看集群健康状态</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">GET /_cat/health?v</span><br></pre></td></tr></table></figure></li>
<li><p>查看节点状态</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">GET /_cat/nodes?v</span><br></pre></td></tr></table></figure></li>
<li><p>查看所有索引信息</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">GET /_cat/indices?v</span><br></pre></td></tr></table></figure>
<h1 id="索引操作"><a href="#索引操作" class="headerlink" title="索引操作"></a>索引操作</h1></li>
<li><p>创建索引并查看</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">PUT /customer GET /_cat/indices?v</span><br></pre></td></tr></table></figure></li>
<li><p>删除索引</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">DELETE /customer</span><br></pre></td></tr></table></figure>
<h1 id="类型操作"><a href="#类型操作" class="headerlink" title="类型操作"></a>类型操作</h1></li>
</ol>
<ul>
<li>查看文档的类型<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">GET /bank/_mapping</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  &quot;bank&quot;: &#123;</span><br><span class="line">    &quot;mappings&quot;: &#123;</span><br><span class="line">      &quot;account&quot;: &#123;</span><br><span class="line">        &quot;properties&quot;: &#123;</span><br><span class="line">          &quot;account_number&quot;: &#123;</span><br><span class="line">            &quot;type&quot;: &quot;long&quot;</span><br><span class="line">          &#125;,</span><br><span class="line">          &quot;address&quot;: &#123;</span><br><span class="line">            &quot;type&quot;: &quot;text&quot;,</span><br><span class="line">            &quot;fields&quot;: &#123;</span><br><span class="line">              &quot;keyword&quot;: &#123;</span><br><span class="line">                &quot;type&quot;: &quot;keyword&quot;,</span><br><span class="line">                &quot;ignore_above&quot;: 256</span><br><span class="line">              &#125;</span><br><span class="line">            &#125;</span><br><span class="line">          &#125;,</span><br><span class="line">          &quot;age&quot;: &#123;</span><br><span class="line">            &quot;type&quot;: &quot;long&quot;</span><br><span class="line">          &#125;,</span><br><span class="line">          &quot;balance&quot;: &#123;</span><br><span class="line">            &quot;type&quot;: &quot;long&quot;</span><br><span class="line">          &#125;,</span><br><span class="line">          &quot;city&quot;: &#123;</span><br><span class="line">            &quot;type&quot;: &quot;text&quot;,</span><br><span class="line">            &quot;fields&quot;: &#123;</span><br><span class="line">              &quot;keyword&quot;: &#123;</span><br><span class="line">                &quot;type&quot;: &quot;keyword&quot;,</span><br><span class="line">                &quot;ignore_above&quot;: 256</span><br><span class="line">              &#125;</span><br><span class="line">            &#125;</span><br><span class="line">          &#125;,</span><br><span class="line">          &quot;email&quot;: &#123;</span><br><span class="line">            &quot;type&quot;: &quot;text&quot;,</span><br><span class="line">            &quot;fields&quot;: &#123;</span><br><span class="line">              &quot;keyword&quot;: &#123;</span><br><span class="line">                &quot;type&quot;: &quot;keyword&quot;,</span><br><span class="line">                &quot;ignore_above&quot;: 256</span><br><span class="line">              &#125;</span><br><span class="line">            &#125;</span><br><span class="line">          &#125;,</span><br><span class="line">          &quot;employer&quot;: &#123;</span><br><span class="line">            &quot;type&quot;: &quot;text&quot;,</span><br><span class="line">            &quot;fields&quot;: &#123;</span><br><span class="line">              &quot;keyword&quot;: &#123;</span><br><span class="line">                &quot;type&quot;: &quot;keyword&quot;,</span><br><span class="line">                &quot;ignore_above&quot;: 256</span><br><span class="line">              &#125;</span><br><span class="line">            &#125;</span><br><span class="line">          &#125;,</span><br><span class="line">          &quot;firstname&quot;: &#123;</span><br><span class="line">            &quot;type&quot;: &quot;text&quot;,</span><br><span class="line">            &quot;fields&quot;: &#123;</span><br><span class="line">              &quot;keyword&quot;: &#123;</span><br><span class="line">                &quot;type&quot;: &quot;keyword&quot;,</span><br><span class="line">                &quot;ignore_above&quot;: 256</span><br><span class="line">              &#125;</span><br><span class="line">            &#125;</span><br><span class="line">          &#125;,</span><br><span class="line">          &quot;gender&quot;: &#123;</span><br><span class="line">            &quot;type&quot;: &quot;text&quot;,</span><br><span class="line">            &quot;fields&quot;: &#123;</span><br><span class="line">              &quot;keyword&quot;: &#123;</span><br><span class="line">                &quot;type&quot;: &quot;keyword&quot;,</span><br><span class="line">                &quot;ignore_above&quot;: 256</span><br><span class="line">              &#125;</span><br><span class="line">            &#125;</span><br><span class="line">          &#125;,</span><br><span class="line">          &quot;lastname&quot;: &#123;</span><br><span class="line">            &quot;type&quot;: &quot;text&quot;,</span><br><span class="line">            &quot;fields&quot;: &#123;</span><br><span class="line">              &quot;keyword&quot;: &#123;</span><br><span class="line">                &quot;type&quot;: &quot;keyword&quot;,</span><br><span class="line">                &quot;ignore_above&quot;: 256</span><br><span class="line">              &#125;</span><br><span class="line">            &#125;</span><br><span class="line">          &#125;,</span><br><span class="line">          &quot;state&quot;: &#123;</span><br><span class="line">            &quot;type&quot;: &quot;text&quot;,</span><br><span class="line">            &quot;fields&quot;: &#123;</span><br><span class="line">              &quot;keyword&quot;: &#123;</span><br><span class="line">                &quot;type&quot;: &quot;keyword&quot;,</span><br><span class="line">                &quot;ignore_above&quot;: 256</span><br><span class="line">              &#125;</span><br><span class="line">            &#125;</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h1 id="文档操作"><a href="#文档操作" class="headerlink" title="文档操作"></a>文档操作</h1></li>
</ul>
<ol start="2">
<li>在索引中添加文档<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">PUT /customer/doc/1GET</span><br><span class="line">&#123;</span><br><span class="line">    &quot;name&quot;:&quot;yanghao&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  &quot;_index&quot;: &quot;customer&quot;,</span><br><span class="line">  &quot;_type&quot;: &quot;doc&quot;,</span><br><span class="line">  &quot;_id&quot;: &quot;1&quot;,</span><br><span class="line">  &quot;_version&quot;: 1,</span><br><span class="line">  &quot;result&quot;: &quot;created&quot;,</span><br><span class="line">  &quot;_shards&quot;: &#123;</span><br><span class="line">    &quot;total&quot;: 2,</span><br><span class="line">    &quot;successful&quot;: 1,</span><br><span class="line">    &quot;failed&quot;: 0</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;_seq_no&quot;: 3,</span><br><span class="line">  &quot;_primary_term&quot;: 1</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li>查看索引中的文档<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">GET /customer/doc/1</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  &quot;_index&quot;: &quot;customer&quot;,</span><br><span class="line">  &quot;_type&quot;: &quot;doc&quot;,</span><br><span class="line">  &quot;_id&quot;: &quot;1&quot;,</span><br><span class="line">  &quot;_version&quot;: 2,</span><br><span class="line">  &quot;found&quot;: true,</span><br><span class="line">  &quot;_source&quot;: &#123;</span><br><span class="line">    &quot;name&quot;: &quot;yanghao&quot;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li>修改索引中的文档<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">POST /customer/doc/1/_update</span><br><span class="line">&#123;</span><br><span class="line">    &quot;doc&quot;:&#123;&quot;name&quot;:&quot;yanghao dashuaige&quot;&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  &quot;_index&quot;: &quot;customer&quot;,</span><br><span class="line">  &quot;_type&quot;: &quot;doc&quot;,</span><br><span class="line">  &quot;_id&quot;: &quot;1&quot;,</span><br><span class="line">  &quot;_version&quot;: 2,</span><br><span class="line">  &quot;result&quot;: &quot;updated&quot;,</span><br><span class="line">  &quot;_shards&quot;: &#123;</span><br><span class="line">    &quot;total&quot;: 2,</span><br><span class="line">    &quot;successful&quot;: 1,</span><br><span class="line">    &quot;failed&quot;: 0</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;_seq_no&quot;: 4,</span><br><span class="line">  &quot;_primary_term&quot;: 1</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li>删除索引中的文档<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">DELETE /customer/doc/1</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  &quot;_index&quot;: &quot;customer&quot;,</span><br><span class="line">  &quot;_type&quot;: &quot;doc&quot;,</span><br><span class="line">  &quot;_id&quot;: &quot;1&quot;,</span><br><span class="line">  &quot;_version&quot;: 3,</span><br><span class="line">  &quot;result&quot;: &quot;deleted&quot;,</span><br><span class="line">  &quot;_shards&quot;: &#123;</span><br><span class="line">    &quot;total&quot;: 2,</span><br><span class="line">    &quot;successful&quot;: 1,</span><br><span class="line">    &quot;failed&quot;: 0</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;_seq_no&quot;: 2,</span><br><span class="line">  &quot;_primary_term&quot;: 1</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li>对索引中的文档执行批量操作<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">POST /customer/doc/_bulk</span><br><span class="line">&#123;&quot;index&quot;:&#123;&quot;_id&quot;:&quot;1&quot;&#125;&#125;</span><br><span class="line">&#123;&quot;name&quot;:&quot;xiaohong&quot;&#125;</span><br><span class="line">&#123;&quot;index&quot;:&#123;&quot;_id&quot;:&quot;2&quot;&#125;&#125;</span><br><span class="line">&#123;&quot;name&quot;:&quot;xiaoming&quot;&#125;</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  &quot;took&quot;: 45,</span><br><span class="line">  &quot;errors&quot;: false,</span><br><span class="line">  &quot;items&quot;: [</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;index&quot;: &#123;</span><br><span class="line">        &quot;_index&quot;: &quot;customer&quot;,</span><br><span class="line">        &quot;_type&quot;: &quot;doc&quot;,</span><br><span class="line">        &quot;_id&quot;: &quot;1&quot;,</span><br><span class="line">        &quot;_version&quot;: 3,</span><br><span class="line">        &quot;result&quot;: &quot;updated&quot;,</span><br><span class="line">        &quot;_shards&quot;: &#123;</span><br><span class="line">          &quot;total&quot;: 2,</span><br><span class="line">          &quot;successful&quot;: 1,</span><br><span class="line">          &quot;failed&quot;: 0</span><br><span class="line">        &#125;,</span><br><span class="line">        &quot;_seq_no&quot;: 5,</span><br><span class="line">        &quot;_primary_term&quot;: 1,</span><br><span class="line">        &quot;status&quot;: 200</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;index&quot;: &#123;</span><br><span class="line">        &quot;_index&quot;: &quot;customer&quot;,</span><br><span class="line">        &quot;_type&quot;: &quot;doc&quot;,</span><br><span class="line">        &quot;_id&quot;: &quot;2&quot;,</span><br><span class="line">        &quot;_version&quot;: 1,</span><br><span class="line">        &quot;result&quot;: &quot;created&quot;,</span><br><span class="line">        &quot;_shards&quot;: &#123;</span><br><span class="line">          &quot;total&quot;: 2,</span><br><span class="line">          &quot;successful&quot;: 1,</span><br><span class="line">          &quot;failed&quot;: 0</span><br><span class="line">        &#125;,</span><br><span class="line">        &quot;_seq_no&quot;: 0,</span><br><span class="line">        &quot;_primary_term&quot;: 1,</span><br><span class="line">        &quot;status&quot;: 201</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h1 id="数据搜索"><a href="#数据搜索" class="headerlink" title="数据搜索"></a>数据搜索</h1></li>
</ol>
<p>查询表达式（Query DSL）是一种非常灵活又富有表现力的查询语言，ES使用它可以以简单的JSON接口来实现丰富的搜索功能。</p>
<h2 id="数据准备"><a href="#数据准备" class="headerlink" title="数据准备"></a>数据准备</h2><ol>
<li>首先导入测试数据，数据结构如下&#x2F;<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    &quot;account_number&quot;: 0,</span><br><span class="line">    &quot;balance&quot;: 16623,</span><br><span class="line">    &quot;firstname&quot;: &quot;Bradshaw&quot;,</span><br><span class="line">    &quot;lastname&quot;: &quot;Mckenzie&quot;,</span><br><span class="line">    &quot;age&quot;: 29,</span><br><span class="line">    &quot;gender&quot;: &quot;F&quot;,</span><br><span class="line">    &quot;address&quot;: &quot;244 Columbus Place&quot;,</span><br><span class="line">    &quot;employer&quot;: &quot;Euron&quot;,</span><br><span class="line">    &quot;email&quot;: &quot;bradshawmckenzie@euron.com&quot;,</span><br><span class="line">    &quot;city&quot;: &quot;Hobucken&quot;,</span><br><span class="line">    &quot;state&quot;: &quot;CO&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li>然后使用批量操作来导入数据（使用Kibana的Dev Tools操作）<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">POST /bank/account/_bulk</span><br><span class="line">&#123;</span><br><span class="line">  &quot;index&quot;: &#123;</span><br><span class="line">    &quot;_id&quot;: &quot;1&quot;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">&#123;</span><br><span class="line">  &quot;account_number&quot;: 1,</span><br><span class="line">  &quot;balance&quot;: 39225,</span><br><span class="line">  &quot;firstname&quot;: &quot;Amber&quot;,</span><br><span class="line">  &quot;lastname&quot;: &quot;Duke&quot;,</span><br><span class="line">  &quot;age&quot;: 32,</span><br><span class="line">  &quot;gender&quot;: &quot;M&quot;,</span><br><span class="line">  &quot;address&quot;: &quot;880 Holmes Lane&quot;,</span><br><span class="line">  &quot;employer&quot;: &quot;Pyrami&quot;,</span><br><span class="line">  &quot;email&quot;: &quot;amberduke@pyrami.com&quot;,</span><br><span class="line">  &quot;city&quot;: &quot;Brogan&quot;,</span><br><span class="line">  &quot;state&quot;: &quot;IL&quot;</span><br><span class="line">&#125;</span><br><span class="line">......省略若干条数据</span><br></pre></td></tr></table></figure></li>
<li>导入完成查看索引信息，可以发现bank索引中已经创建了1000条文档</li>
</ol>
<h2 id="搜索入门"><a href="#搜索入门" class="headerlink" title="搜索入门"></a>搜索入门</h2><ol>
<li><p>最简单的搜索<br><code>GET /bank/_search &#123;  &quot;query&quot;:&#123; &quot;match_all&quot;:&#123;&#125; &#125; &#125;</code></p>
</li>
<li><p>分页搜索</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">GET /bank/_search</span><br><span class="line">&#123;</span><br><span class="line">    &quot;query&quot;:&#123; &quot;match_all&quot;:&#123;&#125; &#125;,</span><br><span class="line">    &quot;from&quot;:0,</span><br><span class="line">    &quot;size&quot;:10</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li><p>搜索排序，使用sort</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">GET /bank/_search</span><br><span class="line">&#123;</span><br><span class="line">    &quot;query&quot;:&#123; &quot;match_all&quot;:&#123;&#125; &#125;,</span><br><span class="line">    &quot;sort&quot;:&#123;&quot;balance&quot;:&#123;&quot;order&quot;:&quot;desc&quot;&#125;&#125; #按照balance字段降序</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li><p>搜索并返回指定字段内容，使用_source 表示</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">GET /bank/_search</span><br><span class="line">&#123;</span><br><span class="line">    &quot;query&quot;:&#123; &quot;match_all&quot;:&#123;&#125; &#125;,</span><br><span class="line">    &quot;_source&quot;:[&quot;account_number&quot;,&quot;balance&quot;] #只返回account_number，balance字段</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="条件搜索"><a href="#条件搜索" class="headerlink" title="条件搜索"></a>条件搜索</h2></li>
<li><p>条件搜索，使用match表示匹配条件</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">GET /bank/_search</span><br><span class="line">&#123;</span><br><span class="line">    &quot;query&quot;:&#123;</span><br><span class="line">        &quot;match&quot;:&#123;</span><br><span class="line">            &quot;account_number&quot;:20</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li><p>文本类型字段的条件搜索，对比上一条可以发现，对于数字类型的字段进行的是精确匹配，而对于文本使用的是模糊匹配</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">GET /bank/_search</span><br><span class="line">&#123;</span><br><span class="line">  &quot;query&quot;: &#123;</span><br><span class="line">    &quot;match&quot;: &#123;</span><br><span class="line">      &quot;address&quot;: &quot;mill&quot;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;_source&quot;: [</span><br><span class="line">    &quot;address&quot;,</span><br><span class="line">    &quot;account_number&quot;</span><br><span class="line">  ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li><p>短语匹配搜索，使用match_phrase</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">GET /bank/_search</span><br><span class="line">&#123;</span><br><span class="line">  &quot;query&quot;: &#123;</span><br><span class="line">    &quot;match_phrase&quot;: &#123;</span><br><span class="line">      &quot;address&quot;: &quot;mill lane&quot;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><strong>组合搜索</strong></p>
</li>
<li><p>组合搜索，使用bool来进行组合，must表示必须同时满足</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">GET /bank/_search</span><br><span class="line">&#123;</span><br><span class="line">  &quot;query&quot;: &#123;</span><br><span class="line">    &quot;bool&quot;: &#123;</span><br><span class="line">      &quot;must&quot;: [</span><br><span class="line">      #同时包含mill lane</span><br><span class="line">        &#123; &quot;match&quot;: &#123; &quot;address&quot;: &quot;mill&quot; &#125; &#125;,</span><br><span class="line">        &#123; &quot;match&quot;: &#123; &quot;address&quot;: &quot;lane&quot; &#125; &#125;</span><br><span class="line">      ]</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li><p>组合搜索，使用should，表示只要满足其中一个</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">GET /bank/_search</span><br><span class="line">&#123;</span><br><span class="line">  &quot;query&quot;: &#123;</span><br><span class="line">    &quot;bool&quot;: &#123;</span><br><span class="line">      &quot;should&quot;: [</span><br><span class="line">        &#123; &quot;match&quot;: &#123; &quot;address&quot;: &quot;mill&quot; &#125; &#125;,</span><br><span class="line">        &#123; &quot;match&quot;: &#123; &quot;address&quot;: &quot;lane&quot; &#125; &#125;</span><br><span class="line">      ]</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li><p>组合搜索，must_not表示必须同时不满足</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">GET /bank/_search</span><br><span class="line">&#123;</span><br><span class="line">  &quot;query&quot;: &#123;</span><br><span class="line">    &quot;bool&quot;: &#123;</span><br><span class="line">      &quot;must_not&quot;: [</span><br><span class="line">        &#123; &quot;match&quot;: &#123; &quot;address&quot;: &quot;mill&quot; &#125; &#125;,</span><br><span class="line">        &#123; &quot;match&quot;: &#123; &quot;address&quot;: &quot;lane&quot; &#125; &#125;</span><br><span class="line">      ]</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li><p>组合搜索，组合must和must_not</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">GET /bank/_search</span><br><span class="line">&#123;</span><br><span class="line">  &quot;query&quot;: &#123;</span><br><span class="line">    &quot;bool&quot;: &#123;</span><br><span class="line">      &quot;must&quot;: [</span><br><span class="line">        &#123; &quot;match&quot;: &#123; &quot;age&quot;: &quot;40&quot; &#125; &#125;</span><br><span class="line">      ],</span><br><span class="line">      &quot;must_not&quot;: [</span><br><span class="line">        &#123; &quot;match&quot;: &#123; &quot;state&quot;: &quot;ID&quot; &#125; &#125;</span><br><span class="line">      ]</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="搜索聚合"><a href="#搜索聚合" class="headerlink" title="搜索聚合"></a>搜索聚合</h2></li>
<li><p>对搜索结果进行聚合，使用aggs表示，类似于Mysql中的group by ，例如对state字段进行聚合，统计出不同state的文档数量。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">GET /bank/_search</span><br><span class="line">&#123;</span><br><span class="line">    &quot;size&quot;:0,</span><br><span class="line">    &quot;aggs&quot;:&#123;</span><br><span class="line">        &quot;group_by_state&quot;:&#123;</span><br><span class="line">            &quot;terms&quot;:&#123;</span><br><span class="line">                &quot;field&quot;:&quot;state.keyword&quot;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li><p>嵌套聚合，例如对state进行聚合，统计出不同state的文档数量，再统计出blance的平均值。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">GET /bank/_search</span><br><span class="line">&#123;</span><br><span class="line">  &quot;size&quot;: 0,</span><br><span class="line">  &quot;aggs&quot;: &#123;</span><br><span class="line">    &quot;group_by_age&quot;: &#123;</span><br><span class="line">      &quot;terms&quot;: &#123;</span><br><span class="line">        &quot;field&quot;: &quot;state.keyword&quot;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;avg_blance&quot;: &#123;</span><br><span class="line">      &quot;avg&quot;: &#123;</span><br><span class="line">        &quot;field&quot;: &quot;age&quot;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li><p>对聚合结果进行排序，例如按balance的平均值降序排序</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">GET /bank/_search</span><br><span class="line">&#123;</span><br><span class="line">  &quot;size&quot;: 0,</span><br><span class="line">  &quot;aggs&quot;: &#123;</span><br><span class="line">    &quot;group_by_state&quot;: &#123;</span><br><span class="line">      &quot;terms&quot;: &#123;</span><br><span class="line">        &quot;field&quot;: &quot;state.keyword&quot;,</span><br><span class="line">        &quot;order&quot;: &#123;</span><br><span class="line">          &quot;average_balance&quot;: &quot;desc&quot;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;,</span><br><span class="line">      &quot;aggs&quot;: &#123;</span><br><span class="line">        &quot;average_balance&quot;: &#123;</span><br><span class="line">          &quot;avg&quot;: &#123;</span><br><span class="line">            &quot;field&quot;: &quot;balance&quot;</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li><p>按字段的范围进行分段聚合，例如分段范围为age字段的[20,30] [30,40] [40,50]，之后按gender统计文档个数和balance的平均值。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">GET /bank/_search</span><br><span class="line">&#123;</span><br><span class="line">    &quot;size&quot;: 0,</span><br><span class="line">    &quot;aggs&quot;: &#123;</span><br><span class="line">        &quot;group_by_age&quot;: &#123;</span><br><span class="line">            &quot;range&quot;: &#123;</span><br><span class="line">                &quot;field&quot;: &quot;age&quot;,</span><br><span class="line">                &quot;ranges&quot;: [</span><br><span class="line">                    &#123;</span><br><span class="line">                        &quot;from&quot;: 20,</span><br><span class="line">                        &quot;to&quot;: 30</span><br><span class="line">                    &#125;,</span><br><span class="line">                    &#123;</span><br><span class="line">                        &quot;from&quot;: 30,</span><br><span class="line">                        &quot;to&quot;: 40</span><br><span class="line">                    &#125;,</span><br><span class="line">                    &#123;</span><br><span class="line">                        &quot;from&quot;: 40,</span><br><span class="line">                        &quot;to&quot;: 50</span><br><span class="line">                    &#125;</span><br><span class="line">                ]</span><br><span class="line">            &#125;,</span><br><span class="line">            &quot;aggs&quot;: &#123;</span><br><span class="line">                &quot;group_by_gender&quot;: &#123;</span><br><span class="line">                    &quot;terms&quot;: &#123;</span><br><span class="line">                        &quot;field&quot;: &quot;gender.keyword&quot;</span><br><span class="line">                    &#125;,</span><br><span class="line">                    &quot;aggs&quot;: &#123;</span><br><span class="line">                        &quot;average_balance&quot;: &#123;</span><br><span class="line">                            &quot;avg&quot;: &#123;</span><br><span class="line">                                &quot;field&quot;: &quot;balance&quot;</span><br><span class="line">                            &#125;</span><br><span class="line">                        &#125;</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h1 id="Spring-Boot整合ElasticSearch"><a href="#Spring-Boot整合ElasticSearch" class="headerlink" title="Spring Boot整合ElasticSearch"></a>Spring Boot整合ElasticSearch</h1></li>
</ol>
<p>使用ElasticSearch-Rest-Client对elasticsearch进行操作</p>
<p>引入依赖：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&lt;dependency&gt;  </span><br><span class="line">    &lt;groupId&gt;org.elasticsearch.client&lt;/groupId&gt;  </span><br><span class="line">    &lt;artifactId&gt;elasticsearch-rest-high-level-client&lt;/artifactId&gt;  </span><br><span class="line">    &lt;version&gt;7.9.0&lt;/version&gt;</span><br><span class="line">&lt;/dependency&gt;</span><br></pre></td></tr></table></figure>
<p>因为SpringBoot管理了elasticsearch的依赖版本，所以我们需要指定一下elasticsearch的版本与其一致：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&lt;properties&gt;  </span><br><span class="line">    &lt;elasticsearch.version&gt;7.9.0&lt;/elasticsearch.version&gt;</span><br><span class="line">&lt;/properties&gt;</span><br></pre></td></tr></table></figure>
<p>然后编写一个配置类，向容器中注册一个操作elasticsearch的组件：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">/**</span><br><span class="line"> * @author : yh</span><br><span class="line"> * @date : 2021/8/30 20:35</span><br><span class="line"> */</span><br><span class="line">@Component</span><br><span class="line">@Getter</span><br><span class="line">@Setter</span><br><span class="line">@ConfigurationProperties(prefix = &quot;elasticsearch&quot;)</span><br><span class="line">public class EsHostConfig &#123;</span><br><span class="line"></span><br><span class="line">    private String[] hostArr;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">/**</span><br><span class="line"> * 定义RestClient Bean</span><br><span class="line"> *</span><br><span class="line"> * @author : yh</span><br><span class="line"> * @date : 2021/8/30 20:32</span><br><span class="line"> */</span><br><span class="line">@Configuration</span><br><span class="line">public class EsRestClientConfig &#123;</span><br><span class="line"></span><br><span class="line">    @Autowired</span><br><span class="line">    private EsHostConfig esHostConfig;</span><br><span class="line"></span><br><span class="line">    @Bean</span><br><span class="line">    public RestHighLevelClient restHighLevelClient() &#123;</span><br><span class="line">        String[] hostArr = esHostConfig.getHostArr();</span><br><span class="line">        int size = hostArr.length;</span><br><span class="line">        HttpHost[] httpHostArr = new HttpHost[size];</span><br><span class="line">        for (int i = 0; i &lt; size; i++) &#123;</span><br><span class="line">            String[] split = hostArr[i].split(&quot;:&quot;);</span><br><span class="line">            httpHostArr[i] = new HttpHost(split[0], Integer.parseInt(split[1]), &quot;http&quot;);</span><br><span class="line">        &#125;</span><br><span class="line">        return new RestHighLevelClient(RestClient.builder(httpHostArr));</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>接下来我们就可以通过它操作 elasticsearch 了：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">@Autowired</span><br><span class="line">private RestHighLevelClient client;</span><br><span class="line"></span><br><span class="line">@Data</span><br><span class="line">class User &#123;</span><br><span class="line">    private String name;    </span><br><span class="line">    private Integer age;    </span><br><span class="line">    private String gender;</span><br><span class="line">&#125;</span><br><span class="line">@Test</span><br><span class="line">public void index() throws IOException &#123;    </span><br><span class="line">    IndexRequest indexRequest = new IndexRequest(&quot;users&quot;);    </span><br><span class="line">    indexRequest.id(&quot;1&quot;);    </span><br><span class="line">    // indexRequest.source(&quot;name&quot;,&quot;zhangsan&quot;,&quot;age&quot;,20,&quot;gender&quot;,&quot;男&quot;);    </span><br><span class="line">    User user = new User();    </span><br><span class="line">    user.setName(&quot;zhangsan&quot;);    </span><br><span class="line">    user.setAge(20);    </span><br><span class="line">    user.setGender(&quot;男&quot;);    </span><br><span class="line">    String json = JSON.toJSONString(user);    </span><br><span class="line">    indexRequest.source(json, XContentType.JSON);    </span><br><span class="line">    // 执行保存操作    </span><br><span class="line">    IndexResponse index = client.index(indexRequest, RequestOptions.DEFAULT);    </span><br><span class="line">    // 响应数据    </span><br><span class="line">    System.out.println(index);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>RestHighLevelClient提供了非常多的方式用于保存数据，但比较常用的是通过json数据直接保存，首先需要指定索引， IndexRequest indexRequest &#x3D; new IndexRequest(&quot;users&quot;); 指定了users索引，然后指定数据id，接着指定数据值，最后使用client执行保存操作，然后可以拿到响应数据。</p>
<p>elasticsearch的其它简单操作，诸如：更新、删除等，都只需要转换一下调用方法即可，如更新操作，就需要使用client调用update方法，接下来我们看看Java程序该如何实现较为复杂的检索操作。</p>
<p>比如现在想聚合出年龄的分布情况，并求出每个年龄分布人群的平均薪资，就应该这样进行编写：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">@Test</span><br><span class="line">    public void aggSearch() throws Exception &#123;</span><br><span class="line">        //创建搜索request</span><br><span class="line">        SearchRequest searchRequest = new SearchRequest(&quot;bank&quot;);</span><br><span class="line">        SearchSourceBuilder searchSourceBuilder = new SearchSourceBuilder();</span><br><span class="line">        //查询条件</span><br><span class="line">        searchSourceBuilder.query(QueryBuilders.matchAllQuery());</span><br><span class="line">        //统计各个年龄的平均工资</span><br><span class="line">        searchSourceBuilder.aggregation(AggregationBuilders.terms(&quot;ageAgg&quot;).field(&quot;age&quot;).subAggregation(AggregationBuilders.avg(&quot;balanceAvgAgg&quot;).field(&quot;balance&quot;)));</span><br><span class="line">        //所有人平均工资</span><br><span class="line">        searchSourceBuilder.aggregation(AggregationBuilders.avg(&quot;allBalanceAvgAgg&quot;).field(&quot;balance&quot;));</span><br><span class="line">        //构建request</span><br><span class="line">        SearchRequest request = searchRequest.source(searchSourceBuilder);</span><br><span class="line">        //search</span><br><span class="line">        SearchResponse searchResponse = restHighLevelClient.search(request, RequestOptions.DEFAULT);</span><br><span class="line">        //Aggregations aggregations = searchResponse.getAggregations();</span><br><span class="line">        //Aggregation接口有很多实现类  Avg（平均值）</span><br><span class="line">//        Avg avg = aggregations.get(&quot;balanceAgg&quot;);</span><br><span class="line">//        System.out.println(avg.getValue());</span><br><span class="line">        Aggregations aggregations = searchResponse.getAggregations();</span><br><span class="line">        Terms ageAgg = aggregations.get(&quot;ageAgg&quot;);</span><br><span class="line">        List&lt;? extends Terms.Bucket&gt; buckets = ageAgg.getBuckets();</span><br><span class="line">        for (Terms.Bucket bucket : buckets) &#123;//只查出了10条数据</span><br><span class="line">            System.out.println(&quot;年龄:&quot; + bucket.getKey());</span><br><span class="line">            System.out.println(&quot;人数:&quot; + bucket.getDocCount());</span><br><span class="line">            Avg avg = bucket.getAggregations().get(&quot;balanceAvgAgg&quot;);</span><br><span class="line">            System.out.println(&quot;平均工资:&quot; + avg.getValue());</span><br><span class="line">            System.out.println(&quot;=================================&quot;);</span><br><span class="line">        &#125;</span><br><span class="line">        Avg avg = aggregations.get(&quot;allBalanceAvgAgg&quot;);</span><br><span class="line">        System.out.println(&quot;所有人平均工资:&quot; + avg.getValue());</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>
<ul>
<li>最终输出结果<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">年龄:31</span><br><span class="line">人数:61</span><br><span class="line">平均工资:28312.918032786885</span><br><span class="line">=================================</span><br><span class="line">年龄:39</span><br><span class="line">人数:60</span><br><span class="line">平均工资:25269.583333333332</span><br><span class="line">=================================</span><br><span class="line">年龄:26</span><br><span class="line">人数:59</span><br><span class="line">平均工资:23194.813559322032</span><br><span class="line">=================================</span><br><span class="line">年龄:32</span><br><span class="line">人数:52</span><br><span class="line">平均工资:23951.346153846152</span><br><span class="line">=================================</span><br><span class="line">年龄:35</span><br><span class="line">人数:52</span><br><span class="line">平均工资:22136.69230769231</span><br><span class="line">=================================</span><br><span class="line">年龄:36</span><br><span class="line">人数:52</span><br><span class="line">平均工资:22174.71153846154</span><br><span class="line">=================================</span><br><span class="line">年龄:22</span><br><span class="line">人数:51</span><br><span class="line">平均工资:24731.07843137255</span><br><span class="line">=================================</span><br><span class="line">年龄:28</span><br><span class="line">人数:51</span><br><span class="line">平均工资:28273.882352941175</span><br><span class="line">=================================</span><br><span class="line">年龄:33</span><br><span class="line">人数:50</span><br><span class="line">平均工资:25093.94</span><br><span class="line">=================================</span><br><span class="line">年龄:34</span><br><span class="line">人数:49</span><br><span class="line">平均工资:26809.95918367347</span><br><span class="line">=================================</span><br><span class="line">所有人平均工资:25714.837</span><br><span class="line"></span><br></pre></td></tr></table></figure></li>
</ul>
]]></content>
      <categories>
        <category>后端</category>
      </categories>
      <tags>
        <tag>elastic search</tag>
      </tags>
  </entry>
  <entry>
    <title>Docker实战</title>
    <url>/2022/05/20/Docker%E5%AE%9E%E6%88%98/</url>
    <content><![CDATA[<h1 id="Docker-部署springboot项目"><a href="#Docker-部署springboot项目" class="headerlink" title="Docker 部署springboot项目"></a>Docker 部署springboot项目</h1><pre><code>使用docker-maven-plugin maven插件
</code></pre>
<h2 id="服务器安装docker"><a href="#服务器安装docker" class="headerlink" title="服务器安装docker"></a>服务器安装docker</h2><pre><code>略
</code></pre>
<h2 id="Docker开启远程访问"><a href="#Docker开启远程访问" class="headerlink" title="Docker开启远程访问"></a>Docker开启远程访问</h2><ol>
<li>查看docker服务状态（查看docker.service位置）<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">pi@raspberrypi:~ $ service docker status</span><br><span class="line">● docker.service - Docker Application Container Engine</span><br><span class="line">     Loaded: loaded (/lib/systemd/system/docker.service; enabled; vendor preset: enabled)</span><br><span class="line">     Active: active (running) since Sun 2022-04-17 17:28:04 CST; 1 months 2 days ago</span><br><span class="line">...</span><br><span class="line">...</span><br><span class="line">...</span><br></pre></td></tr></table></figure></li>
<li>编辑docker.service<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">vim /lib/systemd/system/docker.service</span><br></pre></td></tr></table></figure></li>
<li>修改[Service]下的ExecStart，添加-H tcp:&#x2F;&#x2F;0.0.0.0:2375；对外开放docker服务（建议不要使用默认端口2375）<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">ExecStart=/usr/bin/dockerd -H tcp://0.0.0.0:2375 -H fd:// --containerd=/run/containerd/containerd.sock</span><br></pre></td></tr></table></figure></li>
<li>重新加载Docker配置生效 <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">systemctl daemon-reload </span><br><span class="line">systemctl restart docker </span><br></pre></td></tr></table></figure></li>
<li>服务器防火墙开放端口</li>
<li>浏览器访问<a href="http://ip:2375/version%EF%BC%8C%E6%B5%8B%E8%AF%95%E6%98%AF%E5%90%A6%E6%88%90%E5%8A%9F">http://ip:2375/version，测试是否成功</a></li>
</ol>
<h2 id="使用TLS-HTTPS-保证Docker服务安全"><a href="#使用TLS-HTTPS-保证Docker服务安全" class="headerlink" title="使用TLS(HTTPS)保证Docker服务安全"></a>使用TLS(HTTPS)保证Docker服务安全</h2><h3 id="1-服务器端生成CA共钥和私钥"><a href="#1-服务器端生成CA共钥和私钥" class="headerlink" title="1. 服务器端生成CA共钥和私钥"></a>1. 服务器端生成CA共钥和私钥</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 创建目录存放CA证书</span><br><span class="line">pi@raspberrypi:~ $ mkdir ca</span><br><span class="line"></span><br><span class="line"># 进入目录</span><br><span class="line">pi@raspberrypi:~ $ cd ca</span><br><span class="line"></span><br><span class="line"># 生成私钥（会提示输入密码）</span><br><span class="line">pi@raspberrypi:~/ca $ openssl genrsa -aes256 -out ca-key.pem 4096</span><br><span class="line">Generating RSA private key, 4096 bit long modulus (2 primes)</span><br><span class="line">..........................++++</span><br><span class="line">.......++++</span><br><span class="line">e is 65537 (0x010001)</span><br><span class="line">Enter pass phrase for ca-key.pem:</span><br><span class="line"></span><br><span class="line"># 生成证书信息（需要输入上面的密码以及一些其他信息【注意Common Name填写服务器外网IP】）</span><br><span class="line">pi@raspberrypi:~/ca $ openssl req -new -x509 -days 3650 -key ca-key.pem -sha256 -out ca.pem</span><br><span class="line">Enter pass phrase for ca-key.pem:</span><br><span class="line">You are about to be asked to enter information that will be incorporated</span><br><span class="line">into your certificate request.</span><br><span class="line">What you are about to enter is what is called a Distinguished Name or a DN.</span><br><span class="line">There are quite a few fields but you can leave some blank</span><br><span class="line">For some fields there will be a default value,</span><br><span class="line">If you enter &#x27;.&#x27;, the field will be left blank.</span><br><span class="line">-----</span><br><span class="line">Country Name (2 letter code) [AU]:CN</span><br><span class="line">State or Province Name (full name) [Some-State]:ZheJiang</span><br><span class="line">Locality Name (eg, city) []:HangZhou</span><br><span class="line">Organization Name (eg, company) [Internet Widgits Pty Ltd]:yanghao </span><br><span class="line">Organizational Unit Name (eg, section) []:yanghao</span><br><span class="line">Common Name (e.g. server FQDN or YOUR name) []:192.168.3.3</span><br><span class="line">Email Address []:yh.124@qq.com</span><br></pre></td></tr></table></figure>
<p><strong>有了CA之后，就可以创建服务器密钥和证书签名请求(CSR)了。确保“Common Name”与你连接Docker时使用的主机名匹配</strong></p>
<h3 id="2-创建服务器密钥和证书签名请求"><a href="#2-创建服务器密钥和证书签名请求" class="headerlink" title="2. 创建服务器密钥和证书签名请求"></a>2. 创建服务器密钥和证书签名请求</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 创建服务器密钥</span><br><span class="line">pi@raspberrypi:~/ca $ openssl genrsa -out server-key.pem 4096</span><br><span class="line">Generating RSA private key, 4096 bit long modulus (2 primes)</span><br><span class="line">................................................................++++</span><br><span class="line">.........++++</span><br><span class="line">e is 65537 (0x010001)</span><br><span class="line"></span><br><span class="line"># 证书签名请求（注意修改为你的服务器IP）</span><br><span class="line">openssl req -subj &quot;/CN=192.168.3.3&quot; -sha256 -new -key server-key.pem -out server.csr</span><br></pre></td></tr></table></figure>
<h3 id="3-配置白名单"><a href="#3-配置白名单" class="headerlink" title="3. 配置白名单"></a>3. 配置白名单</h3><p>配置白名单，允许连接的ip（通过证书）;IP可以配置多个</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">echo subjectAltName = IP:192.168.3.3,IP::192.168.3.5 &gt;&gt; extfile.cnf</span><br></pre></td></tr></table></figure>
<h3 id="4-设置Docker守护进程密钥的扩展使用属性，仅用于服务器身份验证"><a href="#4-设置Docker守护进程密钥的扩展使用属性，仅用于服务器身份验证" class="headerlink" title="4. 设置Docker守护进程密钥的扩展使用属性，仅用于服务器身份验证"></a>4. 设置Docker守护进程密钥的扩展使用属性，仅用于服务器身份验证</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">echo extendedKeyUsage = serverAuth &gt;&gt; extfile.cnf</span><br></pre></td></tr></table></figure>
<h3 id="5-生成签名证书（需要输入密码）"><a href="#5-生成签名证书（需要输入密码）" class="headerlink" title="5. 生成签名证书（需要输入密码）"></a>5. 生成签名证书（需要输入密码）</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">openssl x509 -req -days 3650 -sha256 -in server.csr -CA ca.pem -CAkey ca-key.pem \</span><br><span class="line">  -CAcreateserial -out server-cert.pem -extfile extfile.cnf</span><br></pre></td></tr></table></figure>
<h3 id="6-对于客户端身份验证，创建一个客户端密钥和证书签名请求"><a href="#6-对于客户端身份验证，创建一个客户端密钥和证书签名请求" class="headerlink" title="6. 对于客户端身份验证，创建一个客户端密钥和证书签名请求"></a>6. 对于客户端身份验证，创建一个客户端密钥和证书签名请求</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 生成 key.pem</span><br><span class="line">openssl genrsa -out key.pem 4096</span><br><span class="line"></span><br><span class="line"># 生成 csr</span><br><span class="line">openssl req -subj &#x27;/CN=client&#x27; -new -key key.pem -out client.csr</span><br><span class="line"></span><br><span class="line"># 创建配置文件</span><br><span class="line">echo extendedKeyUsage = clientAuth &gt; extfile-client.cnf</span><br><span class="line"></span><br><span class="line"># 生成签名证书</span><br><span class="line">openssl x509 -req -days 3650 -sha256 -in client.csr -CA ca.pem -CAkey ca-key.pem \</span><br><span class="line">  -CAcreateserial -out cert.pem -extfile extfile-client.cnf</span><br><span class="line">  </span><br><span class="line"># 将服务器端的ca.pem cert.pem key.pem复制到本地</span><br><span class="line">scp ca.pem cert.pem key.pem yh@192.168.3.5:/Users/yh/ca</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h3 id="7-删除不需要的文件"><a href="#7-删除不需要的文件" class="headerlink" title="7. 删除不需要的文件"></a>7. 删除不需要的文件</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 服务器（服务端）</span><br><span class="line">rm -rf server.csr extfile.cnf client.csr extfile-client.cnf</span><br></pre></td></tr></table></figure>
<h3 id="8-修改文件权限，防止误删"><a href="#8-修改文件权限，防止误删" class="headerlink" title="8. 修改文件权限，防止误删"></a>8. 修改文件权限，防止误删</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 服务端</span><br><span class="line">chmod -v 0400 ca-key.pem server-key.pem</span><br><span class="line">chmod -v 0444 ca.pem server-cert.pem</span><br><span class="line"># 客户端</span><br><span class="line">chmod -v 0400 key.pem</span><br><span class="line">chmod -v 0444 ca.pem cert.pem</span><br></pre></td></tr></table></figure>
<h3 id="9-再次修改服务器docker-service"><a href="#9-再次修改服务器docker-service" class="headerlink" title="9. 再次修改服务器docker.service"></a>9. 再次修改服务器docker.service</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">vim /lib/systemd/system/docker.service</span><br><span class="line"># 修改ExecStart（添加证书的路径）</span><br><span class="line">ExecStart=/usr/bin/dockerd --tlsverify --tlscacert=/home/pi/ca/ca.pem --tlscert=/home/pi/ca/server-cert.pem --tlskey=/home/pi/ca/server-key.pem -H tcp://0.0.0.0:2376 -H unix:///var/run/docker.sock</span><br></pre></td></tr></table></figure>
<h3 id="10-重新加载daemon并重启docker"><a href="#10-重新加载daemon并重启docker" class="headerlink" title="10. 重新加载daemon并重启docker"></a>10. 重新加载daemon并重启docker</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">systemctl daemon-reload &amp;&amp; systemctl restart docker</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h3 id="11-配置本地环境变量"><a href="#11-配置本地环境变量" class="headerlink" title="11. 配置本地环境变量"></a>11. 配置本地环境变量</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">mkdir -pv ~/.docker</span><br><span class="line"># 将证书copy到.docker下</span><br><span class="line">cp -v &#123;ca,cert,key&#125;.pem ~/.docker</span><br><span class="line">chmod -v 0400 key.pem</span><br><span class="line">chmod -v 0444 ca.pem cert.pem</span><br><span class="line"># 配置环境变量</span><br><span class="line">export DOCKER_HOST=tcp://0.0.0.0:2376 DOCKER_TLS_VERIFY=1</span><br></pre></td></tr></table></figure>
<h3 id="12-客户端测试"><a href="#12-客户端测试" class="headerlink" title="12. 客户端测试"></a>12. 客户端测试</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 配置了环境变量后就可以访问服务器docker服务</span><br><span class="line">docker ps</span><br><span class="line"># 没有配置环境变量</span><br><span class="line">docker --tlsverify --tlscacert=/Users/yh/.docker/ca.pem --tlscert=/Users/yh/.docker/cert.pem --tlskey=/Users/yh/.docker/key.pem -H=tcp://192.168.3.3:2376 version</span><br></pre></td></tr></table></figure>
<h2 id="项目配置"><a href="#项目配置" class="headerlink" title="项目配置"></a>项目配置</h2><h3 id="配置docker-file-maven-plugin插件"><a href="#配置docker-file-maven-plugin插件" class="headerlink" title="配置docker-file-maven-plugin插件"></a>配置docker-file-maven-plugin插件</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&lt;build&gt;</span><br><span class="line">    &lt;plugins&gt;</span><br><span class="line">        &lt;!-- dockerfile maven --&gt;</span><br><span class="line">        &lt;plugin&gt;</span><br><span class="line">            &lt;groupId&gt;com.spotify&lt;/groupId&gt;</span><br><span class="line">            &lt;artifactId&gt;dockerfile-maven-plugin&lt;/artifactId&gt;</span><br><span class="line">            &lt;executions&gt;</span><br><span class="line">                &lt;execution&gt;</span><br><span class="line">                    &lt;id&gt;default&lt;/id&gt;</span><br><span class="line">                    &lt;goals&gt;</span><br><span class="line">                        &lt;goal&gt;build&lt;/goal&gt;</span><br><span class="line">                        &lt;goal&gt;push&lt;/goal&gt;</span><br><span class="line">                    &lt;/goals&gt;</span><br><span class="line">                    &lt;configuration&gt;</span><br><span class="line">                    &lt;/configuration&gt;</span><br><span class="line">                &lt;/execution&gt;</span><br><span class="line">            &lt;/executions&gt;</span><br><span class="line">            &lt;!--docker镜像相关的配置信息--&gt;</span><br><span class="line">            &lt;configuration&gt;</span><br><span class="line">                &lt;contextDirectory&gt;$&#123;project.basedir&#125;&lt;/contextDirectory&gt;</span><br><span class="line">                &lt;dockerfile&gt;$&#123;project.basedir&#125;/Dockerfile&lt;/dockerfile&gt;</span><br><span class="line">                &lt;!--使用username和password标签，也可以使用useMavenSettingsForAuth，在settings.xml文件中的配置 servers--&gt;</span><br><span class="line">                &lt;useMavenSettingsForAuth&gt;false&lt;/useMavenSettingsForAuth&gt;</span><br><span class="line">                &lt;username&gt;xxx&lt;/username&gt;</span><br><span class="line">                &lt;password&gt;xxx&lt;/password&gt;</span><br><span class="line">                &lt;!--远程仓库地址--&gt;</span><br><span class="line">                &lt;repository&gt;$&#123;docker.repository.registry&#125;/$&#123;docker.repository.namespace&#125;/$&#123;project.artifactId&#125;&lt;/repository&gt;</span><br><span class="line">                &lt;tag&gt;$&#123;project.version&#125;&lt;/tag&gt;</span><br><span class="line">                &lt;buildArgs&gt;</span><br><span class="line">                    &lt;JAR_FILE&gt;$&#123;project.build.finalName&#125;.jar&lt;/JAR_FILE&gt;</span><br><span class="line">                &lt;/buildArgs&gt;</span><br><span class="line">            &lt;/configuration&gt;</span><br><span class="line">        &lt;/plugin&gt;</span><br><span class="line">    &lt;/plugins&gt;</span><br></pre></td></tr></table></figure>
<h3 id="Dockerfile"><a href="#Dockerfile" class="headerlink" title="Dockerfile"></a>Dockerfile</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">FROM houwm/jdk8:arm64</span><br><span class="line"></span><br><span class="line">MAINTAINER yanghao&lt;yh.124@qq.com&gt;</span><br><span class="line"></span><br><span class="line"># 参数</span><br><span class="line">ARG JAR_FILE</span><br><span class="line"></span><br><span class="line"># 环境变量</span><br><span class="line">ENV TZ=Asia/Shanghai LANG=C.UTF-8</span><br><span class="line">ENV PARAMS=&quot;--server.port=8080 --spring.profiles.active=prod -Xms512m -Xmx512m&quot;</span><br><span class="line"></span><br><span class="line"># 设置时区</span><br><span class="line">RUN ln -snf /usr/share/zoneinfo/$TZ /etc/localtime &amp;&amp; echo $TZ &gt; /etc/timezone</span><br><span class="line"></span><br><span class="line"># 复制jar包</span><br><span class="line">COPY target/$&#123;JAR_FILE&#125; /app.jar</span><br><span class="line"></span><br><span class="line"># 暴露端口</span><br><span class="line">EXPOSE 8080</span><br><span class="line"></span><br><span class="line"># 工作目录</span><br><span class="line">WORKDIR /</span><br><span class="line"></span><br><span class="line"># 执行命令</span><br><span class="line">ENTRYPOINT [&quot;/bin/sh&quot;,&quot;-c&quot;,&quot;java -jar /app.jar $&#123;PARAMS&#125;&quot;]</span><br></pre></td></tr></table></figure>
<h3 id="部署项目"><a href="#部署项目" class="headerlink" title="部署项目"></a>部署项目</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 会自动在远程服务器构建镜像</span><br><span class="line">mvn package</span><br><span class="line"># 就可以省略这个步骤</span><br><span class="line">mvn dockerfile:build</span><br><span class="line"># 会自动推送镜像到远程仓库</span><br><span class="line">mvn deploy</span><br><span class="line"># 就可以省略这个步骤</span><br><span class="line">mvn dockerfile:push</span><br><span class="line"># 如果要临时跳过所有的Dockerfile相关的目标，执行如下Maven命令</span><br><span class="line">mvn clean install -Ddockerfile.skip</span><br><span class="line"># 想跳过某一个goal</span><br><span class="line">mvn clean package -Ddockerfile.build.skip</span><br><span class="line">mvn clean package -Ddockerfile.tag.skip</span><br><span class="line">mvn clean deploy -Ddockerfile.push.skip</span><br><span class="line"> </span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title>InnoDB中的索引</title>
    <url>/2022/01/12/InnoDB%E4%B8%AD%E7%9A%84%E7%B4%A2%E5%BC%95/</url>
    <content><![CDATA[<h2 id="InnoDB中的索引设计方案"><a href="#InnoDB中的索引设计方案" class="headerlink" title="InnoDB中的索引设计方案"></a>InnoDB中的索引设计方案</h2><ul>
<li>0:普通的用户记录</li>
<li>1:目录项记录</li>
<li>2:最小记录</li>
<li>3:最大记录<br><img src="https://yh-blog-files.oss-cn-hangzhou.aliyuncs.com/2022/01/12/16419950340539.jpg" alt="聚簇索引"><br><strong>一般情况下，我们用到的B+树都不会超过4层。（减少磁盘I&#x2F;O）</strong><br>一个B+树的节点其实可以分成好多层，规定最下边的那层，也就是存放用户记录的那层为第0层，之后依次往上加。一个数据页可以存放16k的数据。假设所有存放用户记录的叶子节点代表的数据页可以存放100条用户记录，所有存放目录项记录的内节点代表的数据页可以存放1000条数据，那么：</li>
<li>如果B+树只有1层，也就是只有一个用于存放记录的节点，最多能存放100条记录。</li>
<li>如果B+树有2层，最多能存放1000 * 100 &#x3D; 10万条记录。</li>
<li>如果B+树有3层，最多能存放1000 * 1000 * 100 &#x3D; 1亿条记录</li>
<li>如果b+树有4层，做多能存放1000 * 1000 * 1000 * 100 &#x3D; 1000亿条记录<h2 id="常见索引概念"><a href="#常见索引概念" class="headerlink" title="常见索引概念"></a>常见索引概念</h2><h3 id="聚簇索引"><a href="#聚簇索引" class="headerlink" title="聚簇索引"></a>聚簇索引</h3><h3 id="二级索引（辅助索引、非聚簇索引）"><a href="#二级索引（辅助索引、非聚簇索引）" class="headerlink" title="二级索引（辅助索引、非聚簇索引）"></a>二级索引（辅助索引、非聚簇索引）</h3><img src="https://yh-blog-files.oss-cn-hangzhou.aliyuncs.com/2022/01/12/16419967282458.jpg" alt="非聚簇索引"><h4 id="联合索引"><a href="#联合索引" class="headerlink" title="联合索引"></a>联合索引</h4><img src="https://yh-blog-files.oss-cn-hangzhou.aliyuncs.com/2022/01/12/16419972009034.jpg" alt="联合索引"><h3 id="InnoDB的B-树索引的注意事项"><a href="#InnoDB的B-树索引的注意事项" class="headerlink" title="InnoDB的B+树索引的注意事项"></a>InnoDB的B+树索引的注意事项</h3><h4 id="根页面位置万年不变"><a href="#根页面位置万年不变" class="headerlink" title="根页面位置万年不变"></a>根页面位置万年不变</h4></li>
<li>每当某个表创建一个B+树索引（聚簇索引）的时候，都会为这个索引创建一个根节点页，最开始表中没有数据的时候，每个B+树索引对应的根节点中，既没有用户记录，也没有目录项记录。</li>
<li>随后向表中插入用户记录时，先把用户记录存储到这个根节点中。</li>
<li>当根节点中的可用空间用完时，继续插入记录，此时会将根节点中的所有记录复制到新分配的页，比如页a中，然后后对这个新页进行页分裂的操作，得到另一个新页，比如页b，这时新插入的记录根据键值（也就是索引值）的大小就会被分配到页a或者页b中，而根节点便升级为存储目录项记录的页<br><strong>这个过程特别注意的是：</strong> 一个B+树索引的根节点自诞生之日起，便不会再移动。这样只要我们对某个表建立一个索引，那么它的根节点的页号便会被记录到某个地方，然后凡事InnoDB存储引擎需要用到这个索引的时候，都会从哪个固定的地方取出根节点的页，从而来访问这个索引。<h3 id="非叶子节点中的目录项记录的唯一性"><a href="#非叶子节点中的目录项记录的唯一性" class="headerlink" title="非叶子节点中的目录项记录的唯一性"></a>非叶子节点中的目录项记录的唯一性</h3>即非叶子节点的索引唯一（创建的索引默认后面会跟主键）<h3 id="一个数据页最少存储2条数据"><a href="#一个数据页最少存储2条数据" class="headerlink" title="一个数据页最少存储2条数据"></a>一个数据页最少存储2条数据</h3><h3 id="MySQL数据结构选择的合理性"><a href="#MySQL数据结构选择的合理性" class="headerlink" title="MySQL数据结构选择的合理性"></a>MySQL数据结构选择的合理性</h3><h4 id="Hash结构"><a href="#Hash结构" class="headerlink" title="Hash结构"></a>Hash结构</h4><ol>
<li>Hash索引仅能满足（&#x3D;）（&lt;&gt;）和in查询。范围查询效率很差。</li>
<li>Hash索引数据存储是没有顺序的。</li>
<li>对于联合索引的情况，Hash值是将联合索引合并后一起来计算的，无法对单独的一个键或者几个索引键进行查询。</li>
<li>对于等值查询来说，通常Hash索引的效率很高，不过存在一种情况，就是索引列的重复值很多，效率就会降低。</li>
</ol>
</li>
</ul>
<p>另外，InnoDB本身不支持Hash索引，但是提供了自适应hash索引（adaptive_hash_index）。如果某个数据经常被访问，当满足一定条件的时候，就会将这个数据页的地址存放到Hash表中。这样下次查询的时候，就可以直接找到这个页面的所在位置。这样让B+树也具备了Hash索引的优点。</p>
<h4 id="二叉搜索树"><a href="#二叉搜索树" class="headerlink" title="二叉搜索树"></a>二叉搜索树</h4><p>二叉树特征：<br>    * 一个节点只能有两个子节点，也就是一个节点度不能超过2<br>    * 左子节点 &lt; 本节点 &lt;&#x3D; 右子节点<br><img src="https://yh-blog-files.oss-cn-hangzhou.aliyuncs.com/2022/01/13/16420811937219.jpg" alt="二叉搜索树"><br> <strong>在极端情况下会变成一个线性链表</strong></p>
<h4 id="AVL树"><a href="#AVL树" class="headerlink" title="AVL树"></a>AVL树</h4><p> 平衡二叉树特征：<br>    <strong>它是一棵空树或它的左右两个子树的高度差的绝对值不超过1，并且左右两个子树都是一棵平衡二叉树。</strong><br><img src="https://yh-blog-files.oss-cn-hangzhou.aliyuncs.com/2022/01/13/16420812487954.jpg" alt="AVL树"><br><strong>树的层数过多，访问一个节点相当于做一次磁盘IO</strong></p>
<h4 id="B-Tree"><a href="#B-Tree" class="headerlink" title="B-Tree"></a>B-Tree</h4><p>Balance Tree，也就是多路平衡查找树。</p>
<p><img src="https://yh-blog-files.oss-cn-hangzhou.aliyuncs.com/2022/01/13/16420815935861.jpg" alt="16420815935861"></p>
<ol>
<li>B树在插入和删除节点的时候如果导致树不平衡，就通过自动调节节点的位置保持树的自平衡。</li>
<li>关键字集合分布在整棵树中，即叶子节点和非叶子节点都存放数据。搜索有可能在非叶子节点结束</li>
<li>其搜索性能等价于在关键字全集内做一次二分查找。<h4 id="B-Tree-1"><a href="#B-Tree-1" class="headerlink" title="B+Tree"></a>B+Tree</h4>B+树也是一种多路搜索树，基于B-Tree做了改进。B+树适合文件索引系统。<br><strong>B+树和B树的差异：</strong></li>
<li>有k个子节点就有k个关键字。也就是子节点数量&#x3D;关键字数量。而B树中，子节点数量&#x3D;关键字数量+1。</li>
<li>非叶子节点的关键字会同时存在在子节点中，并且是在子节点中所有关键字的最大（或最小）。</li>
<li>非叶子节点仅用于索引，不保存数据记录，跟记录相关的信息都存放在叶子节点中。而B树中，非叶子节点即保存索引也保存数据记录。</li>
<li>所有关键字都在叶子节点出现，叶子节点构成一个有序链表，而且叶子节点本身按照关键字的大小从小到大顺序链接。</li>
</ol>
]]></content>
      <categories>
        <category>后端</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title>JVM</title>
    <url>/2021/04/26/JVM/</url>
    <content><![CDATA[<p><img src="https://yh-blog-files.oss-cn-hangzhou.aliyuncs.com/2021/04/26/1.png" alt="1"></p>
<h2 id="Java内存模型（JMM）"><a href="#Java内存模型（JMM）" class="headerlink" title="Java内存模型（JMM）"></a>Java内存模型（JMM）</h2><p><strong>主内存（main memory）</strong>、<strong>本地内存（local memory）</strong>（抽象概念）</p>
<ul>
<li>本地内存涵盖了缓存，写缓冲区，寄存器以及其他的硬件和编译器优化。</li>
<li>Java编译器输入的指令流基本是一种基于栈的指令架构，另外一种指令架构师基于寄存器的指令架构。</li>
</ul>
<span id="more"></span>

<h2 id="执行引擎-Execution-Engine"><a href="#执行引擎-Execution-Engine" class="headerlink" title="执行引擎(Execution Engine)"></a>执行引擎(Execution Engine)</h2><h2 id="类加载子系统（Class-Loader）"><a href="#类加载子系统（Class-Loader）" class="headerlink" title="类加载子系统（Class Loader）"></a>类加载子系统（Class Loader）</h2><p> <img src="https://yh-blog-files.oss-cn-hangzhou.aliyuncs.com/2021/04/26/2.png" alt="2"><br> <em>class。文件，网络</em><br> <strong>加载、验证、准备、解析、初始化。然后是使用和卸载了</strong><br> <em>通过全限定名来加载生成class对象到内存中，然后进行验证这个class文件，包括文件格式校验、元数据验证，字节码校验等。准备是对这个对象分配内存。解析是将符号引用转化为直接引用（指针引用），初始化就是开始执行构造器的代码</em></p>
<p>  <strong>双亲委派模型机制</strong></p>
<ol>
<li>启动类加载器(Bootstrap ClassLoader)用来加载java核心类库，无法被java程序直接引用。</li>
<li>扩展类加载器(Extensions ClassLoader):它用来加载 Java 的扩展库。Java 虚拟机的实现会提供一个扩展库目录。该类加载器在此目录里面查找并加载 Java 类。</li>
<li>应用类加载器（Application ClassLoader）：它根据 Java 应用的类路径（CLASSPATH）来加载 Java 类。一般来说，Java 应用的类都是由它来完成加载的。</li>
<li>用户自定义类加载器，通过继承 java.lang.ClassLoader类的方式实现。</br><br><strong>什么情况下需要自定义类加载器：</strong></li>
</ol>
<ul>
<li><p>隔离加载类</p>
</li>
<li><p>修改类加载方式</p>
</li>
<li><p>扩展加载源</p>
</li>
<li><p>防止源码泄漏</p>
<h2 id="运行时数据区-Runtime-Data-Area"><a href="#运行时数据区-Runtime-Data-Area" class="headerlink" title="运行时数据区(Runtime Data Area)"></a>运行时数据区(Runtime Data Area)</h2><p> 内存</p>
</li>
<li><p>什么是运行时数据区<br><img src="https://yh-blog-files.oss-cn-hangzhou.aliyuncs.com/2021/04/26/3.png" alt="3"></p>
</li>
<li><p>什么是虚拟机栈<br> 栈：数据结构，先进后出，First In Last Out,用来运行java方法的。线程私有。启用一个线程就有一个虚拟机栈。<br> <strong>调用一个方法就压入一帧。</strong><br>栈内存参数<br>-Xss 1m(默认1M)<br><img src="https://yh-blog-files.oss-cn-hangzhou.aliyuncs.com/2021/04/26/4.png" alt="4"><br><img src="https://yh-blog-files.oss-cn-hangzhou.aliyuncs.com/2021/04/26/5.png" alt="5"></p>
</li>
<li><p>局部变量表（八大基本数据类型+对象引用）</p>
</li>
</ul>
<ol>
<li>定义为一个数字数组，主要用于储存方法参数和定义在方法体内的局部变量。</li>
<li>不存在数据线程安全问题。</li>
<li>局部变量表所需容量大小是在编译期确定下来的。</li>
<li>局部变量表中的变量也是重要的垃圾回收根节点（GCRoots可达性分析算法），只要被局部变量表中直接或间接引用的对象都不会被回收。</br><br>关于Slot的理解：</br><br>&amp;emsp;1.最基本的储存单元Slot(变量槽)。</br><br>&amp;emsp;2.32位以内的类型只占一个Slot(包括returnAddress类型)，64位的类型(long和double)占用两个Slot。</br><br>&amp;emsp;3.构造方法和实例方法（非static方法）的局部变量表0位Slot会存放this。</li>
</ol>
<ul>
<li><p>操作栈（对局部变量数据进行运算操作）</br><br>&amp;emsp;操作栈：在方法的执行过程中，根据字节码指令，往栈中写入数据或提取数据，即入栈（push）&#x2F;出栈（pop）；主要用于保存计算过程的中间结果，同时作为计算过程中变量临时的存储空间；操作栈是JVM执行引擎的一个工作区； </p>
</li>
<li><p>动态链接（将常量池中的符号引用在运行期转化为直接引用&#x2F;指向运行时常量池的方法引用）</br><br>&amp;emsp;动态链接的作用就是为了将这些符号引用转换为调用方法的直接引用</br><br><img src="https://yh-blog-files.oss-cn-hangzhou.aliyuncs.com/2021/04/26/6.png" alt="6"><br><img src="https://yh-blog-files.oss-cn-hangzhou.aliyuncs.com/2021/04/26/7.png" alt="7"><br><img src="https://yh-blog-files.oss-cn-hangzhou.aliyuncs.com/2021/04/26/8.png" alt="8"><br><img src="https://yh-blog-files.oss-cn-hangzhou.aliyuncs.com/2021/04/26/9.png" alt="9"></p>
</li>
<li><p>返回地址（方法执行完返回地址）</br><br>存放调用该方法的PC寄存器的值。<br>异常退出：异常表</p>
</li>
<li><p>一些附加信息</p>
</li>
<li><p>本地方法栈（native方法[C,C++实现]）<br>  主要为Native方法服务</p>
</li>
<li><p>程序计数器<br>  内存空间小，字节码解释器工作时通过改变这个计数值可以选取下一条需要执行的字节码指令，分支、循环、跳转、异常处理和线程恢复等功能都需要依赖这个计数器完成。该内存区域是唯一一个java虚拟机规范没有规定任何OOM情况的区域。</p>
<p>  线程切换<br>  记录线程执行的当前的地址和行号</p>
</li>
<li><p>堆（-Xms 30m -Xmx 30m -XX:+PrintGCDetails）</br></p>
</li>
</ul>
<figure class="highlight plaintext"><figcaption><span>设置堆空间大小的参数</span></figcaption><table><tr><td class="code"><pre><span class="line"> -Xms 用来设置堆空间（年轻代+老年代）的初始内存大小</span><br><span class="line">      -X 是jvm的运行参数</span><br><span class="line">      ms 是memory start</span><br><span class="line"> -Xmx 用来设置堆空间（年轻代+老年代）的最大内存大小</span><br><span class="line"></span><br><span class="line"> 2. 默认堆空间的大小</span><br><span class="line">    初始内存大小：物理电脑内存大小 / 64</span><br><span class="line">             最大内存大小：物理电脑内存大小 / 4</span><br><span class="line"> 3. 手动设置：-Xms600m -Xmx600m</span><br><span class="line">     开发中建议将初始堆内存和最大的堆内存设置成相同的值。</span><br><span class="line"></span><br><span class="line"> 4. 查看设置的参数：方式一： jps   /  jstat -gc 进程id</span><br><span class="line">                  方式二：-XX:+PrintGCDetails</span><br><span class="line">-XX:+开启 -关闭</span><br><span class="line">-XX:NewRatio ： 设置新生代与老年代的比例。默认值是2.</span><br><span class="line">-XX:SurvivorRatio ：设置新生代中Eden区与Survivor区的比例。默认值是8</span><br><span class="line">-XX:-UseAdaptiveSizePolicy ：关闭自适应的内存分配策略  （暂时用不到）</span><br><span class="line">-Xmn:设置新生代的空间的大小。 （一般不设置）</span><br></pre></td></tr></table></figure>

<p> <strong>初始化的对象，成员变量（那种非static变量），所有的对象实例和数组都要在堆中分配</strong><br><img src="https://img-blog.csdnimg.cn/20200202132002577.png" alt="q"></p>
<p>堆里面的分区：Eden，Survivor(from+to)，老年代。<br>各自的特点：堆里面分为新生代和老年代（java8取消永久代，采用Matespace(元空间)），新生代包含Eden和Survivor区，Survivor分为from+to区。</p>
<ul>
<li><strong>内存回收时，如果用的是复制算法，从from复制到to，当经过一次或者多次GC之后，存活下来的对象会被移入老年区。</strong></li>
<li><strong>当JVM内存不够用的时候，会触发FullGC，清理JVM老年代。</strong></li>
<li><strong>当新生区满了之后会触发YGC，先把存活的对象放到其中一个Survivor区，然后进行垃圾清理。因为如果仅仅清理需要删除的对象，这样会导致内存碎片，因此一般会把Eden进行完全的清理，然后整理内存。那么下次GC 的时候，就会使用下一个Survive，这样循环使用。</strong></li>
<li><strong>如果有特别大的对象，新生代放不下，就会使用老年代的担保，直接放到老年代里面。因为JVM 认为，一般大对象的存活时间一般比较久远。</strong><br><img src="https://yh-blog-files.oss-cn-hangzhou.aliyuncs.com/2021/04/26/10.png" alt="10"><br>对象的分配原则：</br><br>1.对象优先分配在Eden区</br><br>2.长期存活的对象进入老年代。空间不足，进行GC。对象年龄+1，年龄&#x3D;15进入老年代</br><br>&amp;emsp;&amp;emsp;动态对象年龄判断：如果survivor区中相同年龄的所有对象大小的总和大于survivor空间的一半，年龄大于或等于该年龄的对象直接进入老年代，无需等到MaxTenuringThreshole（15）中要求的年龄。</br><br>3.大对象直接进入老年代</br><br>&#x3D;&#x3D;TLAB&#x3D;&#x3D;(Thread Local Allocation Buffer)<br><img src="https://yh-blog-files.oss-cn-hangzhou.aliyuncs.com/2021/04/26/11.png" alt="11"></li>
</ul>
<p><strong>内存不足、内存溢出、内存泄漏</strong></p>
<h4 id="Minor-GC、Major-GC、Full-GC"><a href="#Minor-GC、Major-GC、Full-GC" class="headerlink" title="Minor GC、Major GC、Full GC"></a>Minor GC、Major GC、Full GC</h4><ol>
<li>部分收集：不是完整收集整个java堆的垃圾收集。</li>
</ol>
<ul>
<li>新生代收集（MinorGC&#x2F;YoungGC）:只是新生代的垃圾收集</li>
<li>老年代收集（MajorGC&#x2F;OldGC）：只是老年代的垃圾收集</br><br> &amp;emsp;&amp;emsp;目前，只有CMS GC会有单独收集老年代的行为。</br><br> &amp;emsp;&amp;emsp;&#x3D;&#x3D;注意，很多时候MajorGC会和FullGC混淆使用，需要具体分辨是老年代回收还是整堆回收。&#x3D;&#x3D;</li>
<li>混合收集（MixedGC）：收集整个新生代以及部分老年代的垃圾收集。</br><br> &amp;emsp;&amp;emsp;目前，只有G1 GC会有这种行为。</li>
</ul>
<ol start="2">
<li>整堆收集（Full GC）：收集整个Java堆和方法区的垃圾收集。<h4 id="堆空间常用参数总结"><a href="#堆空间常用参数总结" class="headerlink" title="堆空间常用参数总结"></a>堆空间常用参数总结</h4></li>
</ol>
<figure class="highlight plaintext"><figcaption><span>测试堆空间常用的jvm参数：</span></figcaption><table><tr><td class="code"><pre><span class="line">* -XX:+PrintFlagsInitial : 查看所有的参数的默认初始值</span><br><span class="line">* -XX:+PrintFlagsFinal  ：查看所有的参数的最终值（可能会存在修改，不再是初始值）</span><br><span class="line">*      具体查看某个参数的指令： jps：查看当前运行中的进程</span><br><span class="line">*                             jinfo -flag SurvivorRatio 进程id</span><br><span class="line">*</span><br><span class="line">* -Xms：初始堆空间内存 （默认为物理内存的1/64）</span><br><span class="line">* -Xmx：最大堆空间内存（默认为物理内存的1/4）</span><br><span class="line">* -Xmn：设置新生代的大小。(初始值及最大值)</span><br><span class="line">* -XX:NewRatio：配置新生代与老年代在堆结构的占比</span><br><span class="line">* -XX:SurvivorRatio：设置新生代中Eden和S0/S1空间的比例</span><br><span class="line">* -XX:MaxTenuringThreshold：设置新生代垃圾的最大年龄</span><br><span class="line">* -XX:+PrintGCDetails：输出详细的GC处理日志</span><br><span class="line">* 打印gc简要信息：① -XX:+PrintGC   ② -verbose:gc</span><br><span class="line">* -XX:HandlePromotionFailure：是否设置空间分配担保</span><br></pre></td></tr></table></figure>

<h4 id="堆是分配对象存储的唯一选择吗（逃逸分析技术-XX-DoEscapeAnalysis默认开启）"><a href="#堆是分配对象存储的唯一选择吗（逃逸分析技术-XX-DoEscapeAnalysis默认开启）" class="headerlink" title="堆是分配对象存储的唯一选择吗（逃逸分析技术-XX:+DoEscapeAnalysis默认开启）"></a>堆是分配对象存储的唯一选择吗（逃逸分析技术-XX:+DoEscapeAnalysis默认开启）</h4><p>没有发生逃逸的对象，则可以分配到栈上，随着方法执行结束，栈空间就被移除。<br><img src="https://yh-blog-files.oss-cn-hangzhou.aliyuncs.com/2021/04/26/12.png" alt="12"></p>
<h4 id="逃逸分析：代码优化"><a href="#逃逸分析：代码优化" class="headerlink" title="逃逸分析：代码优化"></a>逃逸分析：代码优化</h4><ol>
<li>栈上分配。</li>
<li>同步省略(锁消除)。</li>
<li>分离对象或标量替换:在JIT阶段，如果经过逃逸分析，发现一个对象不会被外界访问的话，那么经过JIT优化，就会把这个对象拆分成若干个其中包含的若干个成员变量来代替。这个过程就是标量替换。（-XX:+EliminateAllocations默认开启）<br><img src="https://yh-blog-files.oss-cn-hangzhou.aliyuncs.com/2021/04/26/13.png" alt="13"></li>
</ol>
<ul>
<li><h3 id="方法区-1-8元空间"><a href="#方法区-1-8元空间" class="headerlink" title="方法区(1.8元空间)"></a>方法区(1.8元空间)</h3></li>
</ul>
<ol>
<li>1.7及以前称为永久代，在该区内很少发生垃圾回收，但是并不代表不发生GC，在这里进行的GC主要对方法区里的常量池和对类型的卸载。</li>
<li>方法区主要用来储存已被虚拟机加载的类的信息、常量、静态变量和即时编译器编译后的代码等数据。</br></li>
</ol>
<ul>
<li>虚拟机启动过程中，会将各个Class文件中的常量池载入到运行时常量池中。</br></li>
<li>所以， Class常量池只是一个媒介场所。在JVM真的运行时，需要把常量池中的常量加载到内存中，进入到运行时常量池。</br></li>
<li>字符串常量池可以理解为运行时常量池分出来的部分。加载时，对于class的静态常量池，如果字符串会被装到字符串常量池中。</li>
</ul>
<ol start="3">
<li>该区域被线程共享。</li>
<li>方法区里有一个运行时常量池，用于存放静态编译产生的字面量和符号引用。该常量池具有动态性，也就是说常量不一定是编译时确定的，运行时生成的常量也存放在这个常量池。<br><img src="https://yh-blog-files.oss-cn-hangzhou.aliyuncs.com/2021/04/26/14.png" alt="14"></li>
</ol>
<p>方法区的垃圾收集主要回收两部分内容：常量池中废弃的常量和不再使用的类型。<br>永久代为什么要被元空间替代？</br></p>
<ul>
<li>为永久代设置空间大小是很难确定的。</li>
<li>对永久代进行调优是很困难的。<br><img src="https://yh-blog-files.oss-cn-hangzhou.aliyuncs.com/2021/04/26/15.png" alt="15"></li>
</ul>
<p>常量池表（Constant Pool Table）是Class文件中的一部分，用于存放编译期生成的字面量和符号引用，这部分内容将在类加载后存放到方法区的运行时常量池中。</br><br>运行时常量池相对于Class文件常量池的另一个重要特征是：&#x3D;&#x3D;具有动态性。&#x3D;&#x3D;<br><img src="https://yh-blog-files.oss-cn-hangzhou.aliyuncs.com/2021/04/26/16.png" alt="16"></p>
<h2 id="对象的实例化"><a href="#对象的实例化" class="headerlink" title="对象的实例化"></a>对象的实例化</h2><p><img src="https://yh-blog-files.oss-cn-hangzhou.aliyuncs.com/2021/04/26/17.png" alt="17"><br><img src="https://yh-blog-files.oss-cn-hangzhou.aliyuncs.com/2021/04/26/18.png" alt="18"><br><img src="https://yh-blog-files.oss-cn-hangzhou.aliyuncs.com/2021/04/26/19.png" alt="19"><br><img src="https://yh-blog-files.oss-cn-hangzhou.aliyuncs.com/2021/04/26/20.png" alt="20"></p>
<h2 id="直接内存"><a href="#直接内存" class="headerlink" title="直接内存"></a>直接内存</h2><h2 id="垃圾回收系统"><a href="#垃圾回收系统" class="headerlink" title="垃圾回收系统"></a>垃圾回收系统</h2><p> 新生代内存不够用时候发生MGC也叫YGC，JVM内存不够的时候发生FGC</p>
<ul>
<li><h3 id="引用计数法"><a href="#引用计数法" class="headerlink" title="引用计数法"></a>引用计数法</h3></li>
<li><h3 id="可达性分析算法"><a href="#可达性分析算法" class="headerlink" title="可达性分析算法"></a>可达性分析算法</h3><p>   GCroots对象</p>
<ol>
<li>虚拟机栈中引用的对象</li>
<li>方法区类静态属性引用的对象</li>
<li>方法区常量池引用的对象</li>
<li>本地方法栈JNI引用的对象<br>当一个对象不可达GC Root时，这个对象并 不会立马被回收，而是出于一个死缓的阶段，若要被真正的回收需要经历两次标记.<br>如果对象在可达性分析中没有与GC Root的引用链，那么此时就会被第一次标记并且进行一次筛选，筛选的条件是是否有必要执行finalize()方法。当对象没有覆盖finalize()方法或者已被虚拟机调用过，那么就认为是没必要的。<br>如果该对象有必要执行finalize()方法，那么这个对象将会放在一个称为F-Queue的对队列中，虚拟机会触发一个Finalize()线程去执行，此线程是低优先级的，并且虚拟机不会承诺一直等待它运行完，这是因为如果finalize()执行缓慢或者发生了死锁，那么就会造成F-Queue队列一直等待，造成了内存回收系统的崩溃。GC对处于F-Queue中的对象进行第二次被标记，这时，该对象将被移除”即将回收”集合，等待回收。</li>
</ol>
</li>
<li><h3 id="SafePoint"><a href="#SafePoint" class="headerlink" title="SafePoint"></a>SafePoint</h3><p><em><strong>必须要等到Java线程都进入到safepoint的时候VMThread才能开始执行GC</strong></em></p>
</li>
</ul>
<p>safepoint指的特定位置主要有:</p>
<ol>
<li>循环的末尾（防止大循环的时候一直不进入safepoint，而其他线程在等它进入safepoint）</li>
<li>方法返回前</li>
<li>调用方法的call之后</li>
<li>抛出异常的位置</li>
</ol>
<ul>
<li><h3 id="GC算法"><a href="#GC算法" class="headerlink" title="GC算法"></a>GC算法</h3><ol>
<li>标记清除：先标记，标记完毕再清除，效率不高，会产生碎片</li>
<li>复制算法：分为8:1的Eden区和survivor区，YGC</li>
<li>标记整理：标记完毕之后，让所有存活的对象向一端移动，清理另一端</li>
<li>分代收集：现在的虚拟机垃圾收集大多采用这种方式，它根据对象的生存周期，将堆分为新生代和老年代。在新生代中，由于对象生存期短，每次回收都会有大量对象死去，那么这时就采用复制算法。老年代里的对象存活率较高，没有额外的空间进行分配担保，所以可以使用标记-整理 或者 标记-清除。</li>
</ol>
</li>
<li><h3 id="GC收集器"><a href="#GC收集器" class="headerlink" title="GC收集器"></a>GC收集器</h3>  串型收集器：串行收集器使用一个单独的线程进行收集，GC时服务有停顿时间<br>  并行收集器：次要回收中使用多线程执行</li>
</ul>
<ol>
<li>CMS:基于“标记-清除”算法实现的，经过多次标记才会被清除</li>
<li>G1:从整体来看是基于“标记—整理”算法实现的收集器，从局部（两个Region之间）上来看是基于“复制”算法实现的</li>
</ol>
<p>几种常见的内存调试工具：jmap,jstack,jconsole,jhat<br>    jstack可以看当前栈的情况，jmap查看内存，jhat 进行dump堆的信息<br>    mat（eclipse的也要了解一下）</p>
]]></content>
      <categories>
        <category>后端</category>
      </categories>
      <tags>
        <tag>JVM</tag>
      </tags>
  </entry>
  <entry>
    <title>MySQL性能分析工具的使用</title>
    <url>/2022/06/06/MySQL%E6%80%A7%E8%83%BD%E5%88%86%E6%9E%90%E5%B7%A5%E5%85%B7%E7%9A%84%E4%BD%BF%E7%94%A8/</url>
    <content><![CDATA[<p>在数据库调优中，我们的目标就是<strong>响应时间更快，吞吐量更大</strong>。利用宏观的监控工具和微观的日志分析可以帮助我们快速的找到调优的思路和方式。</p>
<h2 id="数据库服务优化步骤"><a href="#数据库服务优化步骤" class="headerlink" title="数据库服务优化步骤"></a>数据库服务优化步骤</h2><p><img src="https://yh-blog-files.oss-cn-hangzhou.aliyuncs.com/2022/06/06/16545259909755.jpg" alt="16545259909755"><br><strong>小结：</strong></p>
<p><img src="https://yh-blog-files.oss-cn-hangzhou.aliyuncs.com/2022/06/07/16546045730301.jpg" alt="16546045730301"></p>
<h2 id="查看系统性能参数"><a href="#查看系统性能参数" class="headerlink" title="查看系统性能参数"></a>查看系统性能参数</h2><p>在MySQL中，可以使用<strong>show status</strong>语句查询一些MySQL数据库服务器的<strong>性能参数</strong>、<strong>执行频率</strong>。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">SHOW [GLOBAL | SESSION] STATUS LIKE &#x27;参数&#x27;</span><br></pre></td></tr></table></figure>
<p>一些常用的性能参数如下：</p>
<ul>
<li>Connections：连接MySQL服务器的次数</li>
<li>Uptime：MySQL服务器的上线时间</li>
<li>Slow_queries：慢查询的次数</li>
<li>Innodb_rows_read：select查询返回的行数</li>
<li>Innodb_rows_inserted：insert操作插入的行数</li>
<li>Innodb_rows_updated：update操作更新的行数</li>
<li>Innodb_rows_deleted：delete操作删除的行数</li>
<li>Com_select：查询操作的次数</li>
<li>Com_insert：插入操作的次数，对于批量插入的insert操作，只累加一次。</li>
<li>Com_update：更新操作的次数</li>
<li>Com_delete：删除操作的次数<h2 id="统计SQL的查询成本：last-query-cost"><a href="#统计SQL的查询成本：last-query-cost" class="headerlink" title="统计SQL的查询成本：last_query_cost"></a>统计SQL的查询成本：last_query_cost</h2>如果想要查看某条SQL语句的查询成本，可以在执行完这条SQL语句之后，通过查询当前会话的last_query_cost变量值来得到当前查询的成本。它通常也是我们<strong>评价一个查询的执行效率</strong>的一个常用指标。这个查询的成本对应的是<strong>SQL语句所需要读取的页的数量</strong>。<h2 id="定位执行慢的SQL：慢查询日志"><a href="#定位执行慢的SQL：慢查询日志" class="headerlink" title="定位执行慢的SQL：慢查询日志"></a>定位执行慢的SQL：慢查询日志</h2>默认情况下，MySQL数据库没有开启慢查询日志，需要手动设置这个参数。如果不是调优的需要的话，一般不建议启动该参数，因为开启慢查询日志或多或少会带来一些性能影响。<h3 id="开启慢查询日志参数"><a href="#开启慢查询日志参数" class="headerlink" title="开启慢查询日志参数"></a>开启慢查询日志参数</h3><h4 id="开启slow-query-log"><a href="#开启slow-query-log" class="headerlink" title="开启slow_query_log"></a>开启slow_query_log</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 查看是否开启</span><br><span class="line">SHOW VARIABLES LIKE &#x27;%slow_query%&#x27;;</span><br><span class="line"># 开启慢查询日志</span><br><span class="line">SET GLOBAL slow_query_log = on;</span><br></pre></td></tr></table></figure>
<h4 id="设置long-query-time"><a href="#设置long-query-time" class="headerlink" title="设置long_query_time"></a>设置long_query_time</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 查看long_query_time</span><br><span class="line">SHOW VARIABLES LIKE &#x27;%long_query_time%&#x27;;</span><br><span class="line"># 修改为1秒</span><br><span class="line">SET SESSION long_query_time = 1;</span><br><span class="line">SET GLOBAL long_query_time = 1;</span><br></pre></td></tr></table></figure>
<h4 id="永久设置"><a href="#永久设置" class="headerlink" title="永久设置"></a>永久设置</h4>配置my.conf<br><img src="https://yh-blog-files.oss-cn-hangzhou.aliyuncs.com/2022/06/07/16546070983974.jpg" alt="16546070983974"><h4 id="慢查询日志分析工具：mysqldumpslow"><a href="#慢查询日志分析工具：mysqldumpslow" class="headerlink" title="慢查询日志分析工具：mysqldumpslow"></a>慢查询日志分析工具：mysqldumpslow</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 取出使用最多的10条慢查询</span><br><span class="line">mysqldumpslow -s c -t 10 /data/mysql/xxx-slow.log</span><br><span class="line"> </span><br><span class="line"># 取出查询时间最慢的3条慢查询 </span><br><span class="line">mysqldumpslow -s t -t 3 /data/mysql/xxx-slow.log</span><br><span class="line"> </span><br><span class="line"># 得到按照时间排序的前10条里面含有左连接的查询语句 </span><br><span class="line">mysqldumpslow -s t -t 10 -g “left join” /data/mysql/xxx-slow.log</span><br><span class="line"> </span><br><span class="line"># 按照扫描行数最多的</span><br><span class="line">mysqldumpslow -s r -t 10 -g &#x27;left join&#x27; /data/mysql/xxx-slow.log</span><br></pre></td></tr></table></figure>
<h2 id="查看SQL执行成本：SHOW-PROFILE"><a href="#查看SQL执行成本：SHOW-PROFILE" class="headerlink" title="查看SQL执行成本：SHOW PROFILE"></a>查看SQL执行成本：SHOW PROFILE</h2>SHOW PROFILE是MySQL提供的可以用来分析当前会话中的SQL都做了什么，执行的资源消耗情况，可用于sql调优的测量。<strong>默认情况下是关闭的</strong>。并保存最近15次的运行结果。<br>我们可以在会话级别开启这个功能<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">SHOW VARIABLES LIKE &#x27;profiling&#x27;;</span><br><span class="line">SET profiling = ON;</span><br></pre></td></tr></table></figure>
查看最近的查询<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">SHOW PROFILES;</span><br></pre></td></tr></table></figure>
查看某一个查询的详细信息<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">SHOW PROFILE ALL FOR QUERY [QUERY_ID];</span><br></pre></td></tr></table></figure>
<img src="https://yh-blog-files.oss-cn-hangzhou.aliyuncs.com/2022/06/07/16546092097996.jpg" alt="16546092097996"></li>
</ul>
<h2 id="分析查询语句：EXPLAIN"><a href="#分析查询语句：EXPLAIN" class="headerlink" title="分析查询语句：EXPLAIN"></a>分析查询语句：EXPLAIN</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">EXPLAIN SELECT|DELETE|UPDATE|INSERT xxxx;</span><br></pre></td></tr></table></figure>
<h3 id="EXPLAIN语句输出的各个列的作用如下："><a href="#EXPLAIN语句输出的各个列的作用如下：" class="headerlink" title="EXPLAIN语句输出的各个列的作用如下："></a>EXPLAIN语句输出的各个列的作用如下：</h3><p><img src="https://yh-blog-files.oss-cn-hangzhou.aliyuncs.com/2022/06/07/16546100275416.jpg" alt="16546100275416"></p>
<h2 id="EXPLAIN的进一步使用"><a href="#EXPLAIN的进一步使用" class="headerlink" title="EXPLAIN的进一步使用"></a>EXPLAIN的进一步使用</h2><h3 id="EXPLAIN四种输出格式"><a href="#EXPLAIN四种输出格式" class="headerlink" title="EXPLAIN四种输出格式"></a>EXPLAIN四种输出格式</h3><h4 id="传统格式"><a href="#传统格式" class="headerlink" title="传统格式"></a>传统格式</h4><p>传统格式输出一个表格形式，概要说明查询计划。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">EXPLAIN xxxxxx</span><br></pre></td></tr></table></figure>
<h4 id="JSON格式"><a href="#JSON格式" class="headerlink" title="JSON格式"></a>JSON格式</h4><p>第一种格式中介绍的EXPLAIN语句输出中缺少了一个衡量执行计划好坏的重要属性 – <strong>成本</strong>。而JSON格式是四种格式中输出<strong>信息最详尽</strong>的格式，里面包含了执行的成本信息。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">EXPLAIN FORMAT=JSON xxxxx</span><br></pre></td></tr></table></figure>
<p>EXPLAIN的Column与JSON的对应关系：（来源于Mysql5.7文档）<br><img src="https://yh-blog-files.oss-cn-hangzhou.aliyuncs.com/2022/06/14/16552108538058.jpg" alt="16552108538058"></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  &quot;query_block&quot;: &#123;</span><br><span class="line">    &quot;select_id&quot;: 1,</span><br><span class="line">    &quot;cost_info&quot;: &#123;</span><br><span class="line">      &quot;query_cost&quot;: &quot;3.83&quot;</span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;table&quot;: &#123;</span><br><span class="line">      &quot;table_name&quot;: &quot;sys_user&quot;,</span><br><span class="line">      &quot;access_type&quot;: &quot;range&quot;,</span><br><span class="line">      &quot;possible_keys&quot;: [</span><br><span class="line">        &quot;PRIMARY&quot;</span><br><span class="line">      ],</span><br><span class="line">      &quot;key&quot;: &quot;PRIMARY&quot;,</span><br><span class="line">      &quot;used_key_parts&quot;: [</span><br><span class="line">        &quot;id&quot;</span><br><span class="line">      ],</span><br><span class="line">      &quot;key_length&quot;: &quot;4&quot;,</span><br><span class="line">      &quot;rows_examined_per_scan&quot;: 7,</span><br><span class="line">      &quot;rows_produced_per_join&quot;: 7,</span><br><span class="line">      &quot;filtered&quot;: &quot;100.00&quot;,</span><br><span class="line">      &quot;cost_info&quot;: &#123;</span><br><span class="line">        &quot;read_cost&quot;: &quot;2.43&quot;,</span><br><span class="line">        &quot;eval_cost&quot;: &quot;1.40&quot;,</span><br><span class="line">        &quot;prefix_cost&quot;: &quot;3.83&quot;,</span><br><span class="line">        &quot;data_read_per_join&quot;: &quot;80K&quot;</span><br><span class="line">      &#125;,</span><br><span class="line">      &quot;used_columns&quot;: [</span><br><span class="line">        &quot;id&quot;,</span><br><span class="line">        &quot;login_name&quot;,</span><br><span class="line">        &quot;password&quot;,</span><br><span class="line">        ...</span><br><span class="line">      ],</span><br><span class="line">      &quot;attached_condition&quot;: &quot;(`sys_user`.`id` &gt; 1)&quot;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4 id="TREE格式"><a href="#TREE格式" class="headerlink" title="TREE格式"></a>TREE格式</h4><p>tree格式是8.0.16版本之后引入的新格式，主要根据查询的<strong>各个部分之间的关系</strong>和<strong>各部分的执行顺序</strong>来描述如何查询。<br><img src="https://yh-blog-files.oss-cn-hangzhou.aliyuncs.com/2022/06/14/16552115947740.jpg" alt="16552115947740"></p>
<h4 id="可视化输出"><a href="#可视化输出" class="headerlink" title="可视化输出"></a>可视化输出</h4><h3 id="SHOW-WARNINGS的使用"><a href="#SHOW-WARNINGS的使用" class="headerlink" title="SHOW WARNINGS的使用"></a>SHOW WARNINGS的使用</h3><p>在使用了EXPLAIN语句查看了某个查询的执行计划后，紧跟着还可以使用SHOW WARNINGS语句查看与这个查询的执行计划有关的一些扩展信息。</p>
<h2 id="分析优化器执行计划：trace"><a href="#分析优化器执行计划：trace" class="headerlink" title="分析优化器执行计划：trace"></a>分析优化器执行计划：trace</h2><p>OPTIMIZED_TRACE是MySQL5.6引入的一项跟踪功能，他可以跟踪优化器做出的各种决策（比如访问表的方法、各种开销计算、各种转换等），并将跟踪结果记录到<strong>INFORMATION_SCHEMA.OPTIMIZER_TACE</strong>表中。<br>此功能默认是关闭的。开启trace，并设置格式为JSON，同时设置trace最大能够使用的内存的大小，避免解析过程中因为默认内存大小而不能够完整展示。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">SET optimizer_trace=&quot;enable=on&quot;,end_markers_in_json=on;</span><br><span class="line">SET optimizer_trace_max_mem_size=1000000;</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">select xxxxxx;</span><br><span class="line"></span><br><span class="line">SELECT * FROM information_schema.OPTIMIZER_TRACE;</span><br></pre></td></tr></table></figure>
<h2 id="MySQL监控分析视图：sys-schema"><a href="#MySQL监控分析视图：sys-schema" class="headerlink" title="MySQL监控分析视图：sys schema"></a>MySQL监控分析视图：sys schema</h2><h3 id="索引情况"><a href="#索引情况" class="headerlink" title="索引情况"></a>索引情况</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 1.查询冗余的索引</span><br><span class="line">SELECT * FROM sys.schema_redundant_indexes;</span><br><span class="line"># 2.查询未使用过的索引</span><br><span class="line">SELECT * FROM sys.schema_unused_indexes;</span><br><span class="line"># 3.查询索引的使用情况</span><br><span class="line">SELECT * FROM sys.schema_index_statistics WHERE table_schema=&#x27;dbname&#x27;;</span><br></pre></td></tr></table></figure>
<h3 id="表相关"><a href="#表相关" class="headerlink" title="表相关"></a>表相关</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 4.查询表的访问量</span><br><span class="line">SELECT table_schema,table_name,SUM(io_read_requests+io_write_requests) AS io FROM sys.schema_table_statistics GROUP BY table_schema,table_name ORDER BY io desc;</span><br><span class="line"># 5.查询占用buffer pool较多的表</span><br><span class="line">SELECT object_schema,object_name,allocated,data FROM sys.innodb_buffer_stats_by_table ORDER BY allocated LIMIT 10;</span><br><span class="line"># 6.查看表的全表扫描情况</span><br><span class="line">SELECT * FROM sys.statements_with_full_table_scans WHERE db=&#x27;dbname&#x27;;</span><br></pre></td></tr></table></figure>
<h3 id="语句相关"><a href="#语句相关" class="headerlink" title="语句相关"></a>语句相关</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 7.监控SQL执行的频率</span><br><span class="line">SELECT db,exec_count,query FROM sys.statement_analysis ORDER BY exec_count desc;</span><br><span class="line"># 8.监控使用了排序的SQL</span><br><span class="line">SELECT db,exec_count,first_seen,last_seen,query FROM sys.statements_with_sorting LIMIT 1;</span><br><span class="line"># 9.监控使用了临时表或者磁盘临时表的SQL</span><br><span class="line">SELECT db,exec_count,tmp_tables,tmp_disk_tables,query FROM sys.statement_analysis WHERE tmp_tables&gt;0 OR tmp_disk_tables &gt; 0 ORDER BY (tmp_tables+tmp_disk_tables) DESC;</span><br></pre></td></tr></table></figure>
<h3 id="IO相关"><a href="#IO相关" class="headerlink" title="IO相关"></a>IO相关</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 10.查看消耗的磁盘IO文件</span><br><span class="line">SELECT file,avg_read,avg_write,avg_read+avg_write as avg_io FROM sys.io_global_by_file_by_bytes ORDER BY avg_read limit 10;</span><br></pre></td></tr></table></figure>
<h3 id="innodb相关"><a href="#innodb相关" class="headerlink" title="innodb相关"></a>innodb相关</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">SELECT * FROM sys.innodb_lock_waits;</span><br></pre></td></tr></table></figure>
<blockquote>
<p><strong>风险提示：</strong><br>通过sys库去查询时，MySQL会消耗大量资源去收集相关信息，严重的可能会导致业务请求被阻塞，从而引起故障。建议生产环境不要频繁去查询sys或performance_schema、information_schema来完成监控、巡检等工作。</p>
</blockquote>
]]></content>
      <categories>
        <category>后端</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title>MySQL</title>
    <url>/2021/07/31/MySQL/</url>
    <content><![CDATA[<h1 id="事务"><a href="#事务" class="headerlink" title="事务"></a><strong>事务</strong></h1><h2 id="概念"><a href="#概念" class="headerlink" title="概念"></a><strong>概念</strong></h2><pre><code>一个数据库事务通常包含对数据库进行读或写的一个操作序列。它的存在包含有以下两个目的：
    1. 为数据库操作提供了一个从失败中恢复到正常状态的方法，同时提供了数据库即使在异常状态下仍能保持一致性的方法。
    2. 当多个应用程序在并发访问数据库时，可以在这些应用程序之间提供一个隔离方法，以防止彼此的操作互相干扰。
</code></pre>
<span id="more"></span>
<h2 id="特性"><a href="#特性" class="headerlink" title="特性"></a><strong>特性</strong></h2><ul>
<li>原子性（<strong>Atomicity）</strong>：事务作为一个整体被执行，包含在其中的对数据库的操作要么全部被执行，要么都不执行。</li>
<li>一致性<strong>（Consistency）</strong>：事务应确保数据库的状态从一个一致状态转变为另一个一致状态。一致状态的含义是数据库中的数据应满足完整性约束。</li>
<li>隔离性<strong>（Isolation）</strong>：多个事务并发执行时，一个事务的执行不应影响其他事务的执行。</li>
<li>持久性<strong>（Durability）</strong>：一个事务一旦提交，他对数据库的修改应该永久保存在数据库中。</li>
</ul>
<h2 id="数据库的读现象浅析"><a href="#数据库的读现象浅析" class="headerlink" title="数据库的读现象浅析"></a><strong>数据库的读现象浅析</strong></h2><pre><code>&quot;读现象&quot;是多个事务并发执行时，在读取数据方面可能碰到的状况。
</code></pre>
<p><img src="https://yh-blog-files.oss-cn-hangzhou.aliyuncs.com/2021/08/01/16278197683280.jpg"></p>
<h3 id="脏读"><a href="#脏读" class="headerlink" title="脏读"></a>脏读</h3><p>脏读又称无效数据的读出，是指在数据库访问中，事务T1将某一值修改，然后事务T2读取该值，此后T1因为某种原因撤销对该值的修改，这就导致了T2所读取到的数据是无效的。</p>
<p>事务一读取到事务二未提交数据。</p>
<p><img src="https://yh-blog-files.oss-cn-hangzhou.aliyuncs.com/2021/08/01/16278197917060.jpg"></p>
<h3 id="不可重复读"><a href="#不可重复读" class="headerlink" title="不可重复读"></a>不可重复读</h3><p>在一个事务内，多次读同一个数据。在这个事务还没有结束时，另一个事务也访问该同一数据。那么，在第一个事务的两次读数据之间。由于第二个事务的修改，那么第一个事务读到的数据可能不一样，这样就发生了在一个事务内两次读到的数据是不一样的，因此称为不可重复读，即原始读取不可重复。</p>
<p>在事务二提交之前，事务一不可重复读。</p>
<p><img src="https://yh-blog-files.oss-cn-hangzhou.aliyuncs.com/2021/08/01/16278198089221.jpg"></p>
<h3 id="幻读"><a href="#幻读" class="headerlink" title="幻读"></a>幻读</h3><p>第一个事务对一个表中的数据进行了修改，比如这种修改涉及到表中的”全部数据行”。同时，第二个事务也修改这个表中的数据，这种修改是向表中插入”一行新数据”。那么，以后就会发生操作第一个事务的用户发现表中还有没有修改的数据行，就好象发生了幻觉一样.一般解决幻读的方法是增加范围锁RangeS，锁定检锁范围为只读，这样就避免了幻读。</p>
<p>返回数据变多，幻读。</p>
<p><img src="https://yh-blog-files.oss-cn-hangzhou.aliyuncs.com/2021/08/01/16278198223940.jpg"></p>
<p>“幻读(phantom read)”是不可重复读(Non-repeatablereads)的一种特殊场景：当事务没有获取范围锁的情况下执行SELECT ... WHERE操作可能会发生”幻影读(phantom read)”。</p>
<h1 id="Mysql中的行级锁、表级锁、页级锁"><a href="#Mysql中的行级锁、表级锁、页级锁" class="headerlink" title="Mysql中的行级锁、表级锁、页级锁"></a><strong>Mysql中的行级锁、表级锁、页级锁</strong></h1><h2 id="行级锁"><a href="#行级锁" class="headerlink" title="行级锁"></a><strong>行级锁</strong></h2><p>行级锁是Mysql中锁粒度最细的锁，表示只针对当前操作的行为加锁。行级锁能大大减少数据库操作的冲突。其加锁粒度最小，但加锁的开销也最大。行级锁分为共享锁和排他锁。</p>
<p>特点：开销大，加锁慢；会出现死锁；锁粒度最小，发生锁冲突的概率最低，并发度也最高。</p>
<p>Innodb默认使用行级锁</p>
<ul>
<li>读锁（read lock）：也叫共享锁（shared lock），允许一个事务去读一行，阻止其他事务获得相同数据集的排他锁</li>
<li>写锁（write lock）：也叫排他锁（exclusive lock），允许获得排他锁的事务更新数据，阻止其他事务取得相同数据集的共享锁和排他锁</li>
</ul>
<h3 id="行锁的实现算法"><a href="#行锁的实现算法" class="headerlink" title="行锁的实现算法"></a><strong>行锁的实现算法</strong></h3><ol>
<li><p><strong>Record Lock 锁</strong></p>
<p>单个行记录上的锁Record<br>Lock总是会去锁住索引记录，如果InnoDB存储引擎表建立的时候没有设置任何一个索引，这时InnoDB存储引擎会使用隐式的主键来进行锁定</p>
</li>
<li><p><strong>Gap Lock 锁</strong></p>
<p> 当我们用范围条件而不是相等条件检索数据，并请求共享或排他锁时，InnoDB会给符合条件的已有数据记录的索引加锁，对于键值在条件范围内但并不存在的记录。<br> 优点：解决了事务并发的幻读问题不足：因为query执行过程中通过范围查找的话，他会锁定争个范围内所有的索引键值，即使这个键值并不存在。<br> 间隙锁有一个致命的弱点，就是当锁定一个范围键值之后，即使某些不存在的键值也会被无辜的锁定，而造成锁定的时候无法插入锁定键值范围内任何数据。在某些场景下这可能会对性能造成很大的危害。</p>
</li>
<li><p><strong>Next-key Lock 锁</strong></p>
<p> 同时锁住数据+间隙锁(1+2),在Repeatable Read隔离级别下，Next-key Lock</p>
</li>
</ol>
<p>算法是默认的行记录锁定算法。</p>
<h2 id="表级锁"><a href="#表级锁" class="headerlink" title="表级锁"></a><strong>表级锁</strong></h2><p>表级锁是MySQL中锁定粒度最大的一种锁，表示对当前操作的整张表加锁，它实现简单，资源消耗较少，被大部分MySQL引擎支持。最常使用的MYISAM与INNODB都支持表级锁定。表级锁定分为<strong>表共享读锁（共享锁）</strong>与<strong>表独占写锁（排他锁）</strong>。</p>
<p>特点：开销小，加锁快；不会出现死锁；锁定粒度大，发出锁冲突的概率最高，并发度最低。</p>
<p>MyISAM默认使用表级锁</p>
<ul>
<li><p>读锁（read lock），也叫共享锁（shared lock）针对同一份数据，多个读操作可以同时进行而不会互相影响（select）</p>
</li>
<li><p>写锁（write lock），也叫排他锁（exclusive lock）当前操作没完成之前，会阻塞其它读和写操作（update、insert、delete）</p>
</li>
<li><p>意向共享锁（IS）：一个事务给一个数据行加共享锁时，必须先获得表的IS锁</p>
</li>
<li><p>意向排它锁（IX）：一个事务给一个数据行加排他锁时，必须先获得该表的IX锁</p>
</li>
</ul>
<p><img src="https://yh-blog-files.oss-cn-hangzhou.aliyuncs.com/2021/08/01/16278200896050.jpg"></p>
<p>读锁会阻塞写，但不会阻塞读。而写锁则会把读和写都阻塞。</p>
<h3 id="表锁分析："><a href="#表锁分析：" class="headerlink" title="表锁分析："></a><strong>表锁分析：</strong></h3><p>查看哪些表被锁了：show open tables;</p>
<p>分析表锁定：show status like &#39;table%&#39;;</p>
<p><img src="https://yh-blog-files.oss-cn-hangzhou.aliyuncs.com/2021/08/01/16278201278425.jpg"></p>
<h2 id="页锁"><a href="#页锁" class="headerlink" title="页锁"></a><strong>页锁</strong></h2><p>开销和加锁时间介于行锁和表锁之间，会出现死锁，锁定粒度介于行锁和表锁之间，并发度一般。</p>
<h2 id="Innodb中的行锁与表锁"><a href="#Innodb中的行锁与表锁" class="headerlink" title="Innodb中的行锁与表锁"></a><strong>Innodb中的行锁与表锁</strong></h2><p>InnoDB行锁是通过给索引上的索引项加锁来实现的，所以只有通过索引条件检索数据，InnoDB才使用行级锁，否则，InnoDB将使用表锁！(索引失效，行锁变表锁)</p>
<p>当两个事务同时执行，一个锁住了主键索引在等待其他相关索引，一个锁定了非主键索引，在等待主键索引。这样就会发生死锁。</p>
<p>发生死锁后，InnoDB一般都可以检测到，并使一个事务释放锁回退，另一个获取锁完成事务。</p>
<p><strong>有多种方法可以避免死锁，这里只介绍常见的三种</strong></p>
<pre><code>1. 如果不同程序会并发存取多个表，尽量约定以相同的顺序访问表，可以大大降低死锁机会。

2. 在同一个事务中，尽可能做到一次锁定所需要的所有资源，减少死锁产生概率；

3. 对于非常容易产生死锁的业务部分，可以尝试使用升级锁定颗粒度，通过表级锁定来减少死锁产生的概率；
</code></pre>
<h2 id="MySQL中的共享锁与排他锁"><a href="#MySQL中的共享锁与排他锁" class="headerlink" title="MySQL中的共享锁与排他锁"></a><strong>MySQL中的共享锁与排他锁</strong></h2><h3 id="共享锁-Share-Lock"><a href="#共享锁-Share-Lock" class="headerlink" title="共享锁(Share Lock)"></a><strong>共享锁(Share Lock)</strong></h3><p>共享锁又称为读锁，是读取操作创建的锁。其他用户可以并发读取数据，但任何事物都不能对数据进行修改，直到已释放所有共享锁。</p>
<ul>
<li>显式加锁 锁行：SELECT ... LOCK IN SHARE MODE; 锁表：LOCK TABLE XXX READ;(解锁UNLOCK TABLES)</li>
</ul>
<h3 id="排他锁（Exclusive-Lock）"><a href="#排他锁（Exclusive-Lock）" class="headerlink" title="排他锁（Exclusive Lock）"></a><strong>排他锁（Exclusive Lock）</strong></h3><p>排他锁又称写锁，如果事务T对数据A加上排他锁后，则其他事务不能再对A加任任何类型的读写。获准排他锁的事务既能读数据，又能修改数据。</p>
<ul>
<li>显式加锁 锁行：SELECT ... FOR UPDATE; 锁表：LOCK TABLE XXX WRITE;(解锁UNLOCK TABLES)</li>
</ul>
<h2 id="InnoDB的间隙锁："><a href="#InnoDB的间隙锁：" class="headerlink" title="InnoDB的间隙锁："></a><strong>InnoDB的间隙锁：</strong></h2><ul>
<li>当我们用范围条件而不是相等条件检索数据，并请求共享或排他锁时，InnoDB会给符合条件的已有数据记录的索引项加锁；对于键值在条件范围内但并不存在的记录，叫做”间隙（GAP)”，InnoDB也会对这个”间隙”加锁，这种锁机制就是所谓的间隙锁（Next-Key锁）。</li>
</ul>
<p><img src="https://yh-blog-files.oss-cn-hangzhou.aliyuncs.com/2021/08/01/16278202632410.jpg"></p>
<h2 id="深入理解乐观锁与悲观锁"><a href="#深入理解乐观锁与悲观锁" class="headerlink" title="深入理解乐观锁与悲观锁"></a><strong>深入理解乐观锁与悲观锁</strong></h2><pre><code>乐观并发控制(乐观锁)和悲观并发控制（悲观锁）是并发控制主要采用的技术手段。
</code></pre>
<h3 id="悲观锁"><a href="#悲观锁" class="headerlink" title="悲观锁"></a><strong>悲观锁</strong></h3><p>通过开启排他锁的方式实现了悲观锁</p>
<h3 id="乐观锁"><a href="#乐观锁" class="headerlink" title="乐观锁"></a><strong>乐观锁</strong></h3><p>实现数据版本有两种方式，第一种是使用版本号，第二种是使用时间戳。</p>
<h2 id="深入分析事务的隔离级别"><a href="#深入分析事务的隔离级别" class="headerlink" title="深入分析事务的隔离级别"></a><strong>深入分析事务的隔离级别</strong></h2><h3 id="未提交读-Read-uncommitted"><a href="#未提交读-Read-uncommitted" class="headerlink" title="未提交读(Read uncommitted)"></a><strong>未提交读(Read uncommitted)</strong></h3><p>读未提交是最低级的隔离级别。在这种事物隔离级别下，一个事务可以读到另一个事务未提交数据。</p>
<h3 id="未提交读会导致脏读"><a href="#未提交读会导致脏读" class="headerlink" title="未提交读会导致脏读"></a><strong>未提交读会导致脏读</strong></h3><p>未提交读的数据库锁情况（实现原理） 事务在读数据的时候并未对数据加锁。<br>事务在修改数据的时候只对数据增加行级共享锁。</p>
<h3 id="提交读-Read-committed"><a href="#提交读-Read-committed" class="headerlink" title="提交读(Read committed)"></a><strong>提交读(Read committed)</strong></h3><p>在一个事务修改数据过程中，如果事务还没提交，其他事务不能读该数据。</p>
<p><strong>提交读不能解决不可重复读的读现象（重复读数据会变化）</strong></p>
<p><strong>提交读的数据库锁情况</strong> 事务对当前被读取的数据加行级共享锁（当读到时才加锁），一旦读完该行，立即释放该行级共享锁；<br>事务在更新某数据的瞬间（就是发生更新的瞬间），必须先对其加行级排他锁，直到事务结束才释放。</p>
<h3 id="可重复读-Repeatable-reads"><a href="#可重复读-Repeatable-reads" class="headerlink" title="可重复读(Repeatable reads)"></a><strong>可重复读(Repeatable reads)</strong></h3><p>这种隔离级别就叫可重复读（mysql默认隔离级别）</p>
<p><strong>可重复读不能解决幻读</strong></p>
<h4 id="MySQL如何解决幻读？"><a href="#MySQL如何解决幻读？" class="headerlink" title="MySQL如何解决幻读？"></a><strong>MySQL如何解决幻读？</strong></h4><p>SERIALIZABLE 串行化</p>
<p>MVCC + Next-Key Lock</p>
<p><strong>可重复读的数据库锁情况</strong><br>事务在读取某数据的瞬间（就是开始读取的瞬间），必须先对其加行级共享锁，直到事务结束才释放；<br>事务在更新某数据的瞬间（就是发生更新的瞬间），必须先对其加行级排他锁，直到事务结束才释放。</p>
<h3 id="可序列化-Serializable"><a href="#可序列化-Serializable" class="headerlink" title="可序列化(Serializable)"></a><strong>可序列化(Serializable)</strong></h3><p>可序列化(Serializable)是最高的隔离级别，前面提到的所有的隔离级别都无法解决的幻读，在可序列化的隔离级别中可以解决。</p>
<p><strong>可序列化的数据库锁情况</strong><br>事务在读取数据时，必须先对其加 表级共享锁，直到事务结束才释放； 事务在更新数据时，必须先对其加 表级排他锁，直到事务结束才释放。</p>
<h1 id="MySQL性能优化"><a href="#MySQL性能优化" class="headerlink" title="MySQL性能优化"></a><strong>MySQL性能优化</strong></h1><p><img src="https://yh-blog-files.oss-cn-hangzhou.aliyuncs.com/2021/08/01/16278204036880.jpg"></p>
<h2 id="单条SQL运行慢"><a href="#单条SQL运行慢" class="headerlink" title="单条SQL运行慢"></a><strong>单条SQL运行慢</strong></h2><h3 id="创建并正确使用索引"><a href="#创建并正确使用索引" class="headerlink" title="创建并正确使用索引"></a>创建并正确使用索引</h3><h3 id="数据拆分"><a href="#数据拆分" class="headerlink" title="数据拆分"></a>数据拆分</h3><ol>
<li><p>垂直拆分：常用字段、不常用字段拆分</p>
</li>
<li><p>水平拆分：一张表的数据拆分成多张表存放</p>
</li>
</ol>
<h2 id="部分SQL运行慢"><a href="#部分SQL运行慢" class="headerlink" title="部分SQL运行慢"></a><strong>部分SQL运行慢</strong></h2><h3 id="慢查询分析：开启慢查询日志，分析日志进行优化"><a href="#慢查询分析：开启慢查询日志，分析日志进行优化" class="headerlink" title="慢查询分析：开启慢查询日志，分析日志进行优化"></a><strong>慢查询分析：开启慢查询日志，分析日志进行优化</strong></h3><ul>
<li>查询是否开启慢查询日志 SHOW VARIABLES LIKE &quot;%slow_query_log%&quot;;</li>
<li>开启慢查询日志(重启失效) SET GLOBAL slow_query_log&#x3D;1;</li>
<li>查询慢查询时间阈值 show VARIABLES LIKE &quot;%long_query_time%&quot;;</li>
<li>设置慢查询时间阈值(重启失效，需要重新开启一个会话才生效) SET GLOBAL long_query_time&#x3D;3; </li>
<li>慢查询次数 show GLOBAL STATUS LIKE &#39;%Slow_queries%&#39;;</li>
</ul>
<h3 id="使用mysqldumpslow做日志分析："><a href="#使用mysqldumpslow做日志分析：" class="headerlink" title="使用mysqldumpslow做日志分析："></a><strong>使用mysqldumpslow做日志分析：</strong></h3><ul>
<li><p>s：是表示按照何种顺序排序</p>
</li>
<li><p>c：访问次数</p>
</li>
<li><p>l：锁定时间</p>
</li>
<li><p>r：返回记录</p>
</li>
<li><p>t：查询时间</p>
</li>
<li><p>al：平均锁定时间</p>
</li>
<li><p>ar：平均返回记录数</p>
</li>
<li><p>at：平均查询时间</p>
</li>
<li><p>t：即为返回前面多少条数据</p>
</li>
<li><p>g：后边搭配正则表达式，大小写不敏感</p>
<ol>
<li>得到返回记录集最多的10个SQL mysqldumpslow -s r -t 10 &#x2F;var&#x2F;lib&#x2F;mysql&#x2F;xxx-slow.log </li>
<li>得到访问次数最多的10个SQL mysqldumpslow -s c -t 10 &#x2F;var&#x2F;lib&#x2F;mysql&#x2F;xxx-slow.log</li>
<li>得到按照时间排序的前10条里面含有左连接的查询语句 mysqldumpslow -s t -t 10 -g &quot;left join&quot; &#x2F;var&#x2F;lib&#x2F;mysql&#x2F;xxx-slow.log</li>
<li>另外建议在使用这些命令时结合 | more使用，避免有太多数据 mysqldumpslow -s r -t 10 &#x2F;var&#x2F;lib&#x2F;mysql&#x2F;xxx-slow.log | more</li>
</ol>
</li>
</ul>
<h3 id="使用show-profile分析SQL："><a href="#使用show-profile分析SQL：" class="headerlink" title="使用show profile分析SQL："></a><strong>使用show profile分析SQL：</strong></h3><ul>
<li>查询是否开启 SHOW VARIABLES LIKE &#39;profiling&#39;; #开启 SET profiling&#x3D;on;</li>
<li>查询最近执行sql语句(查询) show PROFILES; #查询某一条sql执行过程 show PROFILE cpu,block io for query 26;</li>
</ul>
<h3 id="全局日志查询："><a href="#全局日志查询：" class="headerlink" title="全局日志查询："></a><strong>全局日志查询：</strong></h3><pre><code>开启全局日志 SET GLOBAL general_log=1; 
记录在表中 SET GLOBAL log_output=\&#39;TABLE\&#39;; 
查询日志 SELECT \* FROM mysql.general_log;
</code></pre>
<h2 id="整个SQL运行慢"><a href="#整个SQL运行慢" class="headerlink" title="整个SQL运行慢"></a><strong>整个SQL运行慢</strong></h2><h3 id="读写分离："><a href="#读写分离：" class="headerlink" title="读写分离："></a><strong>读写分离</strong>：</h3><ol>
<li><p>应用层解决方案：通过应用层对数据源做路由来实现读写分离。</p>
</li>
<li><p>中间件解决方案：通过 MySQL 的中间件做主从集群。</p>
</li>
</ol>
<h3 id="EXPLAIN命令："><a href="#EXPLAIN命令：" class="headerlink" title="EXPLAIN命令："></a><strong>EXPLAIN命令：</strong></h3><p><img src="https://yh-blog-files.oss-cn-hangzhou.aliyuncs.com/2021/08/01/16278230182764.jpg"></p>
<ul>
<li><p><strong>id：相同按顺序执行，不同id越大优先级越高，越先执行</strong></p>
</li>
<li><p><strong>select_type:</strong></p>
<ul>
<li><p><strong>SIMPLE：简单的select查询，查询中不包含子查询或者union</strong></p>
</li>
<li><p><strong>PRIMARY：查询中若包含任何复杂的子部分，最外层查询则被标记为PRIMARY</strong></p>
</li>
<li><p><strong>SUBQUERY：在select或where列表中包含了子查询</strong></p>
</li>
<li><p><strong>DERIVED：在from列表中包含子查询被标记为derived（衍生），MySQL会递归执行这些子查询，把结果放在临时表中</strong></p>
</li>
<li><p><strong>UNION：使用了UNION，第二个select则被标记为UNION，若UNION包含在FROM子查询中，外层SELECT将被标记为：DERIVED</strong></p>
</li>
<li><p><strong>UNION RESULT：使用UNION获取结果的查询</strong></p>
</li>
</ul>
</li>
</ul>
<p><img src="https://yh-blog-files.oss-cn-hangzhou.aliyuncs.com/2021/08/01/16278230552996.jpg"></p>
<p><img src="https://yh-blog-files.oss-cn-hangzhou.aliyuncs.com/2021/08/01/16278230650553.jpg"></p>
<ul>
<li><p><strong>table：表名</strong></p>
</li>
<li><p><strong>partitions：表分区</strong></p>
</li>
<li><p><strong>type：表示查询类型，从最好到最差：system&gt;const&gt;eq_ref&gt;ref&gt;range&gt;index&gt;ALL</strong></p>
<ul>
<li><p><strong>system：表示只有一行记录（等于系统表），这是const类型的特例，平时不会出现，这个可以忽略不计</strong></p>
</li>
<li><p><strong>const：表示通过索引一次就找到了，const出现在primary key或者unique索引，因为只匹配一条数据，所以很快，如将主键置于WHERE条件中查询，MYSQL就能将改查询转换为一个常量</strong></p>
</li>
<li><p><strong>eq_ref：唯一性索引扫描，常见于主键或唯一索引扫描</strong></p>
</li>
<li><p><strong>ref：非唯一性索引扫描，返回匹配某个单独值的所有行</strong></p>
</li>
<li><p><strong>range：检索指定范围的行，使用一个索引来选择行。key列显示使用了哪个索引，一般出现在where中使用between,&lt;,&gt;,in等范围查询</strong></p>
</li>
<li><p><strong>index：全索引扫描，index和all的区别为index类型只遍历索引树。这通常比all快，因为索引文件通常比数据文件小。</strong></p>
</li>
<li><p><strong>all：全表扫描，性能最差</strong></p>
</li>
</ul>
</li>
<li><p><strong>possible_key：可能使用的索引</strong></p>
</li>
<li><p><strong>key：实际使用的索引，查询中若使用了覆盖索引，则该索引仅出现在key列表中。（覆盖索引：查询的是索引字段）</strong></p>
</li>
<li><p><strong>key_len：表示索引中使用的字节数，长度越短越好</strong></p>
</li>
<li><p><strong>ref：显示索引的哪一列被使用了，列与索引的比较</strong></p>
</li>
<li><p><strong>rows：根据表统计信息及索引选用情况，大致估算出找到所需的记录所需要读取的行数</strong></p>
</li>
<li><p><strong>Extra：额外信息</strong></p>
<ul>
<li><p><strong>Using filesort：说明mysql会对数据使用一个外部的索引排序，而不是按照表内的索引顺序进行读取。MYSQL中无法利用索引完成的排序操作称为”文件排序”。</strong></p>
</li>
<li><p>**Using temporary：使用了临时表保存中间结果，MySQL在对查询结果排序时使用临时表。常见于排序order</p>
</li>
</ul>
</li>
</ul>
<p>by和分组查询group by**</p>
<pre><code>* **Using Index：表示相应的select操作中使用了覆盖索引（Covering Index），避免访问了表的数据行，效率不错,如果同时出现了using where，表明索引被用来执行索引键值查找。如果没有同时出现using where，表明索引用来读取数据而非执行查找动作。**

* **Using where：使用where子句**

* **Using join buffer： 使用了连接缓存**

* **Using impossible where：表示where子句总是false，查询不到任何数据**

* **select tables optimized away：在没有group by子句的情况下基于索引优化MIN/MAX；对于MYISAM储存引擎优化COUNT(\*)操作，不必等到执行阶段再计算，查询执行计划生成的阶段即完成优化。**

* **distinct：优化distinct操作，在找到第一匹配的元组后即停止查找同样值的动作**
</code></pre>
<p><img src="https://yh-blog-files.oss-cn-hangzhou.aliyuncs.com/2021/08/01/16278232895825.jpg"></p>
<h1 id="高频面试题"><a href="#高频面试题" class="headerlink" title="高频面试题"></a><strong>高频面试题</strong></h1><h2 id="什么是索引"><a href="#什么是索引" class="headerlink" title="什么是索引"></a><strong>什么是索引</strong></h2><p>索引是一种数据结构，可以帮助我们快速进行数据查找。</p>
<h2 id="索引是个什么样的数据结构"><a href="#索引是个什么样的数据结构" class="headerlink" title="索引是个什么样的数据结构"></a><strong>索引是个什么样的数据结构</strong></h2><p>索引的数据结构和具有储存引擎的实现有关，在MySQL中使用较多的索引有Hash索引，B+树索引等，而我们经常使用的InnoDB存储引擎的默认索引实现为：B+树索引。</p>
<h2 id="Hash索引和B-树索引有什么区别或者说优劣"><a href="#Hash索引和B-树索引有什么区别或者说优劣" class="headerlink" title="Hash索引和B+树索引有什么区别或者说优劣"></a><strong>Hash索引和B+树索引有什么区别或者说优劣</strong></h2><p>hash索引底层就是hash表，进行查找时，调用一次hash函数就可以获取到相应的键值，之后进行回表查询获得实际数据；</p>
<p>B+的底层现实是多路平衡查找树，对于每一次查询都是从根节点出发，查找叶子节点方可以获取的所查键值，然后根据查询判断是否需要回表查询数据。</p>
<h3 id="不同："><a href="#不同：" class="headerlink" title="不同："></a><strong>不同：</strong></h3><p>hash索引进行等值查询(where xx&#x3D;xx)更快（一般情况下），但是却无法进行范围查询(模糊查询...)。</p>
<p>因为在hash索引中经过hash函数建立索引之后，索引的顺序与原顺序无法保持一致，不能支持范围查询，而B+树的所有节点皆遵循（左节点小于父节点，右节点大于父节点，多叉树也类似），天然支持范围查询。</p>
<p>hash索引不支持使用索引排序，原理同上。</p>
<p>hash索引不支持模糊查询以及多列索引的最左前缀原则，原理也是因为hash函数的不可预测AAAA和AAAAB的索引没有相关性。</p>
<p>hash索引任何时候都避免不了回表查询数据，而B+树索引在符合某些条件下(聚簇索引，覆盖索引等)的时候可以只通过索引完成查询。</p>
<p>hash索引在等值查询上较快，但是不稳定，性能不可预测，当某个键值存在大量重复的时候，发生hash碰撞，此时效率可能极差，而B+树的查询比较稳定，对于所有查询都是从根节点到叶子节点，而树的高度较低。</p>
<p><strong>因此，在大多数情况下，直接使用B+树索引可以获得稳定且较好的查询速度，而不需要使用hash索引。</strong></p>
<h2 id="什么是聚簇索引"><a href="#什么是聚簇索引" class="headerlink" title="什么是聚簇索引"></a><strong>什么是聚簇索引</strong></h2><p>在B+树的索引中，叶子节点可能存储了当前的key值，也可能存储了当前的key值以及整行数据，这就是聚簇索引和非聚簇索引。</p>
<p>在InnoDB中，只有主键索引是聚簇索引，如果没有主键，则挑选一个唯一键建立聚簇索引，如果没有唯一键，则隐式的生成一个键来建立聚簇索引。</p>
<p><strong>当查询使用聚簇索引时，在对应的叶子节点，可以获取整行数据，因此不用再次进行回表查询。</strong></p>
<h2 id="非聚簇索引一定要回表查询？"><a href="#非聚簇索引一定要回表查询？" class="headerlink" title="非聚簇索引一定要回表查询？"></a><strong>非聚簇索引一定要回表查询？</strong></h2><p>不一定，这涉及到查询语句所要求的字段是否全部命中了索引，那么就不必再进行回表查询。</p>
<p>select age from employee where age &lt;<br>20;在age字段建立索引，查询age，无需回表查询，在索引的叶子节点上，已经包含了age信息。</p>
<h2 id="在建立索引的时候，都需要考虑哪些因素"><a href="#在建立索引的时候，都需要考虑哪些因素" class="headerlink" title="在建立索引的时候，都需要考虑哪些因素"></a><strong>在建立索引的时候，都需要考虑哪些因素</strong></h2><p>字段使用的频率。经常作为条件进行查询的字段比较合适，如果需要建立联合索引的话，还需要考虑联合索引的顺序。</p>
<h2 id="联合索引是什么？为什么需要注意联合索引中的顺序？"><a href="#联合索引是什么？为什么需要注意联合索引中的顺序？" class="headerlink" title="联合索引是什么？为什么需要注意联合索引中的顺序？"></a><strong>联合索引是什么？为什么需要注意联合索引中的顺序？</strong></h2><p>mysql可以使用多个字段同时建立一个索引，叫做联合索引，在联合索引中，如果想要命中索引，需要按照建立索引时的顺序挨个使用，否则无法命中索引。</p>
<h2 id="怎么知道索引是否被使用？或者说怎么才能知道sql执行慢的原因？"><a href="#怎么知道索引是否被使用？或者说怎么才能知道sql执行慢的原因？" class="headerlink" title="怎么知道索引是否被使用？或者说怎么才能知道sql执行慢的原因？"></a><strong>怎么知道索引是否被使用？或者说怎么才能知道sql执行慢的原因？</strong></h2><p>explain查看执行计划。</p>
<h2 id="什么时候索引会失效"><a href="#什么时候索引会失效" class="headerlink" title="什么时候索引会失效"></a><strong>什么时候索引会失效</strong></h2><ol>
<li><p>使用不等号查询</p>
</li>
<li><p>列参与了数学运算或者函数</p>
</li>
<li><p>like &#39;%xxx&#39;</p>
</li>
<li><p>当mysql分析全表扫描比使用索引快的时候</p>
</li>
<li><p>当使⽤联合索引,前⾯⼀个条件为范围查询,后⾯的即使符合最左前缀原则,也⽆法使⽤索引</p>
</li>
</ol>
<h2 id="索引有什么劣势"><a href="#索引有什么劣势" class="headerlink" title="索引有什么劣势"></a><strong>索引有什么劣势</strong></h2><ol>
<li><p>实际上索引也是张表，该表保存了主键和索引字段，并指向实体表记录，所以索引也是要占用空间的。</p>
</li>
<li><p>虽然索引大大的提高查询速度，如对表进行INSERT、UPDATE和DELETE。因为更新表时，MYSQL不仅要保存数据，还要保存一下索引文件每次更新添加了索引类的字段，都会调整因为更新所带来的键值变化后的索引信息。</p>
</li>
</ol>
<h3 id="表结构设计"><a href="#表结构设计" class="headerlink" title="表结构设计"></a><strong>表结构设计</strong></h3><p><strong>尽量设置一个主键</strong></p>
<p><strong>主键使用自增ID</strong></p>
<p><strong>字段不要定义为null</strong></p>
<p><strong>存储密码使用char而不是使用varchar</strong></p>
<h2 id="存储引擎相关"><a href="#存储引擎相关" class="headerlink" title="存储引擎相关"></a><strong>存储引擎相关</strong></h2><h3 id="MySQL支持哪些存储引擎"><a href="#MySQL支持哪些存储引擎" class="headerlink" title="MySQL支持哪些存储引擎"></a><strong>MySQL支持哪些存储引擎</strong></h3><p>InnoDB、MyISAM等等。</p>
<h3 id="InnoDB和MyISAM的区别"><a href="#InnoDB和MyISAM的区别" class="headerlink" title="InnoDB和MyISAM的区别"></a><strong>InnoDB和MyISAM的区别</strong></h3><ol>
<li><p>InnoDB支持事务MyISAM不支持。</p>
</li>
<li><p>InnoDB支持行级锁，而MyISAM只支持表级锁</p>
</li>
<li><p>InnoDB支持MVCC，MyISAM不支持</p>
</li>
<li><p>InnoDB支持外键，MyISAM不支持</p>
</li>
<li><p>InnoDB不支持全文索引，而MyISAM支持</p>
</li>
</ol>
<p><img src="https://yh-blog-files.oss-cn-hangzhou.aliyuncs.com/2021/08/01/16278234762821.jpg"></p>
<h2 id="零散问题"><a href="#零散问题" class="headerlink" title="零散问题"></a><strong>零散问题</strong></h2><h3 id="MySQL中varchar和char的区别"><a href="#MySQL中varchar和char的区别" class="headerlink" title="MySQL中varchar和char的区别"></a><strong>MySQL中varchar和char的区别</strong></h3><p>char是一个定长字段，假如申请了char(10)的空间，那么无论实际存储多少内容，该字段都占用10个字符；</p>
<p>而varchar是变长的，也就是说申请的只是最大长度，占用空间为实际字符长度+1，最后一个字符存储使用了多长空间</p>
<p>在检索效率上，char&gt;varchar，所以如果确定某个字段是定长的，可以使用char，否则尽量使用varchar。例如MD5密码，则应该使用char。</p>
<h3 id="varchar-10-和int-10-的区别"><a href="#varchar-10-和int-10-的区别" class="headerlink" title="varchar(10)和int(10)的区别"></a><strong>varchar(10)和int(10)的区别</strong></h3><p>varchar的10代表了申请的空间⻓度,也是可以存储的数据的最⼤⻓度,⽽int的10只是代表了展⽰的⻓度,不⾜10位以0填充。</p>
<p>也就是说,int(1)和int(10)所能存储的数字⼤⼩以及占⽤的空间都是相同的,只是在展⽰时按照⻓度展⽰。</p>
<h3 id="MySQL的binlog有几种录入格式？"><a href="#MySQL的binlog有几种录入格式？" class="headerlink" title="MySQL的binlog有几种录入格式？"></a><strong>MySQL的binlog有几种录入格式？</strong></h3><p>1）statement：</p>
<p>2）row：</p>
<p>3）mixed：</p>
<h3 id="超大分页怎么处理？"><a href="#超大分页怎么处理？" class="headerlink" title="超大分页怎么处理？"></a><strong>超大分页怎么处理？</strong></h3><p>select * from table where age &gt; 20 limit 1000000,10</p>
<p>select * from table where id in (select id from table where age &gt; 20<br>limit 1000000,10)</p>
<p>同时如果ID连续的好,我们还可以 select * from table where id &gt; 1000000<br>limit 10</p>
<h3 id="数据库三大范式"><a href="#数据库三大范式" class="headerlink" title="数据库三大范式"></a><strong>数据库三大范式</strong></h3><ul>
<li><p>第一范式：每个列都不可拆分。</p>
</li>
<li><p>第二范式：非主键列完全依赖于主键，而不能是依赖于主键的一部分。</p>
</li>
<li><p>第三范式：非主键只依赖于主键，不依赖于其他非主键。</p>
</li>
</ul>
<p><strong>在设计数据库结构式，要尽量遵守三范式，如果不遵守，必须有足够的理由。</strong></p>
<h1 id="MySQL读写分离"><a href="#MySQL读写分离" class="headerlink" title="MySQL读写分离"></a><strong>MySQL读写分离</strong></h1><h2 id="如何实现MySQL的读写分离"><a href="#如何实现MySQL的读写分离" class="headerlink" title="如何实现MySQL的读写分离"></a><strong>如何实现MySQL的读写分离</strong></h2><p>一个主库，多个从库。在主库写，然后主库会自动把数据同步到从库。</p>
<h2 id="MySQL主从复制的原理"><a href="#MySQL主从复制的原理" class="headerlink" title="MySQL主从复制的原理"></a><strong>MySQL主从复制的原理</strong></h2><p>主库将变更写入binlog日志，然后从库连接主库后，从库有一个IO线程，将主库的binlog日志拷贝到自己本地，写入一个relay中继日志中。接着从库中有一个SQL线程会从中继日志中读取binlog，然后执行binlog日志中的内容，也就是在自己本地执行一遍SQL，</p>
<p>这样就可以保证主从一致。</p>
<p>##<strong>从库执行SQL是串行的，高并发下会有延迟问题</strong></p>
<p><strong>MySQL主从同步延时问题</strong></p>
<ol>
<li><p>分库，将一个主库拆分为多个从库。</p>
</li>
<li><p>打开MySQL支持的并行复制。</p>
</li>
<li><p>重写代码，不要在写入之后马上查询。</p>
</li>
<li><p>如果必须要写入之后马上查询，对这个查询设置直连数据库。</p>
</li>
</ol>
<h1 id="MySQL优化"><a href="#MySQL优化" class="headerlink" title="MySQL优化"></a><strong>MySQL优化</strong></h1><p>【优化总结口诀】</p>
<p>全值匹配我最爱，最左前缀要遵守；</p>
<p>带头大哥不能死，中间兄弟不能断；</p>
<p>索引列上少计算，范围之后全失效；</p>
<p>Like百分写最右，覆盖索引不写星；</p>
<p>不等空值还有or，索引失效要少用；</p>
<p>VARCHAR引号不可丢，SQL高级也不难！</p>
<p><img src="https://yh-blog-files.oss-cn-hangzhou.aliyuncs.com/2021/08/01/16278235835760.jpg"></p>
<p><img src="https://yh-blog-files.oss-cn-hangzhou.aliyuncs.com/2021/08/01/16278235919541.jpg"></p>
<p> EXPLAIN</p>
<ol>
<li><p>SQL语句中IN包含的值不应过多</p>
</li>
<li><p>SELECT语句务必指明字段名称</p>
</li>
<li><p>当只需要一条数据的时候，使用limit 1</p>
</li>
<li><p>如果排序字段没有用到索引，就尽量少排序</p>
</li>
<li><p>如果限制条件中其他字段没有索引，尽量少用or</p>
</li>
<li><p>尽量用union all代替union</p>
</li>
<li><p>区分in和exists、not in和not exists(小表驱动大表)</p>
</li>
<li><p>B为小表：select * from 表A where id in (select id from 表B)</p>
<p>A为小表：select * from 表A where exists(select * from 表B where 表B.id&#x3D;表A.id)</p>
</li>
<li><p>使用合理的分页方式以提高分页效率</p>
<p> select id,name from product limit 866613, 20;</p>
<p> 优化方法：可以将上一页排序字段最大值作为下一页的起点。</p>
<p> select id,name from product where id&gt; 866612 limit 20;</p>
</li>
<li><p>分段查询</p>
<p>分段查询，最终合并输出。</p>
</li>
<li><p>避免在where子句中进行null值判断</p>
</li>
<li><p>不建议使用%前缀模糊查询</p>
<p>例如 LIKE &#39;%name%&#39;</p>
</li>
</ol>
<p> <strong>解决办法：</strong></p>
<pre><code>1. 使用全文索引:

    创建全文索引SQL：ALTER TABLE \`dynamic_201606\` ADD FULLTEXT INDEX \`idx_user_name\` (\`user_name\`);

    使用全文索引SQL：select id,fnum,fdst from dynamic_201606 where match(user_name) against(\&#39;zhangsan\&#39; in boolean mode);

2. 使用覆盖索引：查询的字段建立索引
</code></pre>
<ol start="13">
<li><p>避免在where子句中对字段进行表达式操作</p>
</li>
<li><p>避免进行隐式转换（字符串不加单引号导致索引失效）</p>
<p>SELECT * FROM table WHERE type&#x3D;1;（type为varchar）</p>
</li>
<li><p>对于联合索引，要遵守最左前缀原则</p>
<p>举例来说联合索引含有字段id,name,school，可以直接用id字段，也可以id,name这样的顺序，name,school无法使用这个索引,id,school只能使用id索引。（必须是连续的，中间不能断，WHERE子句中MYSQL优化器会优化顺序）。</p>
</li>
<li><p>注意范围查询语句</p>
<p>对于联合索引，如果存在范围查询，比如between、&gt;、&lt;等条件，会造成后面索引字段失效。</p>
</li>
<li><p>关于join优化</p>
<p><img src="https://yh-blog-files.oss-cn-hangzhou.aliyuncs.com/2021/08/01/16278239298268.jpg"></p>
<p>1）MySQL没有full join,可以使用union来实现。</p>
<p>2）尽量使用inner join，因为inner join会自动选择小表作为驱动表。</p>
<p>3）合理运用索引</p>
<p>4）利用小表去驱动大表。</p>
<p>5）巧用STRAIGHT_JOIN：只能在inner join下使用,STRAIGHT_JOIN左边表为驱动表。</p>
</li>
<li><p>ORDER BY优化：（MYSQL支持两种排序方式，filesort和Index）</p>
<ul>
<li><p>ORDER BY子句，尽量使用INDEX（索引）方式排序，避免使用filesort方式排序</p>
</li>
<li><p>尽可能在索引列上完成排序操作，遵循索引的最左前缀原则</p>
</li>
<li><p>ORDER BY子句的列满足索引最左前缀原则</p>
</li>
<li><p>WHERE子句列和ORDER BY子句列满足索引最左前缀原则</p>
</li>
<li><p>无法使用INDEX，FileSort有两种算法：</p>
<p>  双路排序</p>
<p>  单路排序</p>
</li>
</ul>
</li>
</ol>
<p><img src="https://yh-blog-files.oss-cn-hangzhou.aliyuncs.com/2021/08/01/16278240457240.jpg"></p>
<p><img src="https://yh-blog-files.oss-cn-hangzhou.aliyuncs.com/2021/08/01/16278240554561.jpg"></p>
<ol start="19">
<li><p>GROUP BY优化：（和order by几乎相同）</p>
<p>group by的实质是先排序后分组，遵循索引最左前缀原则</p>
<p>当无法使用索引列，增大max_length_for_sort_data参数的设置+增大sort_buffer_size参数设置</p>
<p>where优先级高于having，能在where限定的条件就不要用having了</p>
</li>
</ol>
<h1 id="MySQL日志"><a href="#MySQL日志" class="headerlink" title="MySQL日志"></a><strong>MySQL日志</strong></h1><h2 id="MySQL逻辑架构"><a href="#MySQL逻辑架构" class="headerlink" title="MySQL逻辑架构"></a><strong>MySQL逻辑架构</strong></h2><p><img src="https://yh-blog-files.oss-cn-hangzhou.aliyuncs.com/2021/08/01/16278241125637.jpg"></p>
<h3 id="MySQL逻辑架构-1"><a href="#MySQL逻辑架构-1" class="headerlink" title="MySQL逻辑架构"></a>MySQL逻辑架构</h3><p>MySQL的逻辑架构大致可分为三层：</p>
<p>第一层：处理客户端连接，授权认证，安全校验。</p>
<p>第二层：服务端server层，负责对SQL解释、分析、优化、执行操作引擎等。</p>
<p>第三层：存储引擎，负责MySQL中数据的存储和提取。</p>
<p><img src="https://yh-blog-files.oss-cn-hangzhou.aliyuncs.com/2021/08/02/16279033382808.jpg" alt="MySQL数据更新流程"></p>
<h2 id="MySQL日志-1"><a href="#MySQL日志-1" class="headerlink" title="MySQL日志"></a><strong>MySQL日志</strong></h2><h3 id="redo-log（重做日志）"><a href="#redo-log（重做日志）" class="headerlink" title="redo log（重做日志）"></a><strong>redo log（重做日志）</strong></h3><p><strong>redo log</strong>属于MySQL存储引擎<strong>innoDB</strong>的事务日志。</p>
<p>MySQL的数据是存放在磁盘中的，每次读写数据都需要做磁盘IO操作，如果并发场景下性能就会很差。为此MySQL提供一个优化手段，引入缓存<strong>buffer pool</strong>。这个缓存中包含了磁盘中部分数据页（<strong>page</strong>）的映射，以此来缓解数据库的磁盘压力。</p>
<p>当从数据库读数据时，首先从缓存中读取，如果缓存中没有，则从磁盘读取后放入缓存；当向数据库写数据时，先向缓存写入，此时缓存中的数据页变更，这个数据页称为<strong>脏页，buff pool</strong>中修改完数据后会按照设定的更新策略，定期刷到磁盘中，这个过程称为<strong>刷脏页</strong>。</p>
<h4 id="MySQL宕机"><a href="#MySQL宕机" class="headerlink" title="MySQL宕机"></a>MySQL宕机</h4><p>如果刷脏页还未完成，可MySQL由于某些原因宕机重启，此时<strong>buffer pool</strong>中修改的数据还没有来得及刷到磁盘中，就会导致数据丢失，无法保证事务的持久性。</p>
<p>为了解决这个问题引入了<strong>redo log</strong>，redo Log如其名侧重于重做！它记录的是数据库中每个页的修改，而不是某一行或某几行修改成怎样，可以用来恢复提交后的物理数据页，且只能恢复到最后一次提交的位置。</p>
<p><strong>redo log</strong>用到了<strong>WAL（Write-Ahead Logging）</strong>技术，这个技术的核心就在于修改记录前，一定要先写日志，并保证日志先落盘，才能算事务提交完成。</p>
<p>有了redo log再修改数据时，InnoDB引擎会把更新记录先写在redo log中，在修改<strong>Buffer Pool</strong>中的数据，当提交事务时，调用<strong>fsync</strong>把redo log刷入磁盘。至于缓存中更新的数据文件何时刷入磁盘，则由后台线程异步处理。</p>
<p><strong>注意：</strong>此时redo log的事务状态为prepare，还未真正提交成功。要等到<strong>bin log</strong>日志写入磁盘完成才变更为<strong>commit</strong>，事务才算真正提交完成。</p>
<p>这样一来即使刷脏页之前MySQL意外宕机也没关系，只要在重启时解析redo log中更改记录进行重放，重新刷盘即可。</p>
<p><strong>大小固定</strong></p>
<p>redo log采用固定大小，循环写入的格式，当redo log写满之后，重新从头开始如此循环写，形成一个环状。</p>
<p>如此设计的原因：</p>
<p>因为redo log记录的是数据页上的修改，如果<strong>Buffer Pool</strong>中数据页已经刷磁盘了，那么这些日志记录就失效了，新日志会将这些失效的记录进行覆盖擦除。</p>
<p><img src="https://yh-blog-files.oss-cn-hangzhou.aliyuncs.com/2021/08/02/16279035166872.jpg"></p>
<ul>
<li>图中的<strong>write pos</strong>表示redo log当前记录的日志序列号<strong>LSN</strong>(log sequence number)，写入还未刷盘，循环往后递增；<strong>check point</strong>表示redo log中修改记录已刷入磁盘后的LSN，循环往后递增，这个LSN之前的数据已经全落盘。</li>
<li><strong>write pos</strong>到<strong>check point</strong>之间的部分是redo log空余的部分（绿色），用来记录新的日志；<strong>check point</strong>到<strong>write pos</strong>之间是redo log已经记录的数据页修改数据，此时数据页还未刷回磁盘的部分。当<strong>write pos</strong>追上<strong>check point</strong>时，会先推动<strong>check point</strong>向前移动，空出位置（刷盘）再记录新的日志。</li>
</ul>
<p><strong>注意：</strong><br>redo log日志满了，在擦除之前，需要确保这些要被擦除记录对应在内存中的数据页都已经刷到磁盘中了。擦除旧记录腾出新空间这段期间，是不能再接收新的更新请求的，此刻MySQL的性能会下降。所以在并发量大的情况下，合理调整redo log的文件大小非常重要。</p>
<blockquote>
<p>crash-safe<br>因为redo log的存在使得Innodb引擎具有了crash-safe的能力，即MySQL宕机重启，系统会自动去检查redo log，将修改还未写入磁盘的数据从redo log恢复到MySQL中。</p>
</blockquote>
<p>MySQL启动时，不管上次是正常关闭还是异常关闭，总是会进行恢复操作。会先检查数据页中的LSN，如果这个LSN 小于 redo log 中的LSN，即write pos位置，说明在redo log上记录着数据页上尚未完成的操作，接着就会从最近的一个check point出发，开始同步数据。</p>
<p>简单理解，比如：redo log的LSN是500，数据页的LSN是300，表明重启前有部分数据未完全刷入到磁盘中，那么系统则将redo log中LSN序号300到500的记录进行重放刷盘。</p>
<h3 id="undo-log（回滚日志）"><a href="#undo-log（回滚日志）" class="headerlink" title="undo log（回滚日志）"></a><strong>undo log（回滚日志）</strong></h3><p><img src="https://yh-blog-files.oss-cn-hangzhou.aliyuncs.com/2021/08/02/16279037077440.jpg"></p>
<p>undo log</p>
<p><strong>undo log</strong>也是属于MySQL存储引擎InnoDB的事务日志。</p>
<p>undo log属于逻辑日志，如其名主要起到回滚的作用，它是保证事务原子性的关键。记录的是数据修改前的状态，在数据修改的流程中，同时会记录一条与当前操作相反的逻辑日志到undo log中。<br><img src="https://yh-blog-files.oss-cn-hangzhou.aliyuncs.com/2021/08/02/16279037334256.jpg"></p>
<p>同一个事物内的一条记录被多次修改，不会把每次数据修改前的状态都写入undo log；undo log只负责记录事务开始前要修改数据的原始版本，当我们再次对这行数据进行修改，所产生的修改记录会写入到redo log，undo log负责完成回滚，redo log负责完成前滚。</p>
<p>回滚</p>
<p>未提交的事务，即事务未执行commit。但该事务内修改的脏页中，可能有一部分脏块已经刷盘。如果此时数据库实例宕机重启，就需要用回滚来将先前那部分已经刷盘的脏块从磁盘上撤销。</p>
<p>前滚</p>
<p>未完全提交的事务，即事务已经执行commit，但该事务内修改的脏页中只有一部分数据被刷盘，另外一部分还在buffer pool缓存上，如果此时数据库实例宕机重启，就需要用前滚来完成未完全提交的事务。将先前那部分由于宕机在内存上的未来得及刷盘数据，从redo log中恢复出来并刷入磁盘。</p>
<p><strong>数据库实例恢复时，先做前滚，后做回滚。</strong></p>
<h3 id="bin-log（归档日志）"><a href="#bin-log（归档日志）" class="headerlink" title="bin log（归档日志）"></a><strong>bin log（归档日志）</strong></h3><p><strong>bin log</strong>是一种数据库Server层（和什么引擎无关），以二进制形式存储在磁盘中的逻辑日志。bin log记录了数据库所有DDL和DML操作（不包含 SELECT 和 SHOW等命令，因为这类操作对数据本身并没有修改）。</p>
<p>默认情况下，二进制日志功能是关闭的。可以通过以下命令查看二进制日志是否开启：</p>
<p>SHOW VARIABLES LIKE &#39;log_bin&#39;;</p>
<p>bin log也被叫做归档日志，因为它不会像redo log那样循环写擦除之前的记录，而是会一直记录日志。一个bin log日志文件默认最大容量1G（也可以通过max_binlog_size参数修改），单个日志超过最大值，则会新创建一个文件继续写。</p>
<p>show binary logs;</p>
<p>bin log日志的内容格式其实就是执行SQL命令的反向逻辑，这点和undo log有点类似。一般来说开启bin log都会给日志文件设置过期时间（expire_logs_days参数，默认永久保存），要不然日志的体量会非常庞大。</p>
<p>show variables like &#39;expire_logs_days&#39;;</p>
<p>bin log主要应用于MySQL主从模式（master-slave）中，主从节点间的数据同步；以及基于时间点的数据还原。</p>
<p><strong>bin log和redo log的区别</strong></p>
<ul>
<li><p>层次不同：redo log 是InnoDB存储引擎实现的，bin log是MySQL的服务器层实现的，但MySQL数据库中的任何存储引擎对于数据库的更改都会产生bin log。</p>
</li>
<li><p>作用不同：redo log 用于碰撞恢复（crash recovery），保证MySQL宕机也不会影响持久性；bin log用于时间点恢复（point-in-time recovery），保证服务器可以基于时间点恢复数据和主从复制。</p>
</li>
<li><p>内容不同：redo log 是物理日志，内容基于磁盘的页Page；bin log的内容是二进制，可以根据binlog_format参数自行设置。</p>
</li>
<li><p>写入方式不同：redo log 采用循环写的方式记录；binlog 通过追加的方式记录，当文件大小大于给定值后，后续的日志会记录到新的文件上。</p>
</li>
<li><p>刷盘时机不同：bin log在事务提交时写入；redo log 在事务开始时即开始写入。</p>
</li>
</ul>
<p><strong>bin log 与 redo log功能并不冲突而是起到相辅相成的作用，需要二者同时记录，才能保证当数据库发生宕机重启时，数据不会丢失。</strong></p>
<p><strong>relay log（中继日志）</strong></p>
<p>relay log日志文件具有与bin log日志文件相同的格式，从上边MySQL主从复制的流程可以看出，relay log起到一个中转的作用，slave先从主库master读取二进制日志数据，写入从库本地，后续再异步由SQL线程读取解析relay log为对应的SQL命令执行。</p>
<h3 id="slow-query-log"><a href="#slow-query-log" class="headerlink" title="slow query log"></a><strong>slow query log</strong></h3><p>慢查询日志（slow query log）: 用来记录在 MySQL中执行时间超过指定时间的查询语句，在 SQL<br>优化过程中会经常使用到。通过慢查询日志，我们可以查找出哪些查询语句的执行效率低，耗时严重。</p>
<p>出于性能方面的考虑，一般只有在排查慢SQL、调试参数时才会开启，默认情况下，慢查询日志功能是关闭的。可以通过以下命令查看是否开启慢查询日志：</p>
<p>SHOW VARIABLES LIKE &#39;slow_query%&#39;;</p>
<h3 id="general-query-log"><a href="#general-query-log" class="headerlink" title="general query log"></a><strong>general query log</strong></h3><p>一般查询日志（general query log）：用来记录用户的所有操作，包括客户端何时连接了服务器、客户端发送的所有SQL以及其他事件，比如MySQL服务启动和关闭等等。MySQL服务器会按照它接收到语句的先后顺序写入日志文件。</p>
<p>由于一般查询日志记录的内容过于详细，开启后 Log文件的体量会非常庞大，所以出于对性能的考虑，默认情况下，该日志功能是关闭的，通常会在排查故障需获得详细日志的时候才会临时开启。</p>
<p>show variables like &#39;general_log&#39;;</p>
<h3 id="error-log"><a href="#error-log" class="headerlink" title="error log"></a><strong>error log</strong></h3><p>错误日志（error log）: 应该是 MySQL 中最好理解的一种日志，主要记录 MySQL服务器每次启动和停止的时间以及诊断和出错信息。</p>
<p>默认情况下，该日志功能是开启的，通过如下命令查找错误日志文件的存放路径。</p>
<p>SHOW VARIABLES LIKE &#39;log_error&#39;;</p>
<p><strong>注意：</strong>错误日志中记录的可并非全是错误信息，像 MySQL 如何启动 InnoDB的表空间文件、如何初始化自己的存储引擎，初始化 buffer pool等等，这些也记录在错误日志文件中。</p>
]]></content>
      <categories>
        <category>后端</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title>Netty</title>
    <url>/2021/09/14/Netty/</url>
    <content><![CDATA[<h1 id="Netty"><a href="#Netty" class="headerlink" title="Netty"></a>Netty</h1><h2 id="Netty介绍应用场景"><a href="#Netty介绍应用场景" class="headerlink" title="Netty介绍应用场景"></a>Netty介绍应用场景</h2><h3 id="Netty介绍"><a href="#Netty介绍" class="headerlink" title="Netty介绍"></a>Netty介绍</h3><ol>
<li>Netty是Jboss提供的一个开源框架，现为GitHub上的独立项目。</li>
<li>Netty是异步的、基于事件驱动的网络应用框架，用以快速开发高性能、高可靠性的网络IO程序。</li>
<li>Netty主要针对在TCP协议下，面向Clients端的高并发应用，或者Peer to Peer场景下的大量数据持续传输的应用。</li>
<li>Netty本质是NIO框架，适用于服务器通讯相关的多种应用场景。</li>
<li>要透彻理解Netty，需要先学习NIO，这样我们才能阅读Netty源码。<span id="more"></span>
<img src="https://yh-blog-files.oss-cn-hangzhou.aliyuncs.com/2021/09/14/16316233529799.jpg" alt="16316233529799"></li>
</ol>
<h3 id="Netty的应用场景"><a href="#Netty的应用场景" class="headerlink" title="Netty的应用场景"></a>Netty的应用场景</h3><ol>
<li>互联网行业<ul>
<li>在分布式系统中，各个节点之间需要远程服务调用，高性能的RPC框架必不可少，Netty作为异步高性能通信框架，往往作为基础通信组件被这些RPC框架使用。</li>
<li>典型应用：阿里分布式服务框架Dubbo的RPC框架使用Dubbo协议进行节点间通信，Dubbo协议默认使用Netty作为基础通信组件，用与实现各进程节点之间的内部通信。</li>
</ul>
</li>
<li>游戏行业<ul>
<li>无论是手游服务端还是大型的网络游戏，Java语言得到了越来越广泛的应用。</li>
<li>Netty作为高性能的基础通信组件，提供了TCP&#x2F;UDP和HTTP协议栈，方便定制和开发私有协议，账号登录服务器。</li>
<li>地图服务器之间可以方便的通过Netty进行高性能的通信。</li>
</ul>
</li>
<li>大数据领域<ul>
<li>经典的Hadoop的高性能通信和序列化组件（AVRO 实现数据文件共享）的RPC框架，默认采用Netty进行跨界点通信。</li>
<li>它的Netty Service基于Netty框架二次封装实现的。</li>
</ul>
</li>
</ol>
<h2 id="Java-IO编程"><a href="#Java-IO编程" class="headerlink" title="Java IO编程"></a>Java IO编程</h2><h3 id="IO模型"><a href="#IO模型" class="headerlink" title="IO模型"></a>IO模型</h3><h4 id="IO模型基本说明"><a href="#IO模型基本说明" class="headerlink" title="IO模型基本说明"></a>IO模型基本说明</h4><ol>
<li>IO模型简单的理解：就是用什么样的通道进行数据的发送和接收，很大程度上决定了程序通信的性能。</li>
<li>java共支持3种网络编程模型IO模式：NIO、BIO、AIO<ol>
<li>BIO：同步并阻塞（传统阻塞型），服务器实现模式为一个连接一个线程，即客户端有连接请求时服务器端就需要启动一个线程进行处理，如果这个连接不做任何事情会造成不必要的线程开销。<br><img src="https://yh-blog-files.oss-cn-hangzhou.aliyuncs.com/2021/09/14/16316252775663.jpg" alt="16316252775663"></li>
<li>NIO：同步非阻塞，服务器实现模式为一个线程处理多个请求（连接），即客户端发送连接请求都会注册到多路复用器上， 多路复用器轮询到连接有IO请求就进行处理。<br><img src="https://yh-blog-files.oss-cn-hangzhou.aliyuncs.com/2021/09/14/16316256732370.jpg" alt="16316256732370"></li>
<li>AIO（NIO.2）：异步非阻塞，AIO引入异步通道的概念，采用了Proactor模式，简化了程序编写，有效的请求才启动线程，它的特点是先由操作系统完成后才通知服务端程序启动线程取处理，一般适用于连接数多且连接时间较长的应用。<h4 id="适用场景分析"><a href="#适用场景分析" class="headerlink" title="适用场景分析"></a>适用场景分析</h4></li>
</ol>
</li>
<li>BIO方式适用于连接数目较小且固定的架构，这种方式对服务器资源要求比较高，并发局限于应用中，JDK1.4以前的唯一选择，但程序简单易理解。</li>
<li>NIO方式适用于连接数目多且连接时间比较短（轻操作）的架构，比如聊天服务器，弹幕系统，服务间通讯等。编程比较复杂，JDK1.4开始支持。</li>
<li>AIO方式适用于连接数目多且连接比较长（重操作）的架构，比如相册服务器，充分调用OS参与并发操作，编程比较复杂，JDk7开始支持。<h3 id="Java-BIO"><a href="#Java-BIO" class="headerlink" title="Java BIO"></a>Java BIO</h3></li>
<li>Java BIO就是传统的java io编程，其相关的类和接口在java.io </li>
<li>BIO（block IO）：同步阻塞，服务器实现模式为一个连接一个线程，即客户端有连接请求是服务端就需要启动一个线程进行处理，如果连接不做任何事情会造成不必要的线程开销，可以通过线程池机制改善（实现多个客户端连接服务器）。</li>
<li>BIO方式适用于连接数目比较小且固定的架构，这种方式对服务器资源的要求比较高，并发局限于应用中，JDK1.4以前唯一的选择程序简单易理解</li>
<li>对BIO流程的梳理<ol>
<li>服务端启动一个ServerSocket</li>
<li>客户端启动Socket对服务器进行通信，默认情况下服务器端需要对每一个客户建立一个线程与之通讯</li>
<li>客户端发出请求后，先咨询服务器是否有线程响应，如果没有则会等待，或者拒绝</li>
<li>如果有响应，客户端线程会等待请求结束后，再继续执行</li>
</ol>
</li>
<li>Java BIO应用实例<ol>
<li>使用BIO模型编写一个服务端，监听6666端口，当有客户端连接时，就启动一个线程与之通信。</li>
<li>要求使用线程池机制改善，可以连接多个客户端。</li>
<li>服务端可以接收客户端发送的数据（telnet方式即可）</li>
<li>demo见netty-study<h3 id="Java-NIO"><a href="#Java-NIO" class="headerlink" title="Java NIO"></a>Java NIO</h3></li>
</ol>
</li>
<li>Java NIO全称 java non-blocking IO，是指JDK提供的新API。从JDK1.4开始，Java提供了一系列改进的输入&#x2F;输出的新特性，被统称为NIO（New IO），是同步非阻塞的</li>
<li>NIO相关类都被放在java.nio包及子包下，并且对原java.nio包中的很多类进行改写。</li>
<li>NIO有三大核心部分：Channel（通道），Buffer（缓冲区），Selector（选择器）。</li>
<li>NIO是面向缓冲区，或者面向块编程的。数据读取到一个它稍后处理的缓冲区，需要时可在缓冲区中前后移动，这就增加了处理过程中的灵活性，使用它可以提供非阻塞的高伸缩性网络</li>
<li>Java NIO的非阻塞模式，使一个线程从某通道发送请求或者读取数据，但是它仅能得到目前可用的数据，如果目前没有可用的数据，就什么都不会获取，而不是保持线程阻塞，所以直至数据变得可以读之前，该线程可以继续做其他的事情。非阻塞写也是如此，一个线程请求写入一些数据到某通道，但不需要等待它完全写入，这个线程同时可以去做别的事情。</li>
<li>通俗理解：NIO是可以做到用一个线程来处理多个操作的。假设有10000个请求过来，根据实际情况，可以分配50或者100个线程来处理。不像之前的阻塞IO那样，非得分配10000个线程。</li>
<li>http2.0使用了多路复用的技术，做到同一个连接并发处理多个请求，而且并发请求的数量比http1.1大了好几个数量级。<br><img src="https://yh-blog-files.oss-cn-hangzhou.aliyuncs.com/2021/09/22/16323168494091.jpg" alt="16323168494091"><h3 id="NIO和BIO的比较"><a href="#NIO和BIO的比较" class="headerlink" title="NIO和BIO的比较"></a>NIO和BIO的比较</h3></li>
<li>BIO以流的方式处理数据，而NIO以块的方式处理数据，块IO的效率比流IO高很多</li>
<li>BIO是阻塞的，NIO则是非阻塞的</li>
<li>BIO基于字节流和字符流进行操作，而NIO基于Channel（通道）和Buffer（缓冲区）进行操作，数据总是从通道读取到缓冲区中，或者从缓冲区写入到通道中。Selector（选择器）用于监听多个通道的事件（比如：连接请求，数据到达等），因此使用当个线程就可以监听多个客户端通道<h3 id="NIO三大核心"><a href="#NIO三大核心" class="headerlink" title="NIO三大核心"></a>NIO三大核心</h3></li>
</ol>
<p><img src="https://yh-blog-files.oss-cn-hangzhou.aliyuncs.com/2021/09/22/16323190875807.jpg" alt="16323190875807"></p>
<ol>
<li>每个Channel都会对应一个Buffer</li>
<li>Selector会对应一个线程，一个线程对应多个Channel（连接）</li>
<li>该图反映了有三个Channel注册到该Selector上</li>
<li>程序切换到哪个Channel是由事件决定的，Event就是一个重要的概念</li>
<li>Selector会根据不同的事件，在各个通道上切换</li>
<li>Buffer就是一个内存块，底层是一个数组</li>
<li>数据的读取写入都是通过Buffer，这个和BIO有很大区别（BIO要么是输入流，要么是输出流，不能双向）</li>
<li>Channel是双向的，可以反映操作系统底层的情况，比如Linux，底层的通道就是双向的</li>
</ol>
<h4 id="缓冲区（Buffer）"><a href="#缓冲区（Buffer）" class="headerlink" title="缓冲区（Buffer）"></a>缓冲区（Buffer）</h4><p> 基本介绍：    </p>
<ol>
<li>缓冲区本质上是一个可以读写数据的内存块，可以理解为是一个容器对象（数组），该对象提供一组方法，可以轻松跟踪和记录缓存区的状态变换情况。Channel提供从文件、网络读取数据的渠道，但是读取或写入的数据都必须经由Buffer。如图：<br><img src="https://yh-blog-files.oss-cn-hangzhou.aliyuncs.com/2021/09/27/16327501871455.jpg" alt="16327501871455"></li>
<li>Buffer类定义了所有的缓冲区都具有4个属性来提供关于其所包含的数据元素的信息：<br><img src="https://yh-blog-files.oss-cn-hangzhou.aliyuncs.com/2021/09/27/16327501702766.jpg" alt="16327501702766"></li>
<li>Buffer类相关方法<br><img src="https://yh-blog-files.oss-cn-hangzhou.aliyuncs.com/2021/09/27/16327503987878.jpg" alt="16327503987878"><br><strong>ByteBuffer</strong>：<br> 对于Java中的基本数据类型（boolean）除外，都有一个Buffer类型与之相对应，最常用的自然是ByteBuffer类（二进制数据），该类的主要方法：<br><img src="https://yh-blog-files.oss-cn-hangzhou.aliyuncs.com/2021/09/27/16327506868826.jpg" alt="16327506868826"></li>
</ol>
<h4 id="通道（Channel）"><a href="#通道（Channel）" class="headerlink" title="通道（Channel）"></a>通道（Channel）</h4><p>基本介绍：</p>
<ol>
<li>NIO的通道类似于流，但是有些区别：<ol>
<li>通道可以同时进行读写，而流只能读或者只能写</li>
<li>通道可以实现异步读写数据</li>
<li>通道可以从缓冲读数据，也可以写数据到缓冲</li>
</ol>
</li>
<li>BIO的stream是单向的，例如FileInputStream对象只能进行读取数据的操作，而NIO中的通道（Channel）是双向的，可以读操作，也可以写操作。</li>
<li>Channel在NIO中是一个接口</li>
<li>常用的Channel类有：FileChannel、DatagramChannel、ServerSocketChannel和SocketChannel（ServerSocketChannel -&gt; Java ServerSocket；SocketChannel -&gt; Java Socket）</li>
<li>FileChannel用于文件读写，DatagramChannel用于udp的数据读写，ServerSocketChannel和SocketChannel用于tcp数据读写<br><img src="https://yh-blog-files.oss-cn-hangzhou.aliyuncs.com/2021/09/27/16327523590487.jpg" alt="16327523590487"></li>
</ol>
<p><strong>FileChannel类</strong><br>FileChannel主要用于对本地文件进行IO操作，常见的方法有<br><img src="https://yh-blog-files.oss-cn-hangzhou.aliyuncs.com/2021/09/27/16327525043113.jpg" alt="16327525043113"><br><img src="https://yh-blog-files.oss-cn-hangzhou.aliyuncs.com/2021/09/27/16327537673560.jpg" alt="16327537673560"></p>
<p><strong>关于Buffer和Channel的注意事项和细节</strong></p>
<ol>
<li>Buffer支持类型化的put和get，put放入的是什么数据类型，get就应该使用相应的数据类型来取出，否则可能有BufferUnderflowException。</li>
<li>可以将一个普通Buffer转成只读Buffer。</li>
<li>NIO还提供了MappedByteBuffer，可以让文件直接在内存（堆外内存）中进行修改，而如何同步到文件由NIO来完成。</li>
<li>前面我们讲的读写操作，都是通过一个Buffer来完成的，NIO还支持通过多个Buffer（即Buffer数组）完成读写操作，即Scattering（分散）和Gathering（合并）。</li>
</ol>
<h4 id="选择器（Selector）"><a href="#选择器（Selector）" class="headerlink" title="选择器（Selector）"></a>选择器（Selector）</h4><ol>
<li>Java的NIO，用非阻塞的IO方式。可以用一个线程，处理多个的客户端连接，就会使用到Selector（选择器）。</li>
<li><strong>Selector能够检测多个注册的通道上是否有事件发生（注意：多个Channel以事件的方式可以注册到同一个Selector）</strong>，如果有事件发生，便获取事件然后针对每个事件进行相应的处理。这样就可以只用一个单线程去管理多个通道，也就是管理多个连接和请求。</li>
<li>只有连接真正有读写事件发生时，才会进行读写，就大大地减少了系统开销，并且不必为每个连接都创建一个线程，不用去维护多个线程</li>
<li>避免了多线程之间的上下文切换导致的开销。<br><strong>特点再说明：</strong><ol>
<li>Netty的IO线程NioEventLoop聚合了Selector（选择器，也叫多路复用器），可以同时并发处理成百上千个客户端连接。</li>
<li>当线程从某个客户端Socket通道进行读写数据时，若没有数据可用时，该线程可以进行其他任务。</li>
<li>线程通常将非阻塞IO的空闲时间用于在其他通道上执行IO操作，所以单独的线程可以管理多个输入和输出通道。</li>
<li>由于读写操作时非阻塞的，这就可以充分提升IO线程的运行效率，避免由于频繁的IO阻塞导致线程挂起。</li>
<li>一个IO线程可以并发的处理N个客户端连接和读写操作，这从根本上解决传统同步阻塞IO一连接一线程模型，架构的性能、弹性伸缩能力和可靠性都得到了极大的提升。</li>
<li>Selector相关方法说明： <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">selector.select();// 阻塞</span><br><span class="line">selector.select(1000);// 阻塞1秒，在1秒后返回</span><br><span class="line">selector.wakeup();// 唤醒selector</span><br><span class="line">selector.selectNow();// 不阻塞，立即返回</span><br></pre></td></tr></table></figure>
<strong>NIO非阻塞网络编程原理分析图</strong></li>
</ol>
</li>
</ol>
<p><img src="https://yh-blog-files.oss-cn-hangzhou.aliyuncs.com/2021/10/08/16336985904631.jpg" alt="16336985904631"><br>    说明：<br>        1. 当客户端连接时，会通过ServerSocketChannel得到SocketChannel。<br>        2. 将socketChannel注册到Selector上（register(Selector selector, int ops)），一个selector上可以注册多个SocketChannel。<br>        3. 注册后返回一个selectionKey，会和该Selector关联（集合）。<br>        4. Selector进行监听（select方法），返回有时间发生的通道个数,得到各个SelectionKey<br>        5. 通过SelectionKey反向获取SocketChannel（channel方法）<br>        6. 最后可以通过得到channel，完成业务处理</p>
<h5 id="SelectionKey"><a href="#SelectionKey" class="headerlink" title="SelectionKey"></a>SelectionKey</h5><p>SelectionKey,表示Selector和网络通道的注册关系，共4种：<br>    * OP_ACCEPT：有新的网络连接可以accept，值为16<br>    * OP_CONNECT：代表连接已经建立，值为8<br>    * OP_READ：代表读操作，值为1<br>    * OP_WRITE：代表写操作，值为4<br><img src="https://yh-blog-files.oss-cn-hangzhou.aliyuncs.com/2021/10/13/16341300676869.jpg" alt="16341300676869"></p>
<h5 id="ServerSocketChannel"><a href="#ServerSocketChannel" class="headerlink" title="ServerSocketChannel"></a>ServerSocketChannel</h5><ol>
<li>ServerSocketChannel在服务器端监听新的客户端Socket连接</li>
<li>相关方法<br><img src="https://yh-blog-files.oss-cn-hangzhou.aliyuncs.com/2021/10/13/16341310234601.jpg" alt="16341310234601"><h5 id="SocketChannel"><a href="#SocketChannel" class="headerlink" title="SocketChannel"></a>SocketChannel</h5></li>
<li>SocketChannel，网络IO通道，具体负责进行读写操作。NIO把缓冲区的数据写入通道，或者把通道里的数据读到缓冲区。</li>
<li>相关方法<br><img src="https://yh-blog-files.oss-cn-hangzhou.aliyuncs.com/2021/10/13/16341315034228.jpg" alt="16341315034228"><h3 id="NIO网络编程应用实例-群聊系统"><a href="#NIO网络编程应用实例-群聊系统" class="headerlink" title="NIO网络编程应用实例-群聊系统"></a>NIO网络编程应用实例-群聊系统</h3></li>
<li>编写一个NIO群聊系统，实现服务器和客户端之间的数据简单通讯（非阻塞）</li>
<li>实现多人群聊</li>
<li>服务端：可以监测用户上下线，并实现消息转发功能</li>
<li>客户端：通过Channel可以无阻塞发送消息给其它所有用户，同时可以接受其它用户发送的消息（由服务器转发得到）</li>
<li>目的：进一步理解NIO非阻塞网络编程<h3 id="NIO于零拷贝"><a href="#NIO于零拷贝" class="headerlink" title="NIO于零拷贝"></a>NIO于零拷贝</h3></li>
<li>零拷贝（没有CPU拷贝）是网络编程的关键，很多性能优化都离不开。</li>
<li>在Java程序中，常用的零拷贝有mmap（内存映射）和sendFile。<h4 id="传统IO"><a href="#传统IO" class="headerlink" title="传统IO"></a>传统IO</h4><strong>4次拷贝，3次切换状态</strong><br>DMA：direct memory access（直接内存访问）<br><img src="https://yh-blog-files.oss-cn-hangzhou.aliyuncs.com/2021/10/16/16343550358155.jpg" alt="16343550358155"><h4 id="mmap优化"><a href="#mmap优化" class="headerlink" title="mmap优化"></a>mmap优化</h4><strong>3次拷贝，3次切换状态</strong><br><img src="https://yh-blog-files.oss-cn-hangzhou.aliyuncs.com/2021/10/16/16343550554506.jpg" alt="16343550554506"><h4 id="sendFile优化"><a href="#sendFile优化" class="headerlink" title="sendFile优化"></a>sendFile优化</h4></li>
<li>Linux2.1版本提供了sendFile函数，其基本原理如下：数据根本不用经过用户态，直接从内核缓冲区进入到Socket Buffer，同时，由于和用户态完全无关，就减少了一次上下文切换。<br><strong>3次拷贝，2次切换状态</strong><br><img src="https://yh-blog-files.oss-cn-hangzhou.aliyuncs.com/2021/10/16/16343554344704.jpg" alt="16343554344704"></li>
<li>Linux2.4版本中，做了一些修改，避免从内核缓冲区拷贝到Socket Buffer的操作，直接拷贝到协议栈，从而又一次减少了数据拷贝。<br><strong>2次拷贝*，2次切换状态</strong><br><img src="https://yh-blog-files.oss-cn-hangzhou.aliyuncs.com/2021/10/16/16343557877424.jpg" alt="16343557877424"><br>*这里其实是有一次cpu拷贝的，但是拷贝的信息很少，拷贝一些元数据（length，offset..）,消耗很低，可以忽略<h4 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h4></li>
<li>我们说零拷贝，是从操作系统的角度来说的。因为内核缓冲区之间，没有数据重复的（只有Kernel buffer中有一份数据）。</li>
<li>零拷贝不仅仅带来更少的数据复制，还能带来其他的性能优势，例如更少的上下文切换，更少的CPU缓存伪共享以及无CPU校验和计算。<h3 id="Java-AIO"><a href="#Java-AIO" class="headerlink" title="Java AIO"></a>Java AIO</h3></li>
<li>JDK7引入了Asynchronous IO，即AIO。在进行IO编程中，常用到两种模式：Reactor和Proactor。Java的NIO就是Reactor，当有事件触发时，服务端得到通知，进行相应的处理</li>
<li>AIO及NIO2.0，叫做异步不阻塞的IO。AIO引入异步通道的概念，采用了Proactor模式，简化了程序编写，有效的请求才启动线程，它的特点是先由操作系统完成后才通知服务端程序启动线程去处理，一般适用于连接数较多且连接事件较长的应用</li>
<li>目前AIO还没有广泛应用，Netty也是基于NIO的<h2 id="Netty-1"><a href="#Netty-1" class="headerlink" title="Netty"></a>Netty</h2><img src="https://yh-blog-files.oss-cn-hangzhou.aliyuncs.com/2021/10/17/16344771397316.jpg" alt="16344771397316"><h3 id="原生NIO存在的问题"><a href="#原生NIO存在的问题" class="headerlink" title="原生NIO存在的问题"></a>原生NIO存在的问题</h3></li>
<li>NIO的类库和API繁杂，使用麻烦：需要熟练掌握Selector、ServerSocketChannel、SocketChannel、ByteBuffer等。</li>
<li>需要具备其他额外的技能：要熟悉java多线程编程，因为NIO编程涉及到Reactor模式，你必须对多线程网络编程非常熟悉，才能编写出高质量的NIO程序。</li>
<li>开发工作量和难度非常大：例如客户端面临断连重连、网络闪断、半包读写、失败缓存、网络拥塞和异常流的处理等等。</li>
<li>JDK NIO的BUG：例如臭名昭著的Epoll Bug，它会导致Selector空轮询，最终导致CPU 100%。直到JDK1.7版本该问题依旧存在，没有被根本解决。<h3 id="Netty高性能架构设计"><a href="#Netty高性能架构设计" class="headerlink" title="Netty高性能架构设计"></a>Netty高性能架构设计</h3><h4 id="线程模型基本介绍"><a href="#线程模型基本介绍" class="headerlink" title="线程模型基本介绍"></a>线程模型基本介绍</h4></li>
<li>目前存在的线程模型有：<ul>
<li>传统的阻塞IO服务模型</li>
<li>Reactor模式</li>
</ul>
</li>
<li>根据Reactor的数量和处理资源池线程的数量不同，有3种典型的实现<ul>
<li>单Reactor单线程</li>
<li>单Reactor多线程</li>
<li>主从Reactor多线程</li>
</ul>
</li>
<li>Netty线程模式（Netty主要基于主从Reactor多线程模型做了一定的改进，其中主从Reactor多线程模型有多个Reactor）</li>
</ol>
<p><img src="https://yh-blog-files.oss-cn-hangzhou.aliyuncs.com/2021/10/17/16344787922814.jpg" alt="16344787922814"></p>
<p><img src="https://yh-blog-files.oss-cn-hangzhou.aliyuncs.com/2021/10/17/16344791404243.jpg" alt="16344791404243"><br>说明：<br>    1. Reactor模式，通过一个或多个输入同时传递给服务处理器的模式（基于事件驱动）<br>    2. 服务端程序处理传入的多个请求，并将它们同步分派到相应的处理线程，因此Reactor模式也叫做Dispather模式<br>    3. Reactor模式使用IO复用监听事件，收到事件后，分发给某个线程（进程）。这就是支持高并发的原因</p>
<h4 id="Reactor模式核心组成"><a href="#Reactor模式核心组成" class="headerlink" title="Reactor模式核心组成"></a>Reactor模式核心组成</h4><ol>
<li>Reactor：Reactor在一个单独的线程中运行，负责监听和分发事件，分发给适当的处理程序来对IO事件做出反应。它就像公司的电话接线员，它接听来自客户的电话并将线路转移到适当的联系人。</li>
<li>Handlers：处理程序执行IO事件要完成的实际事件，类似于客户想要与之交谈的公司中的实际人员。Reactor通过调度适当的处理程序来响应IO事件，处理程序执行非阻塞操作。<h3 id="单Reactor单线程"><a href="#单Reactor单线程" class="headerlink" title="单Reactor单线程"></a>单Reactor单线程</h3><img src="https://yh-blog-files.oss-cn-hangzhou.aliyuncs.com/2021/10/18/16345582830238.jpg" alt="16345582830238"></li>
<li>优点：模型简单，没有多线程、进程通信、竞争的问题，全部都在一个线程中完成</li>
<li>缺点：性能问题，只有一个线程，无法完全发挥多核CPU的性能。Handler在处理某个连接上的业务时，整个进程无法处理其他连接事件，很容易导致性能瓶颈；可靠性问题，线程意外终止，或者进入死循环，会导致整个系统通信模块不可用，不能接收和处理外部消息，造成节点故障。</li>
<li>使用场景：客户端数量有限，业务处理非常快速，比如Redis在业务处理的时间复杂度O(1)的情况<h3 id="单Reactor多线程"><a href="#单Reactor多线程" class="headerlink" title="单Reactor多线程"></a>单Reactor多线程</h3><img src="https://yh-blog-files.oss-cn-hangzhou.aliyuncs.com/2021/10/18/16345609747836.jpg" alt="16345609747836"><br>说明：</li>
<li>Reactor对象通过select监控客户端请求事件，收到事件后，通过Dispatch进行分发</li>
<li>如果建立连接请求（accept），则由Accept通过accept处理连接请求，然后创建一个Handler对象处理完成连接后的各种事件</li>
<li>如果不是连接请求，则由Reactor分发调用连接对应的handler来处理</li>
<li>handler只负责响应事件，不做具体的业务处理，通过read读取数据后，会分发给后面的worker线程池的某个线程处理业务</li>
<li>worker线程池会分配独立线程完成真正的业务，并将处理结果返回给handler</li>
<li>handler收到响应后，通过send方法将结果返回给client<br>优点：可以比较充分利用多核cpu的处理能力<br>缺点： 多线程数据共享和访问比较复杂，Reactor还是单线程的，在高并发下也会出现性能瓶颈<h3 id="主从Reactor多线程"><a href="#主从Reactor多线程" class="headerlink" title="主从Reactor多线程"></a>主从Reactor多线程</h3><img src="https://yh-blog-files.oss-cn-hangzhou.aliyuncs.com/2021/10/18/16345622839532.jpg" alt="16345622839532"><br>说明：</li>
<li>Reactor主线程MainReactor对象通过select监听连接事件，收到事件后，通过Acceptor处理连接事件</li>
<li>当Acceptor处理连接事件后，MainReactor将连接分配给SubReactor</li>
<li>SubReactor将连接加入到连接队列，并创建handler进行各种事件的处理</li>
<li>当有新的事件发生时，SubReactor就会调用对应的handler进行处理</li>
<li>handler通过read读取数据，分发给后面的worker线程处理</li>
<li>worker线程池分配独立的worker线程进行处理，并返回结果</li>
<li>handler收到响应后，再通过send将结果返回client</li>
<li>Reactor主线程可以对应多个Reactor子线程，一个MainReactor对应多个SubReactor<br>优点：父线程与子线程的数据交互简单职责明确，父线程只需要接收新连接，子线程完成后续业务处理；父线程与子线程的数据交互简单，Reactor主线程只需要把新连接传给子线程，子线程无需返回数据<br>缺点：编程复杂度较高<br>结合实例：这种模型在许多项目中广泛使用，包括Nginx主从Reactor多线程模型，Memcached主从多线程，Netty主从多线程模型的支持<h3 id="Netty模型"><a href="#Netty模型" class="headerlink" title="Netty模型"></a>Netty模型</h3><h4 id="工作原理示意图1-简单版"><a href="#工作原理示意图1-简单版" class="headerlink" title="工作原理示意图1 - 简单版"></a>工作原理示意图1 - 简单版</h4><img src="https://yh-blog-files.oss-cn-hangzhou.aliyuncs.com/2021/10/18/16345655214458.jpg" alt="16345655214458"><h4 id="工作原理示意图2-进阶版"><a href="#工作原理示意图2-进阶版" class="headerlink" title="工作原理示意图2 - 进阶版"></a>工作原理示意图2 - 进阶版</h4><img src="https://yh-blog-files.oss-cn-hangzhou.aliyuncs.com/2021/10/18/16345656941806.jpg" alt="16345656941806"><h4 id="工作原理示意图-详细版"><a href="#工作原理示意图-详细版" class="headerlink" title="工作原理示意图 - 详细版"></a>工作原理示意图 - 详细版</h4><img src="https://yh-blog-files.oss-cn-hangzhou.aliyuncs.com/2021/10/18/16345658608160.jpg" alt="16345658608160"></li>
<li>Netty 抽象出两组线程池：BossGroup 和 WorkerGroup，也可以叫做 BossNioEventLoopGroup 和WorkerNioEventLoopGroup。每个线程池中都有 NioEventLoop 线程。BossGroup 中的线程专门负责和客户端建立连接，WorkerGroup 中的线程专门负责处理连接上的读写。</li>
<li>BossGroup 和 WorkerGroup 的类型都是 NioEventLoopGroup。</li>
<li>NioEventLoopGroup 相当于一个事件循环组，这个组中含有多个事件循环，每个事件循环就是一个 NioEventLoop。</li>
<li>NioEventLoop 表示一个不断循环的执行事件处理的线程，每个 NioEventLoop 都包含一个 Selector，用于监听注册在其上的 Socket 网络连接（Channel）。</li>
<li>NioEventLoopGroup 可以含有多个线程，即可以含有多个 NioEventLoop。</li>
<li>每个 BossNioEventLoop 中循环执行以下三个步骤：<ol>
<li>select：轮询注册在其上的 ServerSocketChannel 的 accept 事件（OP_ACCEPT 事件）</li>
<li>processSelectedKeys：处理 accept 事件，与客户端建立连接，生成一个 NioSocketChannel，并将其注册到某个 WorkerNioEventLoop 上的 Selector 上</li>
<li>runAllTasks：再去以此循环处理任务队列中的其他任务</li>
</ol>
</li>
<li>每个 WorkerNioEventLoop 中循环执行以下三个步骤：<ol>
<li>select：轮训注册在其上的 NioSocketChannel 的 read&#x2F;write 事件（OP_READ&#x2F;OP_WRITE 事件）</li>
<li>processSelectedKeys：在对应的 NioSocketChannel 上处理 read&#x2F;write 事件</li>
<li>runAllTasks：再去以此循环处理任务队列中的其他任务</li>
</ol>
</li>
<li>在以上两个processSelectedKeys步骤中，会使用 Pipeline（管道），Pipeline 中引用了 Channel，即通过 Pipeline 可以获取到对应的 Channel，Pipeline 中维护了很多的处理器（拦截处理器、过滤处理器、自定义处理器等）。这里暂时不详细展开讲解 Pipeline。<h4 id="任务队列中Task有3种典型的使用场景"><a href="#任务队列中Task有3种典型的使用场景" class="headerlink" title="任务队列中Task有3种典型的使用场景"></a>任务队列中Task有3种典型的使用场景</h4></li>
<li>用户自定义的普通任务 -&gt; TaskQueue</li>
<li>用户自定义定时任务 -&gt; ScheduleTaskQueue</li>
<li>非当前Reactor线程调用Channel的各种方法<br>例如在推送系统的业务线程里面，根据用户的标识，找到对应的Channel引用，然后调用Write类方法向该用户推送消息，就会进入到这种场景。最终的Write会提交到任务队列中后被异步消费<h4 id="异步模型"><a href="#异步模型" class="headerlink" title="异步模型"></a>异步模型</h4></li>
<li>异步的概念和同步相对。当一个异步过程调用发出后，调用者不能立刻得到结果。实际处理这个调用的组件在完成后，通过状态、通知和回调来通知调用者。</li>
<li>Netty中的IO操作是异步的，包括Bind、Write、Connect等操作会简单返回一个ChannelFuture。</li>
<li>调用者不能立刻获得结果，而是通过Future-Listener机制，用户可以方便的主动获取或者通过通知机制获取IO结果。</li>
<li>Netty的异步模型是建立在Future和callback之上的。<br><img src="https://yh-blog-files.oss-cn-hangzhou.aliyuncs.com/2021/10/23/16349582177471.jpg" alt="16349582177471"><h3 id="Netty核心模块组件"><a href="#Netty核心模块组件" class="headerlink" title="Netty核心模块组件"></a>Netty核心模块组件</h3><h4 id="BootStrap、ServerBootStrap"><a href="#BootStrap、ServerBootStrap" class="headerlink" title="BootStrap、ServerBootStrap"></a>BootStrap、ServerBootStrap</h4></li>
<li>BootStrap意思是引导，一个Netty应用通常由一个BootStrap开始，主要作用是配置整个Netty程序，串联各个组件，Netty中BootStrap类是客户端程序的启动引导类，ServerBootStrap是服务端启动引导类</li>
<li>常见方法有：<br><img src="https://yh-blog-files.oss-cn-hangzhou.aliyuncs.com/2021/11/01/16357740744142.jpg" alt="16357740744142"><h4 id="Future、ChannelFuture"><a href="#Future、ChannelFuture" class="headerlink" title="Future、ChannelFuture"></a>Future、ChannelFuture</h4></li>
<li>Netty中所有的IO操作都是异步的，不能立刻得知消息是否被正确处理。通过Future和ChannelFuture，它们可以注册一个监听，当操作执行成功或失败时监听会自动触发注册的监听事件</li>
<li>常见的方法：<br><img src="https://yh-blog-files.oss-cn-hangzhou.aliyuncs.com/2021/11/01/16357744624365.jpg" alt="16357744624365"><h4 id="Channel"><a href="#Channel" class="headerlink" title="Channel"></a>Channel</h4></li>
<li>Netty通信的组件，能够用于执行网络IO操作。</li>
<li>通过Channel可获取当前网络连接的通道的状态。</li>
<li>通过Channel可获得网络连接的配置参数（例如接收缓冲区大小）</li>
<li>Channel提供异步的网络IO操作（如建立连接，读写，绑定端口）。异步调用意味着任何IO调用都将立即返回，并且不保证在调用结束时说请求的IO操作完成。</li>
<li>调用立即返回一个ChannelFuture实例，通过注册监听器到ChannelFuture上，可以IO操作成功、失败或取消时回调通知调用方</li>
<li>支持关联IO操作与对应的处理程序</li>
<li>不同协议、不同的阻塞类型都有不同的Channel类型与之对应，常用的Channel类型：<br><img src="https://yh-blog-files.oss-cn-hangzhou.aliyuncs.com/2021/11/01/16357750690247.jpg" alt="16357750690247"><h4 id="Selector"><a href="#Selector" class="headerlink" title="Selector"></a>Selector</h4></li>
<li>Netty基于Selector对象实现IO多路复用，通过Selector一个线程可以监听多个连接的Channel事件。</li>
<li>当向一个Selector中注册Channel后，Selector内部的机制就可以自动不断的查询（select）这些注册的Channel是否有已就绪的IO事件（例如可读，可写，网络连接完成等），这样程序久可以简单的使用一个线程高效的管理多个Channel<h4 id="ChannelHandler及其实现类"><a href="#ChannelHandler及其实现类" class="headerlink" title="ChannelHandler及其实现类"></a>ChannelHandler及其实现类</h4></li>
<li>ChannelHandler是一个接口，处理IO事件或拦截IO操作，并将其转发到其ChannelPipeline（业务处理链）中的下一个处理程序。</li>
<li>ChannelHandler本身没有提供很多方法，因为这个接口有许多的方法需要实现，方便使用期间，可以继承它的子类</li>
<li>ChannelHandler及其实现类：<br><img src="https://yh-blog-files.oss-cn-hangzhou.aliyuncs.com/2021/11/04/16360306395987.jpg" alt="16360306395987"></li>
</ol>
<ul>
<li>ChannelInboundHandler用于处理入站IO事件。</li>
<li>ChannelOutboundHandler用于处理出站IO操作。</li>
<li>ChannelDuplexHandler既可以用于处理入站IO，也可以处理出站IO<h4 id="Pipeline和ChannelPipeline"><a href="#Pipeline和ChannelPipeline" class="headerlink" title="Pipeline和ChannelPipeline"></a>Pipeline和ChannelPipeline</h4></li>
</ul>
<ol>
<li>ChannelPipeline是一个Handler的集合，它负责处理和拦截inbound或者outbound的事件和操作，相当于一个贯穿Netty的链。</li>
<li>ChannelPipeline实现了一种高级形式的拦截过滤器模式，使用户可以完全控制事件的处理方式，以及CHannel中各个的ChannelHandler如何交互</li>
<li>在Netty中每个Channel都有且仅有一个ChannelPipeline与之对应，它们的组成关系如下<br><img src="https://yh-blog-files.oss-cn-hangzhou.aliyuncs.com/2021/11/10/16365493912838.jpg" alt="16365493912838"></li>
</ol>
<ul>
<li>一个Channel包含了一个ChannelPipeline，而ChannelPipeline中又维护了一个有ChannelHandlerContext组成的双向链表，并且每个ChannelHandlerContext又关联着一个ChannelHandler</li>
<li>入站事件和出站事件在一个双向链表中，入站事件会从链表head往后传递到最后一个入站的handler，出站事件会从链表的tail往前传递到最前一个出站的handler，两种类型的handler互补干扰<h4 id="ChannelHandlerContext"><a href="#ChannelHandlerContext" class="headerlink" title="ChannelHandlerContext"></a>ChannelHandlerContext</h4></li>
</ul>
<ol>
<li>保存Channel相关的所有上下文信息，同时关联一个ChannelHandler对象</li>
<li>即ChannelHandlerContext中包含一个具体的事件处理器ChannelHandler，同时ChannelHandlerContext中也绑定了对应的pipeline和Channel信息，方便对ChannelHandler进行调用。</li>
<li>常用方法：<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">ChannelFuture close(); //关闭通道</span><br><span class="line">ChannelOutBoundInvoker flush(); //刷新</span><br><span class="line">ChannelFuture writeAndFlush(Object msg); //将数据写到ChannelPipeline中当前ChannelHandler的next</span><br></pre></td></tr></table></figure>
<h4 id="ChannelOption"><a href="#ChannelOption" class="headerlink" title="ChannelOption"></a>ChannelOption</h4></li>
<li>Netty在创建Channel实例后，一般都需要设置ChannelOption参数。</li>
<li>ChannelOption参数如下：<ul>
<li>ChannelOption.SO_BACHLOG：对应TCP&#x2F;IP协议listen函数中的backlog参数，用来初始化服务器可连接队列的大小。服务端处理客户端连接请求是顺序处理的，所以同一时间只能处理一个客户端连接。多个客户端来的时候，服务端将不能处理的客户端连接请求放在队列中等待处理，backlog参数指定了队列的大小。</li>
<li>ChannelOption.SO_KEEPALIVE：一直保持连接活动状态。<h4 id="EventLoopGroup和其实现类NioEventLoopGroup"><a href="#EventLoopGroup和其实现类NioEventLoopGroup" class="headerlink" title="EventLoopGroup和其实现类NioEventLoopGroup"></a>EventLoopGroup和其实现类NioEventLoopGroup</h4></li>
</ul>
</li>
<li>EventLoopGroup是一组EventLoop的抽象，Netty为了更好的利用多核CPU资源，一般会有多个EventLoop同时工作，每个EventLoop维护着一个Selector实例。</li>
<li>EventLoopGroup提供next接口，可以从组里面按照一定规则获取其中一个EventLoop来处理任务。在Netty服务端编程中，我们一般都需要提供两个EventLoopGroup，例如：bossEventLoopGroup，workerEventLoopGroup<br><img src="https://yh-blog-files.oss-cn-hangzhou.aliyuncs.com/2021/12/07/16388835610980.jpg" alt="16388835610980"></li>
</ol>
]]></content>
      <categories>
        <category>后端</category>
      </categories>
      <tags>
        <tag>网络编程</tag>
      </tags>
  </entry>
  <entry>
    <title>InnoDB数据存储结构</title>
    <url>/2022/01/15/InnoDB%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8%E7%BB%93%E6%9E%84/</url>
    <content><![CDATA[<h2 id="数据库的存储结构：页"><a href="#数据库的存储结构：页" class="headerlink" title="数据库的存储结构：页"></a>数据库的存储结构：页</h2><p>MySQL服务器上的存储引擎负责对表中的数据的读取和写入工作，不同存储引擎中存放的格式一般不同。此处只剖析InnoDB存储引擎的数据存储结构。</p>
<h3 id="磁盘与内存交互的基本单位：页"><a href="#磁盘与内存交互的基本单位：页" class="headerlink" title="磁盘与内存交互的基本单位：页"></a>磁盘与内存交互的基本单位：页</h3><p>InnoDB将数据划分为若干个页，InnoDB中页的大小默认为<strong>16KB</strong>。</p>
<p><strong>在数据库中，不论读一行，还是读多行，都是将这些行所在的页进行加载，也就是说，数据库管理存储空间的基本单位是页（Page），数据库I&#x2F;O操作的最小单位为页。</strong></p>
<h3 id="页结构概述"><a href="#页结构概述" class="headerlink" title="页结构概述"></a>页结构概述</h3><p><img src="https://yh-blog-files.oss-cn-hangzhou.aliyuncs.com/2022/01/15/16422446514180.jpg" alt="页结构"><br>页a、页b、页c…页n，这些页可以<strong>不在物理结构上相连</strong>，只要通过<strong>双向链表</strong>相关联即可。每个数据页中的记录会按照主键值从小到大的顺序组成一个<strong>单向链表</strong>，每个数据页都会为存储在它里面的记录生成一个<strong>页目录</strong>，在通过主键查找时就可以在页目录中<strong>使用二分法</strong>快速定位到对应的槽，然后再遍历该槽对应分组中的记录即可快速找到指定记录。</p>
<h3 id="页的上层结构"><a href="#页的上层结构" class="headerlink" title="页的上层结构"></a>页的上层结构</h3><p><img src="https://yh-blog-files.oss-cn-hangzhou.aliyuncs.com/2022/01/15/16422451759284.jpg" alt="页的上层结构"></p>
<ul>
<li>区（Extent）是比页大一级的存储结构，在InnoDB存储引擎中，一个区会分配64个连续的页。因为InnoDB中页的默认大小是16KB，所以一个区的大小是 64 * 16KB &#x3D; 1M。</li>
<li>段（Segment）由一个或多个区组成，区在文件系统是一个连续分配的空间（在InnoDB中是连续的64个页），不过在段中不要求区与区之间是相邻的。<strong>段是数据库中的分配单位，不同类型的数据库对象以不同的段形式存在</strong>。当我们创建数据表、索引的时候，就会相应创建对应的段，比如创建一张表时会创建一个表段，创建一个索引时会创建一个索引段。</li>
<li>表空间（TableSpace）是一个逻辑容器，表空间存储的对象是段，在一个表空间中可以有一个或多个段，但是一个段只能属于一个表空间。数据库由一个或多个表空间组成。表空间从管理上可以分为<strong>系统表空间、用户表空间、撤销表空间、临时表空间</strong>等。<h2 id="页的内部结构"><a href="#页的内部结构" class="headerlink" title="页的内部结构"></a>页的内部结构</h2>页如果按类来划分的话，常见的有数据页（保存B+树节点）、系统页、Undo页和事务数据页等。数据页是我们最常使用的页。<br><img src="https://yh-blog-files.oss-cn-hangzhou.aliyuncs.com/2022/01/16/16423369880923.jpg" alt="页的内部结构"><br><img src="https://yh-blog-files.oss-cn-hangzhou.aliyuncs.com/2022/01/16/16423371212785.jpg" alt="页的内部结构"><h2 id="InnoDB行格式（或记录格式）"><a href="#InnoDB行格式（或记录格式）" class="headerlink" title="InnoDB行格式（或记录格式）"></a>InnoDB行格式（或记录格式）</h2><h3 id="COMPACT行格式"><a href="#COMPACT行格式" class="headerlink" title="COMPACT行格式"></a>COMPACT行格式</h3><img src="https://yh-blog-files.oss-cn-hangzhou.aliyuncs.com/2022/01/19/16425967631225.jpg" alt="16425967631225"><h4 id="变长字段长度列表"><a href="#变长字段长度列表" class="headerlink" title="变长字段长度列表"></a>变长字段长度列表</h4>MySQL支持一些变长的数据类型，比如VARCHAR(M)、VARBINARY(M)、TEXT类型，BOLB类型，这些数据类型修饰列称为变长字段。<br><strong>注意：</strong> 这里面存储的变长长度和字段顺序是<strong>反过来</strong>的。比如在表中字段是a(10),b(15)，那么在变长字段列表中存储的长度顺序就是15，10。<br><img src="https://yh-blog-files.oss-cn-hangzhou.aliyuncs.com/2022/01/19/16425971738917.jpg" alt="16425971738917"><h4 id="NULL值列表"><a href="#NULL值列表" class="headerlink" title="NULL值列表"></a>NULL值列表</h4></li>
</ul>
<ol>
<li>二进制位的值为1时，代表该列的值为NULL。</li>
<li>二进制位的值为0时，代表该列的值不为NULL。</li>
<li>NOT NULL的字段没有。<br><img src="https://yh-blog-files.oss-cn-hangzhou.aliyuncs.com/2022/01/19/16425973039144.jpg" alt="16425973039144"><h4 id="记录头信息（5字节）"><a href="#记录头信息（5字节）" class="headerlink" title="记录头信息（5字节）"></a>记录头信息（5字节）</h4><h4 id="记录真实数据"><a href="#记录真实数据" class="headerlink" title="记录真实数据"></a>记录真实数据</h4><img src="https://yh-blog-files.oss-cn-hangzhou.aliyuncs.com/2022/01/19/16425974458867.jpg" alt="16425974458867"><h3 id="Dynamic和Compressed行格式"><a href="#Dynamic和Compressed行格式" class="headerlink" title="Dynamic和Compressed行格式"></a>Dynamic和Compressed行格式</h3><img src="https://yh-blog-files.oss-cn-hangzhou.aliyuncs.com/2022/01/19/16425990444803.jpg" alt="16425990444803"><br>一个页的大小一般是16KB，也就是16384字节，而VARCHAR(M)最多可储存65533个字节。这样就出现了一个页存放不了一条记录，这种现象称为行溢出。<br>Dynamic和Compressed行格式和Compact行格式挺像，只不过在处理行溢出数据时有分歧：</li>
</ol>
<ul>
<li>Dynamic和Compressed两种行格式对于存放在BLOB中的数据采用了完全的行溢出方式，如图，在数据页中只存放20个字节的指针（溢出页的地址），实际的数据都存放在Off Page（溢出页）中。<br><img src="https://yh-blog-files.oss-cn-hangzhou.aliyuncs.com/2022/02/10/16445002427093.jpg" alt="16445002427093"></li>
<li>Compact和Redundant两种格式会在记录的真实数据处存储一部分数据（存放768个前缀字节）。<br><strong>Compressed行记录格式的另一个功能就是，存储在其中的行数据会以zlib的算法进行非常压缩。因此对于BLOL，TEXT，VARCHAR这类大长度类型的数据能够进行非常有效的存储。</strong><h3 id="Redundant行格式"><a href="#Redundant行格式" class="headerlink" title="Redundant行格式"></a>Redundant行格式</h3>Redundant行格式是MySQL5.0版本及之前InnoDB的行记录存储方式。<h2 id="区、段与碎片区"><a href="#区、段与碎片区" class="headerlink" title="区、段与碎片区"></a>区、段与碎片区</h2><h3 id="为什么要有区？"><a href="#为什么要有区？" class="headerlink" title="为什么要有区？"></a>为什么要有区？</h3><code>B+</code>树的每一层中的页都会形成一个双向链表如果<strong>以页为单位</strong>来分配存储空间的话，双向链表相邻的两个页之间的<strong>物理位置可能离的非常远</strong>。 扫描页就会是<strong>随机IO</strong>。随机IO是非常慢的，所以我们应该尽量的让链表中页的<strong>物理位置也相邻</strong>，这样进行范围查询的时候时候才可以使用所谓的<strong>顺序IO</strong>。<br>一个区就是在物理位置上连续的<strong>64个页</strong>。因为InnoDB中的页大小。默认是<strong>16kb</strong>，所以一个区的大小是<strong>64*16&#x3D;1M</strong>。在表中数据量大的时候，为某个索引分配空间的时候就不再按照页为单位分配了，而是按照<strong>区为单位分配</strong>，甚至在表中数据特别多的时候，可以一次性分配多个连续的区。虽然可能造成<strong>一点点空间的浪费</strong>（数据不足以填满整个区），但是从性能角度看，可以消除很多随机IO，<strong>利大于弊</strong>。<h3 id="为什么要有段？"><a href="#为什么要有段？" class="headerlink" title="为什么要有段？"></a>为什么要有段？</h3>对于范围查询，其实是对B+树叶子节点的记录进行顺序扫描，而如果不区分叶子节点和非叶子节点，统统把节点代表的页面放到申请到的区中的话，进行范围扫描的效果就可能会比较差。所以InnoDB对B+树的<strong>叶子节点</strong>和<strong>非叶子节点</strong>进行区别对待，也就是说叶子节点有自己独有的区，非叶子节点也有自己独特的区。存放叶子节点的区的集合就是一个<strong>段（segment）</strong>，存放非叶子节点的区的集合也是一个段。也就是说一个索引会生成2个段，一个<strong>叶子节点段</strong>，一个<strong>非叶子节点段</strong>。</li>
</ul>
<p>除了索引的叶子节点段和非叶子节点段之外，InnoDB中还有为储存一些特殊的数据定义的段，比如回滚段。所以常见的段有<strong>数据段</strong>，<strong>索引段</strong>，<strong>回滚段</strong>。数据段即为B+树的叶子节点，索引段即为非叶子节点段。</p>
<p>段其实不对应表空间中某一个连续的物理区域，而是一个逻辑上的概念，由若干个零散的页面以及一些完整的区组成。</p>
<h3 id="为什么要有碎片区？"><a href="#为什么要有碎片区？" class="headerlink" title="为什么要有碎片区？"></a>为什么要有碎片区？</h3><p>一个区默认占用1M（64*16K）存储空间，所以默认情况下一个只存了几条记录的小表也需要2M存储空间吗？</p>
<p>为了考虑以完整的区为单位分配给某个段，对于<strong>数量较小的</strong>表太浪费存储空间的这种情况，InnoDB提出了一个<strong>碎片区（fragment）</strong> 的概念。在一个碎片区中，并不是所有的页都是为了存储同一个段的数据而存在的，而是碎片区中的页可以用于不同的目的，比如有些页用于段A，有些页用于段B，有些页用于段C，有些页甚至哪个段都不属于。<strong>碎片区直属于表空间</strong>，并不属于任何一个段。</p>
<p>所以此后为某个段分配存储空间的策略是这样的：</p>
<ul>
<li>在刚开始向表中插入数据的时候，段是从某个碎片区以单个页面为单位来分配存储空间的。</li>
<li>当某个段已经占用了<strong>32个碎片</strong>区页面之后，就会申请以完整的区为单位来分配存储空间的。<h3 id="区的分类"><a href="#区的分类" class="headerlink" title="区的分类"></a>区的分类</h3></li>
<li>空闲的区（free）：现在还没有用到这个区中的任何页面。</li>
<li>有剩余空间的碎片区（free_frag）：表示碎片区中还有可用页面。</li>
<li>没有剩余空间的碎片区（full_frag）：表示碎片区的所有页面都被使用，没有空闲的页面。</li>
<li>附属于某个段的区（fseg）：每一个索引都可以分为叶子节点段和非叶子节点段。<br>处于free、free_frag、full_frag都是碎片区，fseg为属于某个段的区。<h2 id="表空间"><a href="#表空间" class="headerlink" title="表空间"></a>表空间</h2>表空间可以看作是InnoDB存储引擎逻辑结构的最高层，所有的数据都存放在表空间中。</li>
</ul>
<p>表空间是一个<strong>逻辑容器</strong>，表空间存储的对象是段，在一个表空间中可以有一个或多个段，但是一个段只能属于一个表空间。数据库由一个或多个表空间组成，表空间从管理上可以划分为<strong>系统表空间</strong>（system Tablespace），<strong>独立表空间</strong>（File-per-table Tablespace）、<strong>撤销表空间</strong>（Undo-tablesapce）和<strong>临时表空间</strong>（Temporary Tablespace）等。</p>
<h3 id="独立表空间"><a href="#独立表空间" class="headerlink" title="独立表空间"></a>独立表空间</h3><h4 id="独立表空间结构"><a href="#独立表空间结构" class="headerlink" title="独立表空间结构"></a>独立表空间结构</h4><p>独立表空间由段、区、页组成。</p>
<h4 id="表空间对应的文件"><a href="#表空间对应的文件" class="headerlink" title="表空间对应的文件"></a>表空间对应的文件</h4><p>一个新建的表对应的 <strong>.idb</strong> 文件文件只占用了<strong>96k</strong>，才6个页面的大小（MySQL5.7），这是因为一开始表中没有数据。随着表中的数据增加，表空间对应的文件也逐渐增大。</p>
<h3 id="系统表空间"><a href="#系统表空间" class="headerlink" title="系统表空间"></a>系统表空间</h3><p>系统表空间和独立表空间基本类似，只不过MySQL只有一个系统表空间，在系统表空间中会额外记录一些有关整个系统信息的页面，这部分是独立表空间没有的。<br><img src="https://yh-blog-files.oss-cn-hangzhou.aliyuncs.com/2022/02/13/16447536181188.jpg" alt="16447536181188"></p>
]]></content>
      <categories>
        <category>后端</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title>RabbitMQ</title>
    <url>/2021/07/31/RabbitMQ/</url>
    <content><![CDATA[<h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p>RabbitMQ是最受欢迎的开源消息中间件之一，在全球范围内被广泛应用。RabbitMQ是轻量级且易于部署的，能支持多种消息协议。RabbitMQ可以部署在分布式系统中，以满足大规模、高可用的要求。</p>
<span id="more"></span>

<h1 id="安装及配置"><a href="#安装及配置" class="headerlink" title="安装及配置"></a>安装及配置</h1><h2 id="Linux安装："><a href="#Linux安装：" class="headerlink" title="Linux安装："></a>Linux安装：</h2><p>下载docker镜像</p>
<pre><code>docker pull rabbitmq:3.7.15
</code></pre>
<p>使用docker命令启动服务</p>
<pre><code>docker run -d -p 5672:5672 -p 15672:15672 --name rabbitmq rabbitmq:3.7.15
</code></pre>
<p>进入容器并开启管理功能</p>
<pre><code>docker exec -it rabbitmq /bin/bash 
rabbitmq-plugins enable rabbitmq_management
</code></pre>
<p>开启防火墙便于外网访问</p>
<h2 id="访问及配置"><a href="#访问及配置" class="headerlink" title="访问及配置"></a>访问及配置</h2><ol>
<li>访问RabbitMQ管理页面地址，查看是否安装成功（Linux下使用服务器IP访问即可）：<a href="http://localhost:15672/">http://localhost:15672</a></li>
<li>输入账号密码并登录，这里使用默认账号密码登录：guest guest</li>
<li>创建帐号并设置其角色为管理员：yh yh<br><img src="https://yh-blog-files.oss-cn-hangzhou.aliyuncs.com/2021/08/16/16291220880322.jpg" alt="16291220880322"></li>
<li>创建一个新的虚拟host为：&#x2F;yh<br><img src="https://yh-blog-files.oss-cn-hangzhou.aliyuncs.com/2021/08/16/16291221215137.jpg" alt="16291221215137"></li>
<li>点击yh用户，给yh用户配置该虚拟host的权限；<br><img src="https://yh-blog-files.oss-cn-hangzhou.aliyuncs.com/2021/08/16/16291221501459.jpg" alt="16291221501459"></li>
<li>至此，RabbitMQ的配置完成。</li>
</ol>
<h1 id="RabbitMQ简介"><a href="#RabbitMQ简介" class="headerlink" title="RabbitMQ简介"></a>RabbitMQ简介</h1><p>RabbitMQ是一个由erlang开发的AMQP(Advanced Message Queue Protocol)的开源实现。</p>
<h2 id="核心概念"><a href="#核心概念" class="headerlink" title="核心概念"></a>核心概念</h2><h3 id="Message"><a href="#Message" class="headerlink" title="Message"></a>Message</h3><blockquote>
<p>消息，消息是不具名的，它由消息头和消息体组成。消息体是不透明的，而消息头则由一系列的可选属性组成，这些属性包括routing-key（路由键）、priority（相对于其他消息的优先权）、delivery-mode（指出该消息可能需要持久性储存）等。</p>
</blockquote>
<h3 id="Publish"><a href="#Publish" class="headerlink" title="Publish"></a>Publish</h3><blockquote>
<p>消息的生产者，也是一个向交换器发布消息的客户端应用程序。</p>
</blockquote>
<h3 id="Exchange"><a href="#Exchange" class="headerlink" title="Exchange"></a>Exchange</h3><blockquote>
<p>交换器，用来接收生产者发送的消息并将这些消息路由给服务器中的队列。Exchange有4种类型：direct（默认），fanout，topic和headers，不同类型的Exchange转发消息的策略有所区别</p>
</blockquote>
<h3 id="Queue"><a href="#Queue" class="headerlink" title="Queue"></a>Queue</h3><blockquote>
<p>消息队列，用来保存消息直到发送给消费者，它是消息的容器，也是消息的终点。一个消息可投入一个或多个队列。消息一直在队列里面，等待消费者连接到这个队列将其取走。</p>
</blockquote>
<h3 id="Binding"><a href="#Binding" class="headerlink" title="Binding"></a>Binding</h3><blockquote>
<p>绑定，用于消息队列和交换器之间的关联。一个绑定就是基于路由键将交换器和消息队列连接起来的路由规则，所以可以将交换器理解为一个由绑定构成的路由表。Exchange和Queue的绑定可以是多对多的关系。</p>
</blockquote>
<h3 id="Connection"><a href="#Connection" class="headerlink" title="Connection"></a>Connection</h3><blockquote>
<p>网络连接，比如一个TCP连接。</p>
</blockquote>
<h3 id="Channel"><a href="#Channel" class="headerlink" title="Channel"></a>Channel</h3><blockquote>
<p>信道，多路复用连接中的一条独立的双向数据流通道。信道是建立在真实的TCP连接内的虚拟连接，AMQP命令都是通过信道发出去的，不管是发布消息、订阅队列还是接收消息，这些都是通过信道完成的。因为对于操作系统来说建立和销毁TCP都是非常昂贵的开销，所以引入信道的概念，以复用一条TCP连接。</p>
</blockquote>
<h3 id="Consumer"><a href="#Consumer" class="headerlink" title="Consumer"></a>Consumer</h3><blockquote>
<p>消息的消费者，表示一个从消息队列中取得消息的客户端应用程序。</p>
</blockquote>
<h3 id="Virtual-Host"><a href="#Virtual-Host" class="headerlink" title="Virtual Host"></a>Virtual Host</h3><blockquote>
<p>虚拟主机，表示一批交换器、消息队列和相关对象。虚拟主机是共享相同身份认证和加密环境的独立服务器域。每个vhost本质上就是一个mini版的RabbitMQ服务器，拥有自己的队列、交换器、绑定和权限机制。vhost是AMQP概念的基础，必须在连接时指定，默认的vhost是&#x2F;。</p>
</blockquote>
<h3 id="Broker"><a href="#Broker" class="headerlink" title="Broker"></a>Broker</h3><blockquote>
<p>表示消息队列服务器实体</p>
</blockquote>
<p><img src="https://yh-blog-files.oss-cn-hangzhou.aliyuncs.com/2021/08/16/16291223199643.jpg" alt="16291223199643"></p>
<h2 id="5种消息模式"><a href="#5种消息模式" class="headerlink" title="5种消息模式"></a>5种消息模式</h2><h3 id="简单模式"><a href="#简单模式" class="headerlink" title="简单模式"></a>简单模式</h3><blockquote>
<p>简单模式是最简单的消息模式，它包含一个生产者、一个消费者和一个队列。生产者向队列里发送消息，消费者从队列中获取消息并消费。</p>
</blockquote>
<p><img src="https://yh-blog-files.oss-cn-hangzhou.aliyuncs.com/2021/08/16/16291223509014.jpg" alt="16291223509014"></p>
<h3 id="工作模式"><a href="#工作模式" class="headerlink" title="工作模式"></a>工作模式</h3><blockquote>
<p>工作模式是指向多个互相竞争的消费者发送消息的模式，它包含一个生产者、两个消费者和一个队列。两个消费者同时绑定到一个队列上去，当消费者获取消息处理耗时任务时，空闲的消费者从队列中获取并消费消息。</p>
</blockquote>
<p><img src="https://yh-blog-files.oss-cn-hangzhou.aliyuncs.com/2021/08/16/16291223898130.jpg" alt="16291223898130"></p>
<h3 id="发布-x2F-订阅模式（fanout）"><a href="#发布-x2F-订阅模式（fanout）" class="headerlink" title="发布&#x2F;订阅模式（fanout）"></a>发布&#x2F;订阅模式（fanout）</h3><blockquote>
<p>发布&#x2F;订阅模式是指同时向多个消费者发送消息的模式（类似广播的形式），它包含一个生产者、两个消费者、两个队列和一个交换机。两个消费者同时绑定到不同的队列上去，两个队列绑定到交换机上去，生产者通过发送消息到交换机，所有消费者接收并消费消息。</p>
</blockquote>
<p><img src="https://yh-blog-files.oss-cn-hangzhou.aliyuncs.com/2021/08/16/16291224068875.jpg" alt="16291224068875"></p>
<h3 id="路由模式（direct）"><a href="#路由模式（direct）" class="headerlink" title="路由模式（direct）"></a>路由模式（direct）</h3><blockquote>
<p>路由模式是可以根据路由键选择性给多个消费者发送消息的模式，它包含一个生产者、两个消费者、两个队列和一个交换机。两个消费者同时绑定到不同的队列上去，两个队列通过路由键绑定到交换机上去，生产者发送消息到交换机，交换机通过路由键转发到不同队列，队列绑定的消费者接收并消费消息。</p>
</blockquote>
<p><img src="https://yh-blog-files.oss-cn-hangzhou.aliyuncs.com/2021/08/16/16291224228449.jpg" alt="16291224228449"></p>
<h3 id="通配符模式（topic）"><a href="#通配符模式（topic）" class="headerlink" title="通配符模式（topic）"></a>通配符模式（topic）</h3><blockquote>
<p>通配符模式是可以根据路由键匹配规则选择性给多个消费者发送消息的模式，它包含一个生产者、两个消费者、两个队列和一个交换机。两个消费者同时绑定到不同的队列上去，两个队列通过路由键匹配规则绑定到交换机上去，生产者发送消息到交换机，交换机通过路由键匹配规则转发到不同队列，队列绑定的消费者接收并消费消息。</p>
</blockquote>
<p><img src="https://yh-blog-files.oss-cn-hangzhou.aliyuncs.com/2021/08/16/16291224454336.jpg" alt="16291224454336"></p>
<h3 id="header模式（header）"><a href="#header模式（header）" class="headerlink" title="header模式（header）"></a>header模式（header）</h3><p>header模式与routing不同的地方在于，header模式取消routingkey，使用header中的<br>key&#x2F;value（键值对）匹配队列。</p>
<h3 id="RPC模式（direct）"><a href="#RPC模式（direct）" class="headerlink" title="RPC模式（direct）"></a>RPC模式（direct）</h3><blockquote>
<p>1、客户端即是生产者就是消费者，向RPC请求队列发送RPC调用消息，同时监听RPC响应队列。</p>
<p>2、服务端监听RPC请求队列的消息，收到消息后执行服务端的方法，得到方法返回的结果。</p>
<p>3、服务端将RPC方法 的结果发送到RPC响应队列。</p>
<p>4、客户端（RPC调用方）监听RPC响应队列，接收到RPC调用结果。</p>
</blockquote>
<p><img src="https://yh-blog-files.oss-cn-hangzhou.aliyuncs.com/2021/08/16/16291225166457.jpg" alt="16291225166457"></p>
<h1 id="消息确认机制-可靠抵达"><a href="#消息确认机制-可靠抵达" class="headerlink" title="消息确认机制-可靠抵达"></a>消息确认机制-可靠抵达</h1><blockquote>
<p>保证消息不丢失，可靠抵达，可以使用事务消息，性能下降250倍，为此引入确认机制</p>
</blockquote>
<ul>
<li><p><strong>publish</strong> cornfirmCallback确认模式</p>
</li>
<li><p><strong>publish</strong> returnCallback未投递到queue退回模式</p>
</li>
<li><p><strong>consumer</strong> ack机制</p>
</li>
</ul>
<p><img src="https://yh-blog-files.oss-cn-hangzhou.aliyuncs.com/2021/08/16/16291226024394.jpg" alt="16291226024394"></p>
<p><img src="https://yh-blog-files.oss-cn-hangzhou.aliyuncs.com/2021/08/16/16291226225999.jpg" alt="16291226225999"></p>
<h1 id="如何保证消息可靠性-消息丢失"><a href="#如何保证消息可靠性-消息丢失" class="headerlink" title="如何保证消息可靠性-消息丢失"></a>如何保证消息可靠性-消息丢失</h1><h2 id="1-消息丢失"><a href="#1-消息丢失" class="headerlink" title="1.消息丢失"></a>1.消息丢失</h2><blockquote>
<p>消息发送出去，由于网络原因未到达服务器</p>
</blockquote>
<ul>
<li><p>做好容错方法，发送消息可能会网络失败，失败后要去重试机制，可记录到数据库，定期重发</p>
</li>
<li><p>做好日志记录，每个消息状态是否被服务器收到都应该记录</p>
</li>
<li><p>做好定期重发，如果消息发送成功，定期去数据库扫描未成功发送的消息进行重发</p>
</li>
</ul>
<blockquote>
<p>消息抵达Broker，Broker要将消息持久化才算成功。此时如果宕机，消息持久化未完成</p>
</blockquote>
<ul>
<li>publisher也必须加入确认回调机制，确认成功的消息，修改数据库消息状态</li>
</ul>
<blockquote>
<p>自动ack的状态下。消费者收到消息，但没来得及处理消息，宕机</p>
</blockquote>
<ul>
<li>开启手动ack，消费成功才移除，消费失败就noack并重新入队</li>
</ul>
<h2 id="2-消息重复"><a href="#2-消息重复" class="headerlink" title="2.消息重复"></a>2.消息重复</h2><blockquote>
<p>消息消费成功，但是手动ack时宕机，导致ack失败，消息被发送给其他消费者</p>
</blockquote>
<blockquote>
<p>消息消费失败，由于重试机制，自动又将消息发出去</p>
</blockquote>
<ul>
<li><p>保证消费业务接口幂等性，处理过了就不处理了</p>
</li>
<li><p>rabbitmq的每一个消息都有redelivered字段，可以获取是否被重新投递过来的，而不是第一次投递</p>
</li>
</ul>
<h2 id="3-消息积压"><a href="#3-消息积压" class="headerlink" title="3.消息积压"></a>3.消息积压</h2><blockquote>
<p>消费者宕机</p>
</blockquote>
<blockquote>
<p>消费者消费能力不足</p>
</blockquote>
<blockquote>
<p>发送者发送流量过大</p>
</blockquote>
<ul>
<li><p>上线更多消费者</p>
</li>
<li><p>先将消息记录到数据库，再慢慢处理</p>
</li>
</ul>
<h2 id="RabbitMQ延时队列（实现定时任务）"><a href="#RabbitMQ延时队列（实现定时任务）" class="headerlink" title="RabbitMQ延时队列（实现定时任务）"></a>RabbitMQ延时队列（实现定时任务）</h2><blockquote>
<p>场景：比如未付款订单，超时一定时间后，系统自动取消订单并释放库存。</p>
</blockquote>
<h3 id="常用解决方案："><a href="#常用解决方案：" class="headerlink" title="常用解决方案："></a>常用解决方案：</h3><p>spring Schedule定时任务轮询数据库</p>
<p><strong>缺点：</strong></p>
<p>消耗系统内存，增加数据库压力，存在时间误差</p>
<p><strong>解决：RabbitMQ的消息ttl和死信Exchange结合</strong></p>
<h3 id="消息的TTL（Time-To-Live）"><a href="#消息的TTL（Time-To-Live）" class="headerlink" title="消息的TTL（Time To Live）"></a>消息的TTL（Time To Live）</h3><ul>
<li><p>消息TTL就是消息的存活时间</p>
</li>
<li><p>RabbitMQ可以对队列和消息分别设置TTL</p>
</li>
<li><p>对队列设置就是队列没有消费者连着的保留时间，也可以对每个单独的消息做单独的设置。超过这个时间，我们认为消息死了，称之为死信。</p>
</li>
<li><p>如果队列设置了。消息也设置了，那么会取小的。所以一个消息如果被路由到不同的队列，这个消息的死亡的时间可能不一样（不同队列设置）。这里单讲单个消息的TTL因为它才是实现延迟任务的关键。可以通过设置消息expiration字段或者x-message-ttl属性来设置时间，两者是一样的效果。</p>
</li>
</ul>
<h3 id="Dead-Letter-Exchanges-DLX"><a href="#Dead-Letter-Exchanges-DLX" class="headerlink" title="Dead Letter Exchanges(DLX)"></a>Dead Letter Exchanges(DLX)</h3><ul>
<li><p>一个消息在满足如下条件下，会进入死信路由，记住这里是路由不是队列，一个路由可以应对很多队列。（什么是死信）</p>
</li>
<li><p>一个消息被消费者拒收了，并且reject方法的参数是requeue是false。也就是说不会被再次放在队列里，被其他消费者使用。（basicNack&#x2F;basicReject）requeue&#x3D;false</p>
</li>
<li><p>上面的消息ttl到了，消息过期</p>
</li>
<li><p>队列的长度限制满了。排在前面的消息会被丢弃或扔到死信路由</p>
</li>
<li><p>Dead Letter Exchange其实就是一个普通的exchange，和创建其他exchange没两样。只是在某一个设置Dead<br>Letter Exchange的队列中有消息过期了，会自动触发消息的转发，发送到Dead Letter Exchange中去。</p>
</li>
<li><p>我们既可以控制消息在一段时间后变成死信，又可以控制变成死信的消息被路由到某一个指定的exchange，结合二者，就可以实现一个延迟队列。</p>
</li>
</ul>
]]></content>
      <categories>
        <category>后端</category>
      </categories>
      <tags>
        <tag>消息队列</tag>
      </tags>
  </entry>
  <entry>
    <title>Shell脚本</title>
    <url>/2021/12/04/Shell%E8%84%9A%E6%9C%AC/</url>
    <content><![CDATA[<h2 id="HelloWorld"><a href="#HelloWorld" class="headerlink" title="HelloWorld"></a>HelloWorld</h2><p>第一个Shell脚本</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#!bin/bash</span><br><span class="line">echo &quot;Hello World!&quot;</span><br></pre></td></tr></table></figure>
<p>输出结果:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Hello World!</span><br></pre></td></tr></table></figure>
<h2 id="Shell变量"><a href="#Shell变量" class="headerlink" title="Shell变量"></a>Shell变量</h2><ol>
<li>定义变量时，变量名不加美元符号：<code>your_name=&quot;yanghap&quot;</code></li>
<li>变量名和等号之间不能有空格，同时，变量名的命名须遵循如下规则：<ol>
<li>命名只能使用英文字母，数字和下划线，首个字符不能以数字开头。</li>
<li>中间不能有空格，可以使用下划线 _。</li>
<li>不能使用标点符号。</li>
<li>不能使用bash里的关键字（可用help命令查看保留关键字）。<h2 id="Shell传递参数"><a href="#Shell传递参数" class="headerlink" title="Shell传递参数"></a>Shell传递参数</h2>我们可以在Shell脚本中传递参数，脚本传递参数的格式为：<code>$n</code>（n为一个数字）,1为第一个参数，2为第二个参数…<br><strong>$0代表执行时文件的文件路径</strong><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#!bin/bash</span><br><span class="line">echo &quot;执行的文件名：$0&quot;;</span><br><span class="line">echo &quot;第一个参数为：$1&quot;;</span><br><span class="line">echo &quot;第二个参数为：$2&quot;;</span><br><span class="line">echo &quot;第三个参数为：$3&quot;;</span><br></pre></td></tr></table></figure>
<code>sh /Users/yh/Downloads/test.sh 1 2 3</code><br>输出结果:<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">执行的文件名：/Users/yh/Downloads/test.sh</span><br><span class="line">第一个参数为：1</span><br><span class="line">第二个参数为：2</span><br><span class="line">第三个参数为：3</span><br></pre></td></tr></table></figure>
<h3 id="几个特殊的参数处理"><a href="#几个特殊的参数处理" class="headerlink" title="几个特殊的参数处理"></a>几个特殊的参数处理</h3></li>
</ol>
</li>
</ol>
<ul>
<li><code>$#</code> 传递到脚本的参数个数</li>
<li><code>$*</code> 以一个单字符串显示所有向脚本传递的参数。如”$*”用「”」括起来的情况、以”$1 $2 … $n”的形式输出所有参数。</li>
<li><code>$$</code> 脚本运行的当前进程ID号</li>
<li><code>$!</code> 后台运行的最后一个进程的ID号</li>
<li><code>$@</code> 与<code>$*</code>相同，但是使用时加引号，并在引号中返回每个参数。如”<code>$@</code>“用「”」括起来的情况、以”<code>$1</code>“ “<code>$2</code>“ … “<code>$n</code>“ 的形式输出所有参数。</li>
<li><code>$-</code> 显示Shell使用的当前选项，与set命令功能相同。</li>
<li><code>$?</code> 显示最后命令的退出状态。0表示没有错误，其他任何值表明有错误。<h2 id="Shell数组"><a href="#Shell数组" class="headerlink" title="Shell数组"></a>Shell数组</h2></li>
</ul>
<ol>
<li>Shell数组用括号来表示，元素用空格分隔开<br><code>array_name=(value1 value2 ... valuen)</code></li>
<li>读取数组：<code>$&#123;array_name[index]&#125;</code><br>实例:<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#!/bin/bash</span><br><span class="line"></span><br><span class="line">my_array=(A B &quot;C&quot; D)</span><br><span class="line"></span><br><span class="line">echo &quot;第一个元素为: $&#123;my_array[0]&#125;&quot;</span><br><span class="line">echo &quot;第二个元素为: $&#123;my_array[1]&#125;&quot;</span><br><span class="line">echo &quot;第三个元素为: $&#123;my_array[2]&#125;&quot;</span><br><span class="line">echo &quot;第四个元素为: $&#123;my_array[3]&#125;&quot;</span><br></pre></td></tr></table></figure>
<h2 id="Shell运算符"><a href="#Shell运算符" class="headerlink" title="Shell运算符"></a>Shell运算符</h2><h3 id="算术运算符"><a href="#算术运算符" class="headerlink" title="算术运算符"></a>算术运算符</h3>+、-、*、&#x2F;、%、&#x3D;（赋值）、&#x3D;&#x3D;（相等）、!&#x3D;(不相等)<br><strong>注意</strong>：<strong>条件表达式</strong>要放在方括号内，并且要有空格，例如: <code>[$a==$b]</code> 是错误的，必须写成 <code>[ $a == $b ]</code>。<h3 id="关系运算符"><a href="#关系运算符" class="headerlink" title="关系运算符"></a>关系运算符</h3>关系运算符只支持数字，不支持字符串，除非字符串的值是数字。</li>
</ol>
<ul>
<li><code>-eq</code>：检测两个数是否相等，相等返回 true。</li>
<li><code>-ne</code>：!&#x3D;</li>
<li><code>-gt</code>：&gt;</li>
<li><code>-lt</code>：&lt;</li>
<li><code>-ge</code>：&gt;&#x3D;</li>
<li><code>-le</code>：&lt;&#x3D;<h3 id="布尔运算符"><a href="#布尔运算符" class="headerlink" title="布尔运算符"></a>布尔运算符</h3></li>
<li><code>!</code>：非运算，表达式为 true 则返回 false，否则返回 true。</li>
<li><code>-o</code>：或运算，有一个表达式为 true 则返回 true。（or）</li>
<li><code>-a</code>：与运算，两个表达式都为 true 才返回 true。（and）<h3 id="逻辑运算符"><a href="#逻辑运算符" class="headerlink" title="逻辑运算符"></a>逻辑运算符</h3></li>
<li><code>&amp;&amp;</code>：逻辑的 AND</li>
<li><code>||</code>：逻辑的 OR<h3 id="字符串运算符"><a href="#字符串运算符" class="headerlink" title="字符串运算符"></a>字符串运算符</h3></li>
<li><code>=</code>：检测两个字符串是否相等，相等返回 true。</li>
<li><code>!=</code>：检测两个字符串是否不相等，不相等返回 true。</li>
<li><code>-z</code>：检测字符串长度是否为0，为0返回 true。</li>
<li><code>-n</code>：检测字符串长度是否不为 0，不为 0 返回 true。</li>
<li><code>$</code>：检测字符串是否不为空，不为空返回 true。<h3 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h3><a href="https://www.runoob.com/linux/linux-shell-basic-operators.html">文件测试运算符</a><h2 id="Shell-echo命令"><a href="#Shell-echo命令" class="headerlink" title="Shell echo命令"></a>Shell echo命令</h2><h3 id="显示普通字符串"><a href="#显示普通字符串" class="headerlink" title="显示普通字符串"></a>显示普通字符串</h3><code>echo &quot;It is a test&quot;</code><h3 id="显示转义字符"><a href="#显示转义字符" class="headerlink" title="显示转义字符"></a>显示转义字符</h3><code>echo &quot;\&quot;It is a test\&quot;&quot;</code><br>结果:<br><code>&quot;It is a test&quot;</code><h3 id="显示变量"><a href="#显示变量" class="headerlink" title="显示变量"></a>显示变量</h3><code>echo &quot;$1&quot;</code><h3 id="显示换行"><a href="#显示换行" class="headerlink" title="显示换行"></a>显示换行</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">echo -e &quot;OK! \n&quot; # -e 开启转义</span><br><span class="line">echo &quot;It is a test&quot;</span><br></pre></td></tr></table></figure>
结果:<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">OK!</span><br><span class="line"></span><br><span class="line">It is a test</span><br></pre></td></tr></table></figure>
<h3 id="显示不换行"><a href="#显示不换行" class="headerlink" title="显示不换行"></a>显示不换行</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#!/bin/sh</span><br><span class="line">echo -e &quot;OK! \c&quot; # -e 开启转义 \c 不换行</span><br><span class="line">echo &quot;It is a test&quot;</span><br></pre></td></tr></table></figure>
结果：<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">OK! It is a test</span><br></pre></td></tr></table></figure>
<h3 id="显示结果定向至文件"><a href="#显示结果定向至文件" class="headerlink" title="显示结果定向至文件"></a>显示结果定向至文件</h3><code>echo &quot;It is a test&quot; &gt; myfile</code><h3 id="原样输出字符串，不进行转义或取变量-用单引号"><a href="#原样输出字符串，不进行转义或取变量-用单引号" class="headerlink" title="原样输出字符串，不进行转义或取变量(用单引号)"></a>原样输出字符串，不进行转义或取变量(用单引号)</h3><code>echo &#39;$name\&quot;&#39;</code><br>结果:<code>$name\&quot;</code><h3 id="显示命令执行结果，使用反引号"><a href="#显示命令执行结果，使用反引号" class="headerlink" title="显示命令执行结果，使用反引号"></a>显示命令执行结果，使用反引号</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">echo `date`</span><br></pre></td></tr></table></figure>
<h2 id="Shell-printf命令"><a href="#Shell-printf命令" class="headerlink" title="Shell printf命令"></a>Shell printf命令</h2><h2 id="Shell-test命令"><a href="#Shell-test命令" class="headerlink" title="Shell test命令"></a>Shell test命令</h2>Shell中的 test 命令用于检查某个条件是否成立，它可以进行数值、字符和文件三个方面的测试。<h3 id="数值测试"><a href="#数值测试" class="headerlink" title="数值测试"></a>数值测试</h3>实例：<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">num1=100</span><br><span class="line">num2=100</span><br><span class="line">if test $[num1] -eq $[num2]</span><br><span class="line">then</span><br><span class="line">    echo &#x27;两个数相等！&#x27;</span><br><span class="line">else</span><br><span class="line">    echo &#x27;两个数不相等！&#x27;</span><br><span class="line">fi</span><br></pre></td></tr></table></figure>
<h3 id="字符串测试"><a href="#字符串测试" class="headerlink" title="字符串测试"></a>字符串测试</h3><h3 id="文件测试"><a href="#文件测试" class="headerlink" title="文件测试"></a>文件测试</h3><h2 id="Shell流程控制"><a href="#Shell流程控制" class="headerlink" title="Shell流程控制"></a>Shell流程控制</h2><h3 id="if"><a href="#if" class="headerlink" title="if"></a>if</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">if condition</span><br><span class="line">then</span><br><span class="line">    command1 </span><br><span class="line">    command2</span><br><span class="line">    ...</span><br><span class="line">    commandN </span><br><span class="line">fi</span><br></pre></td></tr></table></figure>
<h3 id="if-else"><a href="#if-else" class="headerlink" title="if else"></a>if else</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">if condition</span><br><span class="line">then</span><br><span class="line">    command1 </span><br><span class="line">    command2</span><br><span class="line">    ...</span><br><span class="line">    commandN</span><br><span class="line">else</span><br><span class="line">    command</span><br><span class="line">fi</span><br></pre></td></tr></table></figure>
<h3 id="if-else-if-else"><a href="#if-else-if-else" class="headerlink" title="if else-if else"></a>if else-if else</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">if condition1</span><br><span class="line">then</span><br><span class="line">    command1</span><br><span class="line">elif condition2 </span><br><span class="line">then </span><br><span class="line">    command2</span><br><span class="line">else</span><br><span class="line">    commandN</span><br><span class="line">fi</span><br></pre></td></tr></table></figure>
<h3 id="for循环"><a href="#for循环" class="headerlink" title="for循环"></a>for循环</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">for var in item1 item2 ... itemN</span><br><span class="line">do</span><br><span class="line">    command1</span><br><span class="line">    command2</span><br><span class="line">    ...</span><br><span class="line">    commandN</span><br><span class="line">done</span><br></pre></td></tr></table></figure>
实例：<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">for loop in 1 2 3 4 5</span><br><span class="line">do</span><br><span class="line">    echo &quot;The value is: $loop&quot;</span><br><span class="line">done</span><br></pre></td></tr></table></figure>
<h2 id="Shell输入-x2F-输出重定向"><a href="#Shell输入-x2F-输出重定向" class="headerlink" title="Shell输入&#x2F;输出重定向"></a>Shell输入&#x2F;输出重定向</h2></li>
<li><code>command &gt; file</code>：将输出重定向到 file。</li>
<li><code>command &lt; file</code>：将输入重定向到 file。</li>
<li><code>command &gt;&gt; file</code>：将输出以追加的方式重定向到 file。</li>
<li><code>n &gt; file</code>：将文件描述符为 n 的文件重定向到 file。</li>
<li><code>n &gt;&gt; file</code>：将文件描述符为 n 的文件以追加的方式重定向到 file。</li>
<li><code>n &gt;&amp; m</code>：将输出文件 m 和 n 合并。</li>
<li><code>n &lt;&amp; m</code>：将输入文件 m 和 n 合并。</li>
<li><code>&lt;&lt; tag</code>：将开始标记 tag 和结束标记 tag 之间的内容作为输入。<br><strong>注意：</strong> 文件描述符 0 通常是标准输入（STDIN），1 是标准输出（STDOUT），2 是标准错误输出（STDERR）。</li>
</ul>
<p>如果希望屏蔽STDOUT和STDERR，可以这样写：<br><code>command &gt; /dev/null 2&gt;&amp;1</code><br><strong>注意：</strong> 这里的 2 和 &gt; 之间不可以有空格，2&gt; 是一体的时候才表示错误输出。</p>
<h2 id="Shell-文件包含"><a href="#Shell-文件包含" class="headerlink" title="Shell 文件包含"></a>Shell 文件包含</h2><p>和其他语言一样，Shell 也可以包含外部脚本。这样可以很方便的封装一些公用的代码作为一个独立的文件。<br>语法格式如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">. filename   # 注意点号(.)和文件名中间有一空格</span><br><span class="line"></span><br><span class="line">或</span><br><span class="line"></span><br><span class="line">source filename</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>脚本语言</category>
      </categories>
  </entry>
  <entry>
    <title>SpringBoot+Elasticsearch实战</title>
    <url>/2021/10/26/SpringBoot%20ES%E5%AE%9E%E6%88%98/</url>
    <content><![CDATA[<h2 id="一、引入依赖"><a href="#一、引入依赖" class="headerlink" title="一、引入依赖"></a>一、引入依赖</h2><p>本文使用的SpringBoot版本为2.5.4，elasticsearch版本为7.15.0</p>
<span id="more"></span>
<h3 id="1-pom文件如下"><a href="#1-pom文件如下" class="headerlink" title="1. pom文件如下"></a>1. pom文件如下</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;</span><br><span class="line">&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;</span><br><span class="line">         xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt;</span><br><span class="line">    &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;</span><br><span class="line">    &lt;parent&gt;</span><br><span class="line">        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;</span><br><span class="line">        &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt;</span><br><span class="line">        &lt;version&gt;2.5.4&lt;/version&gt;</span><br><span class="line">        &lt;relativePath/&gt; &lt;!-- lookup parent from repository --&gt;</span><br><span class="line">    &lt;/parent&gt;</span><br><span class="line">    &lt;groupId&gt;com.yh&lt;/groupId&gt;</span><br><span class="line">    &lt;artifactId&gt;es-demo&lt;/artifactId&gt;</span><br><span class="line">    &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt;</span><br><span class="line">    &lt;name&gt;es-demo&lt;/name&gt;</span><br><span class="line">    &lt;description&gt;es-demo&lt;/description&gt;</span><br><span class="line">    &lt;properties&gt;</span><br><span class="line">        &lt;java.version&gt;1.8&lt;/java.version&gt;</span><br><span class="line">        &lt;elasticsearch.version&gt;7.15.0&lt;/elasticsearch.version&gt;</span><br><span class="line">    &lt;/properties&gt;</span><br><span class="line">    &lt;dependencies&gt;</span><br><span class="line">        &lt;dependency&gt;</span><br><span class="line">            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;</span><br><span class="line">            &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;</span><br><span class="line">        &lt;/dependency&gt;</span><br><span class="line">        &lt;dependency&gt;</span><br><span class="line">            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;</span><br><span class="line">            &lt;artifactId&gt;spring-boot-configuration-processor&lt;/artifactId&gt;</span><br><span class="line">            &lt;optional&gt;true&lt;/optional&gt;</span><br><span class="line">        &lt;/dependency&gt;</span><br><span class="line">        &lt;dependency&gt;</span><br><span class="line">            &lt;groupId&gt;org.projectlombok&lt;/groupId&gt;</span><br><span class="line">            &lt;artifactId&gt;lombok&lt;/artifactId&gt;</span><br><span class="line">            &lt;optional&gt;true&lt;/optional&gt;</span><br><span class="line">        &lt;/dependency&gt;</span><br><span class="line">        &lt;dependency&gt;</span><br><span class="line">            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;</span><br><span class="line">            &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt;</span><br><span class="line">            &lt;scope&gt;test&lt;/scope&gt;</span><br><span class="line">        &lt;/dependency&gt;</span><br><span class="line">        &lt;!--使用的rest-high-level-client--&gt;</span><br><span class="line">        &lt;dependency&gt;</span><br><span class="line">            &lt;groupId&gt;org.elasticsearch.client&lt;/groupId&gt;</span><br><span class="line">            &lt;artifactId&gt;elasticsearch-rest-high-level-client&lt;/artifactId&gt;</span><br><span class="line">            &lt;version&gt;$&#123;elasticsearch.version&#125;&lt;/version&gt;</span><br><span class="line">        &lt;/dependency&gt;</span><br><span class="line">        &lt;dependency&gt;</span><br><span class="line">            &lt;groupId&gt;org.elasticsearch&lt;/groupId&gt;</span><br><span class="line">            &lt;artifactId&gt;elasticsearch&lt;/artifactId&gt;</span><br><span class="line">            &lt;version&gt;$&#123;elasticsearch.version&#125;&lt;/version&gt;</span><br><span class="line">        &lt;/dependency&gt;</span><br><span class="line">        &lt;dependency&gt;</span><br><span class="line">            &lt;groupId&gt;com.alibaba&lt;/groupId&gt;</span><br><span class="line">            &lt;artifactId&gt;fastjson&lt;/artifactId&gt;</span><br><span class="line">            &lt;version&gt;1.2.70&lt;/version&gt;</span><br><span class="line">            &lt;scope&gt;test&lt;/scope&gt;</span><br><span class="line">        &lt;/dependency&gt;</span><br><span class="line">    &lt;/dependencies&gt;</span><br><span class="line"></span><br><span class="line">    &lt;build&gt;</span><br><span class="line">        &lt;plugins&gt;</span><br><span class="line">            &lt;plugin&gt;</span><br><span class="line">                &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;</span><br><span class="line">                &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt;</span><br><span class="line">                &lt;configuration&gt;</span><br><span class="line">                    &lt;excludes&gt;</span><br><span class="line">                        &lt;exclude&gt;</span><br><span class="line">                            &lt;groupId&gt;org.projectlombok&lt;/groupId&gt;</span><br><span class="line">                            &lt;artifactId&gt;lombok&lt;/artifactId&gt;</span><br><span class="line">                        &lt;/exclude&gt;</span><br><span class="line">                    &lt;/excludes&gt;</span><br><span class="line">                &lt;/configuration&gt;</span><br><span class="line">            &lt;/plugin&gt;</span><br><span class="line">        &lt;/plugins&gt;</span><br><span class="line">    &lt;/build&gt;</span><br><span class="line"></span><br><span class="line">&lt;/project&gt;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h3 id="2-application-yml配置如下"><a href="#2-application-yml配置如下" class="headerlink" title="2. application.yml配置如下"></a>2. application.yml配置如下</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">elasticsearch:</span><br><span class="line">  host-arr:</span><br><span class="line">    - 127.0.0.1:9200</span><br></pre></td></tr></table></figure>
<h2 id="二、ES-SpringBoot配置"><a href="#二、ES-SpringBoot配置" class="headerlink" title="二、ES SpringBoot配置"></a>二、ES SpringBoot配置</h2><h3 id="1-配置ES服务器地址"><a href="#1-配置ES服务器地址" class="headerlink" title="1. 配置ES服务器地址"></a>1. 配置ES服务器地址</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">package com.yh.esdemo.config;</span><br><span class="line"></span><br><span class="line">import lombok.Getter;</span><br><span class="line">import lombok.Setter;</span><br><span class="line">import org.springframework.boot.context.properties.ConfigurationProperties;</span><br><span class="line">import org.springframework.stereotype.Component;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">/**</span><br><span class="line"> * @author : yh</span><br><span class="line"> * @date : 2021/8/30 20:35</span><br><span class="line"> */</span><br><span class="line">@Component</span><br><span class="line">@Getter</span><br><span class="line">@Setter</span><br><span class="line">@ConfigurationProperties(prefix = &quot;elasticsearch&quot;)</span><br><span class="line">public class EsHostConfig &#123;</span><br><span class="line"></span><br><span class="line">    private String[] hostArr;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="2-配置RestHighLevelClient"><a href="#2-配置RestHighLevelClient" class="headerlink" title="2. 配置RestHighLevelClient"></a>2. 配置RestHighLevelClient</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">package com.yh.esdemo.config;</span><br><span class="line"></span><br><span class="line">import org.apache.http.HttpHost;</span><br><span class="line">import org.elasticsearch.client.RestClient;</span><br><span class="line">import org.elasticsearch.client.RestHighLevelClient;</span><br><span class="line">import org.springframework.beans.factory.annotation.Autowired;</span><br><span class="line">import org.springframework.context.annotation.Bean;</span><br><span class="line">import org.springframework.context.annotation.Configuration;</span><br><span class="line"></span><br><span class="line">/**</span><br><span class="line"> * 定义RestClient Bean</span><br><span class="line"> *</span><br><span class="line"> * @author : yh</span><br><span class="line"> * @date : 2021/8/30 20:32</span><br><span class="line"> */</span><br><span class="line">@Configuration</span><br><span class="line">public class EsRestClientConfig &#123;</span><br><span class="line"></span><br><span class="line">    @Autowired</span><br><span class="line">    private EsHostConfig esHostConfig;</span><br><span class="line"></span><br><span class="line">    @Bean</span><br><span class="line">    public RestHighLevelClient restHighLevelClient() &#123;</span><br><span class="line">        String[] hostArr = esHostConfig.getHostArr();</span><br><span class="line">        int size = hostArr.length;</span><br><span class="line">        HttpHost[] httpHostArr = new HttpHost[size];</span><br><span class="line">        for (int i = 0; i &lt; size; i++) &#123;</span><br><span class="line">            String[] split = hostArr[i].split(&quot;:&quot;);</span><br><span class="line">            httpHostArr[i] = new HttpHost(split[0], Integer.parseInt(split[1]), &quot;http&quot;);</span><br><span class="line">        &#125;</span><br><span class="line">        return new RestHighLevelClient(RestClient.builder(httpHostArr));</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><em><strong>配置完成后只需在相关业务中注入RestHighLevelClient即可使用</strong></em></p>
<h2 id="三、ES基本使用"><a href="#三、ES基本使用" class="headerlink" title="三、ES基本使用"></a>三、ES基本使用</h2><h3 id="索引操作"><a href="#索引操作" class="headerlink" title="索引操作"></a>索引操作</h3><h4 id="1-创建索引"><a href="#1-创建索引" class="headerlink" title="1. 创建索引"></a>1. 创建索引</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">@Test</span><br><span class="line">public void addIndex() throws Exception &#123;</span><br><span class="line">    //获取 IndicesClient ，用于创建 Index</span><br><span class="line">    IndicesClient indices = restHighLevelClient.indices();</span><br><span class="line">    //定义一个 CreateIndexRequest ，参数为索引的名称</span><br><span class="line">    CreateIndexRequest createIndexRequest = new CreateIndexRequest(&quot;yh_customer&quot;);</span><br><span class="line">    //CreateIndexRequest配置相关参数 number_of_shards：分片数  number_of_replicas：每个分片的副本数</span><br><span class="line">    createIndexRequest.settings(</span><br><span class="line">            Settings.builder()</span><br><span class="line">                    .put(&quot;index.number_of_shards&quot;, 1)</span><br><span class="line">                    .put(&quot;index.number_of_replicas&quot;, 0)</span><br><span class="line">    );</span><br><span class="line">    Map&lt;String, Object&gt; name = new HashMap&lt;&gt;();</span><br><span class="line">    name.put(&quot;type&quot;, &quot;text&quot;);</span><br><span class="line">    name.put(&quot;analyzer&quot;, &quot;ik_max_word&quot;);//指定分词器</span><br><span class="line">    name.put(&quot;search_analyzer&quot;, &quot;ik_smart&quot;);</span><br><span class="line">    Map&lt;String, Object&gt; timestamp = new HashMap&lt;&gt;();</span><br><span class="line">    timestamp.put(&quot;type&quot;, &quot;date&quot;);</span><br><span class="line">    timestamp.put(&quot;format&quot;, &quot;yyyy-MM-dd HH:mm:ss&quot;);//指定时间格式</span><br><span class="line">    Map&lt;String, Object&gt; uuid = new HashMap&lt;&gt;();</span><br><span class="line">    uuid.put(&quot;type&quot;, &quot;keyword&quot;);</span><br><span class="line">    Map&lt;String, Object&gt; properties = new HashMap&lt;&gt;();</span><br><span class="line">    properties.put(&quot;name&quot;, name);</span><br><span class="line">    properties.put(&quot;timestamp&quot;, timestamp);</span><br><span class="line">    properties.put(&quot;uuid&quot;, uuid);</span><br><span class="line">    Map&lt;String, Object&gt; mapping = new HashMap&lt;&gt;();</span><br><span class="line">    mapping.put(&quot;properties&quot;, properties);</span><br><span class="line">    //创建mapping  mapping可以理解为此索引中数据的数据结构</span><br><span class="line">    createIndexRequest.mapping(mapping);</span><br><span class="line">    //创建索引 此方法同步返回结果  异步使用 createAsync</span><br><span class="line">    CreateIndexResponse createIndexResponse = indices.create(createIndexRequest, RequestOptions.DEFAULT);</span><br><span class="line">    //创建结果（true/false）</span><br><span class="line">    System.out.println(createIndexResponse.isAcknowledged());</span><br><span class="line">    //输出创建成功的索引名称</span><br><span class="line">    System.out.println(createIndexResponse.index());</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>最终输出:<br><img src="https://yh-blog-files.oss-cn-hangzhou.aliyuncs.com/2021/10/26/16352546351035.jpg" alt="16352546351035"></p>
<h4 id="2-删除索引"><a href="#2-删除索引" class="headerlink" title="2. 删除索引"></a>2. 删除索引</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">@Test</span><br><span class="line">public void delIndex() throws Exception &#123;</span><br><span class="line">    IndicesClient indices = restHighLevelClient.indices();</span><br><span class="line">    DeleteIndexRequest deleteIndexRequest = new DeleteIndexRequest(&quot;yh_customer&quot;);</span><br><span class="line">    AcknowledgedResponse deleteIndexResponse = indices.delete(deleteIndexRequest, RequestOptions.DEFAULT);</span><br><span class="line">    System.out.println(deleteIndexResponse.isAcknowledged());</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="增删改查"><a href="#增删改查" class="headerlink" title="增删改查"></a>增删改查</h3><h4 id="1-添加数据（单个）"><a href="#1-添加数据（单个）" class="headerlink" title="1. 添加数据（单个）"></a>1. 添加数据（单个）</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">@Test</span><br><span class="line">public void addDoc() throws Exception &#123;</span><br><span class="line">    SimpleDateFormat simpleDateFormat = new SimpleDateFormat(&quot;yyyy-MM-dd HH:mm:ss&quot;);</span><br><span class="line">    String timestamp = simpleDateFormat.format(new Date());</span><br><span class="line">    Map&lt;String, Object&gt; jsonMap = new HashMap&lt;&gt;();</span><br><span class="line">    jsonMap.put(&quot;uuid&quot;, &quot;534523dqw4qweq24324&quot;);</span><br><span class="line">    jsonMap.put(&quot;name&quot;, &quot;张三&quot;);</span><br><span class="line">    jsonMap.put(&quot;timestamp&quot;, timestamp);</span><br><span class="line">    //创建 IndexRequest 指定id</span><br><span class="line">    IndexRequest indexRequest = new IndexRequest(&quot;yh_customer&quot;).id(&quot;1&quot;).source(jsonMap);</span><br><span class="line">    IndexResponse indexResponse = restHighLevelClient.index(indexRequest, RequestOptions.DEFAULT);</span><br><span class="line">    System.out.println(indexResponse);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>最终输出：<br><img src="https://yh-blog-files.oss-cn-hangzhou.aliyuncs.com/2021/10/26/16352570339401.jpg" alt="16352570339401"></p>
<h4 id="2-批量添加数据"><a href="#2-批量添加数据" class="headerlink" title="2. 批量添加数据"></a>2. 批量添加数据</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">    @Test</span><br><span class="line">    public void bulkTest() &#123;</span><br><span class="line">        //批量添加使用 BulkRequest</span><br><span class="line">        BulkRequest bulkRequest = new BulkRequest();</span><br><span class="line">        for (int i = 0; i &lt; 100; i++) &#123;</span><br><span class="line">            Customer customer = new Customer(UUID.randomUUID().toString().replace(&quot;-&quot;, &quot;&quot;), i + &quot;号客户&quot;, LocalDateTime.now());</span><br><span class="line">            //String data = JSONObject.toJSONString(customer);</span><br><span class="line">            String data = JSONObject.toJSONStringWithDateFormat(customer, &quot;yyyy-MM-dd HH:mm:ss&quot;);</span><br><span class="line">            IndexRequest request = new IndexRequest(&quot;yh_customer&quot;).source(data, XContentType.JSON);</span><br><span class="line">            bulkRequest.add(request);</span><br><span class="line">        &#125;</span><br><span class="line">        //同步</span><br><span class="line">//        try &#123;</span><br><span class="line">//            BulkResponse bulk = restHighLevelClient.bulk(bulkRequest, RequestOptions.DEFAULT);</span><br><span class="line">//            boolean hasFailures = bulk.hasFailures();</span><br><span class="line">//            if (hasFailures) &#123;</span><br><span class="line">//                List&lt;BulkItemResponse&gt; collect = Arrays.stream(bulk.getItems()).filter(BulkItemResponse::isFailed).collect(Collectors.toList());</span><br><span class="line">//                System.out.println(collect.size());</span><br><span class="line">//                String msg = bulk.buildFailureMessage();</span><br><span class="line">//                System.out.println(msg);</span><br><span class="line">//            &#125;</span><br><span class="line">//        &#125; catch (IOException e) &#123;</span><br><span class="line">//            e.printStackTrace();</span><br><span class="line">//        &#125;</span><br><span class="line"></span><br><span class="line">        //异步</span><br><span class="line">        restHighLevelClient.bulkAsync(bulkRequest, RequestOptions.DEFAULT, new ActionListener&lt;BulkResponse&gt;() &#123;</span><br><span class="line">            //成功回调</span><br><span class="line">            @Override</span><br><span class="line">            public void onResponse(BulkResponse bulkItemResponses) &#123;</span><br><span class="line">                System.out.println(&quot;success&quot;);</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            //失败回调</span><br><span class="line">            @Override</span><br><span class="line">            public void onFailure(Exception e) &#123;</span><br><span class="line">                System.out.println(&quot;failure&quot;);</span><br><span class="line">                e.printStackTrace();</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;);</span><br><span class="line"></span><br><span class="line">        try &#123;</span><br><span class="line">            TimeUnit.MINUTES.sleep(5);</span><br><span class="line">        &#125; catch (InterruptedException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>
<p>最终输出：<br><img src="https://yh-blog-files.oss-cn-hangzhou.aliyuncs.com/2021/10/26/16352575817746.jpg" alt="16352575817746"></p>
<h4 id="3-修改数据"><a href="#3-修改数据" class="headerlink" title="3. 修改数据"></a>3. 修改数据</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">@Test</span><br><span class="line">public void updateDoc() throws Exception &#123;</span><br><span class="line">    UpdateRequest updateRequest = new UpdateRequest(&quot;yh_customer&quot;, &quot;1&quot;);</span><br><span class="line">    Map&lt;String, Object&gt; jsonMap = new HashMap&lt;&gt;();</span><br><span class="line">    jsonMap.put(&quot;name&quot;, &quot;李四&quot;);</span><br><span class="line">    updateRequest.doc(jsonMap);</span><br><span class="line">    UpdateResponse update = restHighLevelClient.update(updateRequest, RequestOptions.DEFAULT);</span><br><span class="line">    System.out.println(update);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>最终输出:<br><img src="https://yh-blog-files.oss-cn-hangzhou.aliyuncs.com/2021/10/26/16352577179296.jpg" alt="16352577179296"></p>
<h4 id="4-获取数据"><a href="#4-获取数据" class="headerlink" title="4. 获取数据"></a>4. 获取数据</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">@Test</span><br><span class="line">public void get() throws Exception &#123;</span><br><span class="line">    GetRequest getRequest = new GetRequest(&quot;yh_customer&quot;);</span><br><span class="line">    getRequest.id(&quot;1&quot;);</span><br><span class="line">    GetResponse getResponse = restHighLevelClient.get(getRequest, RequestOptions.DEFAULT);</span><br><span class="line">    System.out.println(getResponse);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>最终输出：<br><img src="https://yh-blog-files.oss-cn-hangzhou.aliyuncs.com/2021/10/26/16352579192385.jpg" alt="16352579192385"></p>
<h4 id="5-直接获取source"><a href="#5-直接获取source" class="headerlink" title="5. 直接获取source"></a>5. 直接获取source</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">@Test</span><br><span class="line">public void getSource() throws Exception &#123;</span><br><span class="line">    GetSourceRequest getRequest = new GetSourceRequest(&quot;yh_customer&quot;, &quot;1&quot;);</span><br><span class="line">    GetSourceResponse source = restHighLevelClient.getSource(getRequest, RequestOptions.DEFAULT);</span><br><span class="line">    System.out.println(source);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>最终输出：<br><img src="https://yh-blog-files.oss-cn-hangzhou.aliyuncs.com/2021/10/26/16352580418359.jpg" alt="16352580418359"></p>
<h3 id="判断是否存在"><a href="#判断是否存在" class="headerlink" title="判断是否存在"></a>判断是否存在</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">@Test</span><br><span class="line">public void exists() throws Exception &#123;</span><br><span class="line">    GetRequest getRequest = new GetRequest(&quot;yh_customer&quot;);</span><br><span class="line">    getRequest.id(&quot;1&quot;);</span><br><span class="line">    boolean exists = restHighLevelClient.exists(getRequest, RequestOptions.DEFAULT);</span><br><span class="line">    System.out.println(exists);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>最终输出:<br><img src="https://yh-blog-files.oss-cn-hangzhou.aliyuncs.com/2021/10/26/16352578138427.jpg" alt="16352578138427"></p>
<h2 id="四、ES简单搜索"><a href="#四、ES简单搜索" class="headerlink" title="四、ES简单搜索"></a>四、ES简单搜索</h2><h3 id="根据条件搜索"><a href="#根据条件搜索" class="headerlink" title="根据条件搜索"></a>根据条件搜索</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">@Test</span><br><span class="line">public void search() throws Exception &#123;</span><br><span class="line">    SearchRequest searchRequest = new SearchRequest(&quot;yh_customer&quot;);//没有参数，查询所有索引</span><br><span class="line">    //构建搜索条件</span><br><span class="line">    SearchSourceBuilder searchSourceBuilder = new SearchSourceBuilder();</span><br><span class="line">    //根据name字段搜索</span><br><span class="line">    searchSourceBuilder.query(QueryBuilders.matchQuery(&quot;name&quot;, &quot;1&quot;));</span><br><span class="line">    searchRequest.source(searchSourceBuilder);</span><br><span class="line">    SearchResponse search = restHighLevelClient.search(searchRequest, RequestOptions.DEFAULT);</span><br><span class="line">    //返回命中数据</span><br><span class="line">    SearchHits hits = search.getHits();</span><br><span class="line">    for (SearchHit hit : hits.getHits()) &#123;</span><br><span class="line">        String sourceAsString = hit.getSourceAsString();</span><br><span class="line">        Customer customer = JSONObject.parseObject(sourceAsString, Customer.class);</span><br><span class="line">        System.out.println(customer);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>最终输出:<br><img src="https://yh-blog-files.oss-cn-hangzhou.aliyuncs.com/2021/10/26/16352583920483.jpg" alt="16352583920483"></p>
<h3 id="查询所有"><a href="#查询所有" class="headerlink" title="查询所有"></a>查询所有</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">@Test</span><br><span class="line">public void simpleSearch() throws Exception &#123;</span><br><span class="line">    //创建搜索request</span><br><span class="line">    SearchRequest searchRequest = new SearchRequest(&quot;bank&quot;);</span><br><span class="line">    SearchSourceBuilder searchSourceBuilder = new SearchSourceBuilder();</span><br><span class="line">    searchSourceBuilder.query(QueryBuilders.matchAllQuery());//检索所有字段</span><br><span class="line">    SearchRequest request = searchRequest.source(searchSourceBuilder);</span><br><span class="line">    SearchResponse search = restHighLevelClient.search(request, RequestOptions.DEFAULT);</span><br><span class="line">    SearchHits hits = search.getHits();//命中条数</span><br><span class="line">    System.out.println(&quot;总条数：&quot; + hits.getTotalHits().value);</span><br><span class="line">    for (SearchHit hit : hits) &#123;//默认只检索出10条</span><br><span class="line">        Staff staff = JSONObject.parseObject(hit.getSourceAsString(), Staff.class);</span><br><span class="line">        System.out.println(staff);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>最终输出：<br><img src="https://yh-blog-files.oss-cn-hangzhou.aliyuncs.com/2021/10/27/16353396396063.jpg" alt="16353396396063"></p>
<h2 id="五、ES聚合搜索"><a href="#五、ES聚合搜索" class="headerlink" title="五、ES聚合搜索"></a>五、ES聚合搜索</h2><p><em><strong>需要先导入官方提供的测试数据（使用kibana）</strong></em></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">    @Test</span><br><span class="line">    public void aggSearch() throws Exception &#123;</span><br><span class="line">        //创建搜索request</span><br><span class="line">        SearchRequest searchRequest = new SearchRequest(&quot;bank&quot;);</span><br><span class="line">        SearchSourceBuilder searchSourceBuilder = new SearchSourceBuilder();</span><br><span class="line">        //查询条件</span><br><span class="line">        searchSourceBuilder.query(QueryBuilders.matchAllQuery());</span><br><span class="line">        //统计各个年龄的平均工资</span><br><span class="line">        searchSourceBuilder.aggregation(AggregationBuilders.terms(&quot;ageAgg&quot;).field(&quot;age&quot;).subAggregation(AggregationBuilders.avg(&quot;balanceAvgAgg&quot;).field(&quot;balance&quot;)));</span><br><span class="line">        //所有人平均工资</span><br><span class="line">        searchSourceBuilder.aggregation(AggregationBuilders.avg(&quot;allBalanceAvgAgg&quot;).field(&quot;balance&quot;));</span><br><span class="line">        //构建request</span><br><span class="line">        SearchRequest request = searchRequest.source(searchSourceBuilder);</span><br><span class="line">        //search</span><br><span class="line">        SearchResponse searchResponse = restHighLevelClient.search(request, RequestOptions.DEFAULT);</span><br><span class="line">        //Aggregations aggregations = searchResponse.getAggregations();</span><br><span class="line">        //Aggregation接口有很多实现类  Avg（平均值）</span><br><span class="line">//        Avg avg = aggregations.get(&quot;balanceAgg&quot;);</span><br><span class="line">//        System.out.println(avg.getValue());</span><br><span class="line">        Aggregations aggregations = searchResponse.getAggregations();</span><br><span class="line">        Terms ageAgg = aggregations.get(&quot;ageAgg&quot;);</span><br><span class="line">        List&lt;? extends Terms.Bucket&gt; buckets = ageAgg.getBuckets();</span><br><span class="line">        for (Terms.Bucket bucket : buckets) &#123;//只查出了10条数据</span><br><span class="line">            System.out.println(&quot;年龄:&quot; + bucket.getKey());</span><br><span class="line">            System.out.println(&quot;人数:&quot; + bucket.getDocCount());</span><br><span class="line">            Avg avg = bucket.getAggregations().get(&quot;balanceAvgAgg&quot;);</span><br><span class="line">            System.out.println(&quot;平均工资:&quot; + avg.getValue());</span><br><span class="line">            System.out.println(&quot;=================================&quot;);</span><br><span class="line">        &#125;</span><br><span class="line">        Avg avg = aggregations.get(&quot;allBalanceAvgAgg&quot;);</span><br><span class="line">        System.out.println(&quot;所有人平均工资:&quot; + avg.getValue());</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>
<p>最终输出：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">年龄:31</span><br><span class="line">人数:61</span><br><span class="line">平均工资:28312.918032786885</span><br><span class="line">=================================</span><br><span class="line">年龄:39</span><br><span class="line">人数:60</span><br><span class="line">平均工资:25269.583333333332</span><br><span class="line">=================================</span><br><span class="line">年龄:26</span><br><span class="line">人数:59</span><br><span class="line">平均工资:23194.813559322032</span><br><span class="line">=================================</span><br><span class="line">年龄:32</span><br><span class="line">人数:52</span><br><span class="line">平均工资:23951.346153846152</span><br><span class="line">=================================</span><br><span class="line">年龄:35</span><br><span class="line">人数:52</span><br><span class="line">平均工资:22136.69230769231</span><br><span class="line">=================================</span><br><span class="line">年龄:36</span><br><span class="line">人数:52</span><br><span class="line">平均工资:22174.71153846154</span><br><span class="line">=================================</span><br><span class="line">年龄:22</span><br><span class="line">人数:51</span><br><span class="line">平均工资:24731.07843137255</span><br><span class="line">=================================</span><br><span class="line">年龄:28</span><br><span class="line">人数:51</span><br><span class="line">平均工资:28273.882352941175</span><br><span class="line">=================================</span><br><span class="line">年龄:33</span><br><span class="line">人数:50</span><br><span class="line">平均工资:25093.94</span><br><span class="line">=================================</span><br><span class="line">年龄:34</span><br><span class="line">人数:49</span><br><span class="line">平均工资:26809.95918367347</span><br><span class="line">=================================</span><br><span class="line">所有人平均工资:25714.837</span><br></pre></td></tr></table></figure>
<p>demo地址：<a href="https://github.com/yangh124/es-demo">https://github.com/yangh124/es-demo</a></p>
]]></content>
      <categories>
        <category>后端</category>
      </categories>
      <tags>
        <tag>elastic search</tag>
        <tag>实战</tag>
      </tags>
  </entry>
  <entry>
    <title>Redisson分布式锁（使用注解方式）</title>
    <url>/2022/05/30/Redisson%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81%EF%BC%88%E4%BD%BF%E7%94%A8%E6%B3%A8%E8%A7%A3%E6%96%B9%E5%BC%8F%EF%BC%89/</url>
    <content><![CDATA[<h2 id="引入pom依赖"><a href="#引入pom依赖" class="headerlink" title="引入pom依赖"></a>引入pom依赖</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&lt;dependency&gt;</span><br><span class="line">    &lt;groupId&gt;org.redisson&lt;/groupId&gt;</span><br><span class="line">    &lt;artifactId&gt;redisson-spring-boot-starter&lt;/artifactId&gt;</span><br><span class="line">    &lt;version&gt;3.13.1&lt;/version&gt;</span><br><span class="line">&lt;/dependency&gt;</span><br></pre></td></tr></table></figure>
<h2 id="配置RedissonClient"><a href="#配置RedissonClient" class="headerlink" title="配置RedissonClient"></a>配置RedissonClient</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">import org.redisson.Redisson;</span><br><span class="line">import org.redisson.api.RedissonClient;</span><br><span class="line">import org.redisson.config.Config;</span><br><span class="line">import org.redisson.config.SingleServerConfig;</span><br><span class="line">import org.redisson.config.TransportMode;</span><br><span class="line">import org.springframework.beans.factory.annotation.Value;</span><br><span class="line">import org.springframework.context.annotation.Bean;</span><br><span class="line">import org.springframework.context.annotation.Configuration;</span><br><span class="line"></span><br><span class="line">/**</span><br><span class="line"> * @author : yh</span><br><span class="line"> * @date : 2021/11/29 14:03</span><br><span class="line"> */</span><br><span class="line">@Configuration</span><br><span class="line">public class RedissonConfig &#123;</span><br><span class="line"></span><br><span class="line">    @Value(&quot;$&#123;spring.redis.host&#125;&quot;)</span><br><span class="line">    private String host;</span><br><span class="line"></span><br><span class="line">    @Value(&quot;$&#123;spring.redis.port&#125;&quot;)</span><br><span class="line">    private int port;</span><br><span class="line"></span><br><span class="line">    @Value(&quot;$&#123;spring.redis.password&#125;&quot;)</span><br><span class="line">    private String password;</span><br><span class="line"></span><br><span class="line">    @Bean</span><br><span class="line">    public RedissonClient redissonClient() &#123;</span><br><span class="line">        Config config = new Config();</span><br><span class="line">        // 这里使用最简单的单机模式</span><br><span class="line">        SingleServerConfig singleServerConfig = config.useSingleServer();</span><br><span class="line">        singleServerConfig.setAddress(&quot;redis://&quot; + host + &quot;:&quot; + port);</span><br><span class="line">        singleServerConfig.setPassword(password);</span><br><span class="line">        return Redisson.create(config);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="自定义RedissonLock注解"><a href="#自定义RedissonLock注解" class="headerlink" title="自定义RedissonLock注解"></a>自定义RedissonLock注解</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">import java.lang.annotation.*;</span><br><span class="line">import java.util.concurrent.TimeUnit;</span><br><span class="line"></span><br><span class="line">/**</span><br><span class="line"> * @author : yh</span><br><span class="line"> * @date : 2022/5/27 16:05</span><br><span class="line"> */</span><br><span class="line">@Target(&#123;ElementType.METHOD&#125;)</span><br><span class="line">@Retention(RetentionPolicy.RUNTIME)</span><br><span class="line">@Documented</span><br><span class="line">@Inherited</span><br><span class="line">public @interface RedissonLock &#123;</span><br><span class="line"></span><br><span class="line">    /**</span><br><span class="line">     * 锁的key</span><br><span class="line">     */</span><br><span class="line">    String value();</span><br><span class="line"></span><br><span class="line">    /**</span><br><span class="line">     * 锁的key SpEL 表达式</span><br><span class="line">     * </span><br><span class="line">     */</span><br><span class="line">    String key() default &quot;&quot;;</span><br><span class="line"></span><br><span class="line">    /**</span><br><span class="line">     * 加锁时间</span><br><span class="line">     *</span><br><span class="line">     */</span><br><span class="line">    long time() default -1;</span><br><span class="line"></span><br><span class="line">    /**</span><br><span class="line">     * 时间单位</span><br><span class="line">     *</span><br><span class="line">     */</span><br><span class="line">    TimeUnit timeUnit() default TimeUnit.SECONDS;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="定义Aspect"><a href="#定义Aspect" class="headerlink" title="定义Aspect"></a>定义Aspect</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">import java.util.Objects;</span><br><span class="line">import java.util.concurrent.TimeUnit;</span><br><span class="line"></span><br><span class="line">import org.aspectj.lang.ProceedingJoinPoint;</span><br><span class="line">import org.aspectj.lang.annotation.AfterThrowing;</span><br><span class="line">import org.aspectj.lang.annotation.Around;</span><br><span class="line">import org.aspectj.lang.annotation.Aspect;</span><br><span class="line">import org.aspectj.lang.annotation.Pointcut;</span><br><span class="line">import org.aspectj.lang.reflect.MethodSignature;</span><br><span class="line">import org.redisson.api.RLock;</span><br><span class="line">import org.redisson.api.RedissonClient;</span><br><span class="line">import org.springframework.beans.factory.annotation.Autowired;</span><br><span class="line">import org.springframework.beans.factory.annotation.Value;</span><br><span class="line">import org.springframework.core.DefaultParameterNameDiscoverer;</span><br><span class="line">import org.springframework.expression.EvaluationContext;</span><br><span class="line">import org.springframework.expression.spel.standard.SpelExpressionParser;</span><br><span class="line">import org.springframework.expression.spel.support.StandardEvaluationContext;</span><br><span class="line">import org.springframework.stereotype.Component;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">/**</span><br><span class="line"> * @author : yh</span><br><span class="line"> * @date : 2022/5/27 16:07</span><br><span class="line"> */</span><br><span class="line">@Component</span><br><span class="line">@Aspect</span><br><span class="line">public class RedissonLockAspect &#123;</span><br><span class="line"></span><br><span class="line">    @Autowired</span><br><span class="line">    private RedissonClient redissonClient;</span><br><span class="line">    </span><br><span class="line">    // redis key全局前缀</span><br><span class="line">    @Value(&quot;$&#123;spring.redis.prefix&#125;&quot;)</span><br><span class="line">    private String redisPrefix;</span><br><span class="line"></span><br><span class="line">    /**</span><br><span class="line">     * 用于SpEL表达式解析</span><br><span class="line">     */</span><br><span class="line">    private final SpelExpressionParser spelExpressionParser = new SpelExpressionParser();</span><br><span class="line">    /**</span><br><span class="line">     * 用于获取方法参数定义名字</span><br><span class="line">     */</span><br><span class="line">    private final DefaultParameterNameDiscoverer defaultParameterNameDiscoverer = new DefaultParameterNameDiscoverer();</span><br><span class="line"></span><br><span class="line">    @Pointcut(&quot;@annotation(com.xxx.annotation.RedissonLock)&quot;)</span><br><span class="line">    public void LockAspect() &#123;&#125;</span><br><span class="line"></span><br><span class="line">    @Around(&quot;LockAspect()&quot;)</span><br><span class="line">    public Object around(ProceedingJoinPoint proceedingJoinPoint) throws Throwable &#123;</span><br><span class="line">        Object object;</span><br><span class="line">        RLock lock = null;</span><br><span class="line">        try &#123;</span><br><span class="line">            // 获取注解实体信息</span><br><span class="line">            RedissonLock lockEntity =</span><br><span class="line">                (((MethodSignature)proceedingJoinPoint.getSignature()).getMethod()).getAnnotation(RedissonLock.class);</span><br><span class="line">            String key = lockEntity.key();</span><br><span class="line">            String cacheName = lockEntity.value();</span><br><span class="line">            long time = lockEntity.time();</span><br><span class="line">            TimeUnit timeUnit = lockEntity.timeUnit();</span><br><span class="line">            // 根据名字获取锁实例</span><br><span class="line">            lock = redissonClient.getLock(getKey(cacheName, key, proceedingJoinPoint));</span><br><span class="line">            // 这里加锁失败会阻塞等待；也可以使用tryLock，不阻塞，加锁失败返回flase，自行处理后续逻辑（比如抛异常）</span><br><span class="line">            lock.lock(time, timeUnit);</span><br><span class="line">            object = proceedingJoinPoint.proceed();</span><br><span class="line">        &#125; finally &#123;</span><br><span class="line">            if (Objects.nonNull(lock) &amp;&amp; lock.isHeldByCurrentThread()) &#123;</span><br><span class="line">                lock.unlock();</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        return object;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    @AfterThrowing(value = &quot;LockAspect()&quot;, throwing = &quot;ex&quot;)</span><br><span class="line">    public void afterThrowing(Throwable ex) &#123;</span><br><span class="line">        throw new RuntimeException(ex);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    /**</span><br><span class="line">     * 获取缓存的key</span><br><span class="line">     *</span><br><span class="line">     * key 定义在注解上，支持SPEL表达式 cacheName 为缓存的名称</span><br><span class="line">     * </span><br><span class="line">     *</span><br><span class="line">     * @return 缓存的key -&gt; redisPrefix:cacheName:SpELVal</span><br><span class="line">     */</span><br><span class="line">    public String getKey(String cacheName, String spel, ProceedingJoinPoint proceedingJoinPoint) &#123;</span><br><span class="line">        MethodSignature methodSignature = (MethodSignature)proceedingJoinPoint.getSignature();</span><br><span class="line">        String[] paramNames = defaultParameterNameDiscoverer.getParameterNames(methodSignature.getMethod());</span><br><span class="line">        if (!&quot;&quot;.equals(spel) &amp;&amp; null != paramNames &amp;&amp; paramNames.length &gt; 0) &#123;</span><br><span class="line">            EvaluationContext context = new StandardEvaluationContext();</span><br><span class="line">            Object[] args = proceedingJoinPoint.getArgs();</span><br><span class="line">            for (int i = 0; i &lt; args.length; i++) &#123;</span><br><span class="line">                context.setVariable(paramNames[i], args[i]);</span><br><span class="line">            &#125;</span><br><span class="line">            Object value = spelExpressionParser.parseExpression(spel).getValue(context);</span><br><span class="line">            if (null != value) &#123;</span><br><span class="line">                return redisPrefix + &quot;:&quot; + cacheName + &quot;:&quot; + value;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        return redisPrefix + &quot;:&quot; + cacheName;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="使用"><a href="#使用" class="headerlink" title="使用"></a>使用</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">// 也可以指定加锁时间 time设值</span><br><span class="line">@RedissonLock(value = &quot;test:lock&quot;, key = &quot;#id&quot;)</span><br><span class="line">public void testLock(Long id) &#123;</span><br><span class="line">    // ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="查看redis中的锁"><a href="#查看redis中的锁" class="headerlink" title="查看redis中的锁"></a>查看redis中的锁</h2><p><img src="https://yh-blog-files.oss-cn-hangzhou.aliyuncs.com/2022/05/30/16539146066735.jpg" alt="16539146066735"></p>
]]></content>
      <categories>
        <category>后端</category>
      </categories>
      <tags>
        <tag>分布式</tag>
      </tags>
  </entry>
  <entry>
    <title>SpringBoot+RabbitMQ实战</title>
    <url>/2021/10/29/SpringBoot%20RabbitMQ%E5%AE%9E%E6%88%98/</url>
    <content><![CDATA[<h2 id="一、引入依赖"><a href="#一、引入依赖" class="headerlink" title="一、引入依赖"></a>一、引入依赖</h2><p>本文使用的SpringBoot版本为2.5.4</p>
<h3 id="1-pom文件"><a href="#1-pom文件" class="headerlink" title="1.pom文件"></a>1.pom文件</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;</span><br><span class="line">&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt;</span><br><span class="line">    &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;</span><br><span class="line">    &lt;parent&gt;</span><br><span class="line">        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;</span><br><span class="line">        &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt;</span><br><span class="line">        &lt;version&gt;2.5.4&lt;/version&gt;</span><br><span class="line">        &lt;relativePath /&gt; &lt;!-- lookup parent from repository --&gt;</span><br><span class="line">    &lt;/parent&gt;</span><br><span class="line">    &lt;groupId&gt;com.yh&lt;/groupId&gt;</span><br><span class="line">    &lt;artifactId&gt;rabbitmq-demo&lt;/artifactId&gt;</span><br><span class="line">    &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt;</span><br><span class="line">    &lt;name&gt;rabbitmq-demo&lt;/name&gt;</span><br><span class="line">    &lt;description&gt;rabbitmq-demo&lt;/description&gt;</span><br><span class="line">    &lt;properties&gt;</span><br><span class="line">        &lt;java.version&gt;1.8&lt;/java.version&gt;</span><br><span class="line">    &lt;/properties&gt;</span><br><span class="line">    &lt;dependencies&gt;</span><br><span class="line">        &lt;dependency&gt;</span><br><span class="line">            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;</span><br><span class="line">            &lt;artifactId&gt;spring-boot-starter-amqp&lt;/artifactId&gt;</span><br><span class="line">        &lt;/dependency&gt;</span><br><span class="line">        &lt;dependency&gt;</span><br><span class="line">            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;</span><br><span class="line">            &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;</span><br><span class="line">        &lt;/dependency&gt;</span><br><span class="line"></span><br><span class="line">        &lt;dependency&gt;</span><br><span class="line">            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;</span><br><span class="line">            &lt;artifactId&gt;spring-boot-configuration-processor&lt;/artifactId&gt;</span><br><span class="line">            &lt;optional&gt;true&lt;/optional&gt;</span><br><span class="line">        &lt;/dependency&gt;</span><br><span class="line">        &lt;dependency&gt;</span><br><span class="line">            &lt;groupId&gt;org.projectlombok&lt;/groupId&gt;</span><br><span class="line">            &lt;artifactId&gt;lombok&lt;/artifactId&gt;</span><br><span class="line">            &lt;optional&gt;true&lt;/optional&gt;</span><br><span class="line">        &lt;/dependency&gt;</span><br><span class="line">        &lt;dependency&gt;</span><br><span class="line">            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;</span><br><span class="line">            &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt;</span><br><span class="line">            &lt;scope&gt;test&lt;/scope&gt;</span><br><span class="line">        &lt;/dependency&gt;</span><br><span class="line">        &lt;dependency&gt;</span><br><span class="line">            &lt;groupId&gt;org.springframework.amqp&lt;/groupId&gt;</span><br><span class="line">            &lt;artifactId&gt;spring-rabbit-test&lt;/artifactId&gt;</span><br><span class="line">            &lt;scope&gt;test&lt;/scope&gt;</span><br><span class="line">        &lt;/dependency&gt;</span><br><span class="line">        &lt;!-- https://mvnrepository.com/artifact/com.alibaba/fastjson --&gt;</span><br><span class="line">        &lt;dependency&gt;</span><br><span class="line">            &lt;groupId&gt;com.alibaba&lt;/groupId&gt;</span><br><span class="line">            &lt;artifactId&gt;fastjson&lt;/artifactId&gt;</span><br><span class="line">            &lt;version&gt;1.2.78&lt;/version&gt;</span><br><span class="line">        &lt;/dependency&gt;</span><br><span class="line">    &lt;/dependencies&gt;</span><br><span class="line"></span><br><span class="line">    &lt;build&gt;</span><br><span class="line">        &lt;plugins&gt;</span><br><span class="line">            &lt;plugin&gt;</span><br><span class="line">                &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;</span><br><span class="line">                &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt;</span><br><span class="line">                &lt;configuration&gt;</span><br><span class="line">                    &lt;excludes&gt;</span><br><span class="line">                        &lt;exclude&gt;</span><br><span class="line">                            &lt;groupId&gt;org.projectlombok&lt;/groupId&gt;</span><br><span class="line">                            &lt;artifactId&gt;lombok&lt;/artifactId&gt;</span><br><span class="line">                        &lt;/exclude&gt;</span><br><span class="line">                    &lt;/excludes&gt;</span><br><span class="line">                &lt;/configuration&gt;</span><br><span class="line">            &lt;/plugin&gt;</span><br><span class="line">        &lt;/plugins&gt;</span><br><span class="line">    &lt;/build&gt;</span><br><span class="line"></span><br><span class="line">&lt;/project&gt;</span><br></pre></td></tr></table></figure>
<h3 id="2-application-yml文件"><a href="#2-application-yml文件" class="headerlink" title="2.application.yml文件"></a>2.application.yml文件</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">spring:</span><br><span class="line">  rabbitmq:</span><br><span class="line">    host: 192.168.2.9</span><br><span class="line">    port: 5672</span><br><span class="line">    username: yh</span><br><span class="line">    password: yh</span><br></pre></td></tr></table></figure>
<h2 id="二、RabbitMQ-SpringBoot配置"><a href="#二、RabbitMQ-SpringBoot配置" class="headerlink" title="二、RabbitMQ SpringBoot配置"></a>二、RabbitMQ SpringBoot配置</h2><h3 id="1-配置RabbitTemplate"><a href="#1-配置RabbitTemplate" class="headerlink" title="1.配置RabbitTemplate"></a>1.配置RabbitTemplate</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">package com.yh.rabbitmqdemo.config;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">import lombok.extern.slf4j.Slf4j;</span><br><span class="line">import org.springframework.amqp.rabbit.connection.ConnectionFactory;</span><br><span class="line">import org.springframework.amqp.rabbit.core.RabbitTemplate;</span><br><span class="line">import org.springframework.amqp.support.converter.Jackson2JsonMessageConverter;</span><br><span class="line">import org.springframework.amqp.support.converter.MessageConverter;</span><br><span class="line">import org.springframework.context.annotation.Bean;</span><br><span class="line">import org.springframework.context.annotation.Configuration;</span><br><span class="line">import org.springframework.context.annotation.DependsOn;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">/**</span><br><span class="line"> * rabbitmq 配置</span><br><span class="line"> *</span><br><span class="line"> * @author : yh</span><br><span class="line"> * @date : 2021/9/9 20:12</span><br><span class="line"> */</span><br><span class="line">@Slf4j</span><br><span class="line">@Configuration</span><br><span class="line">public class RabbitMqConfig &#123;</span><br><span class="line"></span><br><span class="line">    @DependsOn(&quot;messageConverter&quot;)</span><br><span class="line">    @Bean(&quot;rabbitTemplate&quot;)</span><br><span class="line">    public RabbitTemplate rabbitTemplate(ConnectionFactory connectionFactory) &#123;</span><br><span class="line">        RabbitTemplate rabbitTemplate = new RabbitTemplate(connectionFactory);</span><br><span class="line">        rabbitTemplate.setMessageConverter(messageConverter());</span><br><span class="line">        return rabbitTemplate;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    /**</span><br><span class="line">     * 配置消息转换器</span><br><span class="line">     */</span><br><span class="line">    @Bean</span><br><span class="line">    public MessageConverter messageConverter() &#123;</span><br><span class="line">        return new Jackson2JsonMessageConverter();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="2-定义交换机（Exchange）"><a href="#2-定义交换机（Exchange）" class="headerlink" title="2.定义交换机（Exchange）"></a>2.定义交换机（Exchange）</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">package com.yh.rabbitmqdemo.rabbitmq;</span><br><span class="line"></span><br><span class="line">import org.springframework.amqp.core.Exchange;</span><br><span class="line">import org.springframework.amqp.core.ExchangeBuilder;</span><br><span class="line">import org.springframework.context.annotation.Bean;</span><br><span class="line">import org.springframework.context.annotation.Configuration;</span><br><span class="line"></span><br><span class="line">/**</span><br><span class="line"> * 定义交换机</span><br><span class="line"> * 这里定义了所有类型的交换机（四种）</span><br><span class="line"> * 方便学习测试</span><br><span class="line"> * &lt;p&gt;</span><br><span class="line"> * durable  消息持久化</span><br><span class="line"> *</span><br><span class="line"> * @author : yh</span><br><span class="line"> * @date : 2021/9/9 20:38</span><br><span class="line"> */</span><br><span class="line">@Configuration</span><br><span class="line">public class ExchangeConfig &#123;</span><br><span class="line"></span><br><span class="line">    @Bean(&quot;myDirectExchange&quot;)</span><br><span class="line">    public Exchange myDirectExchange() &#123;</span><br><span class="line">        return ExchangeBuilder.directExchange(&quot;my-direct-exchange&quot;).durable(true).build();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    @Bean(&quot;myTopicExchange&quot;)</span><br><span class="line">    public Exchange myTopicExchange() &#123;</span><br><span class="line">        return ExchangeBuilder.topicExchange(&quot;my-topic-exchange&quot;).durable(true).build();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    @Bean(&quot;myFanoutExchange&quot;)</span><br><span class="line">    public Exchange myFanoutExchange() &#123;</span><br><span class="line">        return ExchangeBuilder.fanoutExchange(&quot;my-fanout-exchange&quot;).durable(true).build();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    @Bean(&quot;myHeadsExchange&quot;)</span><br><span class="line">    public Exchange myHeadersExchange() &#123;</span><br><span class="line">        return ExchangeBuilder.headersExchange(&quot;my-headers-exchange&quot;).durable(true).build();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="3-定义队列（Queue）"><a href="#3-定义队列（Queue）" class="headerlink" title="3.定义队列（Queue）"></a>3.定义队列（Queue）</h3>]]></content>
      <categories>
        <category>后端</category>
      </categories>
      <tags>
        <tag>实战</tag>
      </tags>
  </entry>
  <entry>
    <title>k3s实战</title>
    <url>/2022/05/22/k3s%E5%AE%9E%E6%88%98/</url>
    <content><![CDATA[<h2 id="k3s简介"><a href="#k3s简介" class="headerlink" title="k3s简介"></a>k3s简介</h2><p>K3s 是一个轻量级的 Kubernetes 发行版，它针对边缘计算、物联网等场景进行了高度优化。K3s 有以下增强功能：</p>
<ul>
<li>打包为单个二进制文件。</li>
<li>使用基于 sqlite3 的轻量级存储后端作为默认存储机制。同时支持使用 etcd3、MySQL 和 PostgreSQL 作为存储机制。</li>
<li>封装在简单的启动程序中，通过该启动程序处理很多复杂的 TLS 和选项。</li>
<li>默认情况下是安全的，对轻量级环境有合理的默认值。</li>
<li>添加了简单但功能强大的batteries-included功能，例如：本地存储提供程序，服务负载均衡器，Helm controller 和 Traefik Ingress controller。</li>
<li>所有 Kubernetes control-plane 组件的操作都封装在单个二进制文件和进程中，使 K3s 具有自动化和管理包括证书分发在内的复杂集群操作的能力。</li>
<li>最大程度减轻了外部依赖性，K3s 仅需要 kernel 和 cgroup 挂载。 K3s 软件包需要的依赖项包括：<ul>
<li>containerd</li>
<li>Flannel</li>
<li>CoreDNS</li>
<li>CNI</li>
<li>主机实用程序（iptables、socat 等）</li>
<li>Ingress controller（Traefik）</li>
<li>嵌入式服务负载均衡器（service load balancer）</li>
<li>嵌入式网络策略控制器（network policy controller）<h2 id="为什么叫k3s"><a href="#为什么叫k3s" class="headerlink" title="为什么叫k3s"></a>为什么叫k3s</h2>我们希望安装的 Kubernetes 在内存占用方面只是一半的大小。Kubernetes 是一个 10 个字母的单词，简写为 K8s。所以，有 Kubernetes 一半大的东西就是一个 5 个字母的单词，简写为 K3s。K3s 没有全称，也没有官方的发音。<h2 id="安装k3s"><a href="#安装k3s" class="headerlink" title="安装k3s"></a>安装k3s</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">curl -sfL https://rancher-mirror.rancher.cn/k3s/k3s-install.sh | INSTALL_K3S_MIRROR=cn sh -</span><br></pre></td></tr></table></figure>
运行此安装后：</li>
<li>K3s 服务将被配置为在节点重启后或进程崩溃或被杀死时自动重启。</li>
<li>将安装其他实用程序，包括kubectl、crictl、ctr、k3s-killall.sh 和 k3s-uninstall.sh。</li>
<li>将kubeconfig文件写入到&#x2F;etc&#x2F;rancher&#x2F;k3s&#x2F;k3s.yaml，由 K3s 安装的 kubectl 将自动使用该文件</li>
</ul>
</li>
</ul>
<p><strong>如果要部署集群，使用以下脚本部署：</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">curl -sfL https://rancher-mirror.rancher.cn/k3s/k3s-install.sh | INSTALL_K3S_MIRROR=cn K3S_URL=https://myserver:6443 K3S_TOKEN=mynodetoken sh -</span><br><span class="line"></span><br><span class="line">myserver -&gt; master节点的ip</span><br><span class="line">mynodetoken -&gt; cat /var/lib/rancher/k3s/server/node-token</span><br></pre></td></tr></table></figure>

<h3 id="查看版本"><a href="#查看版本" class="headerlink" title="查看版本"></a>查看版本</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">root@YH-UBUNTU:~# kubectl version --output=yaml</span><br><span class="line">clientVersion:</span><br><span class="line">  buildDate: &quot;2023-01-26T00:47:47Z&quot;</span><br><span class="line">  compiler: gc</span><br><span class="line">  gitCommit: 9176e03c5788e467420376d10a1da2b6de6ff31f</span><br><span class="line">  gitTreeState: clean</span><br><span class="line">  gitVersion: v1.25.6+k3s1</span><br><span class="line">  goVersion: go1.19.5</span><br><span class="line">  major: &quot;1&quot;</span><br><span class="line">  minor: &quot;25&quot;</span><br><span class="line">  platform: linux/amd64</span><br><span class="line">kustomizeVersion: v4.5.7</span><br><span class="line">serverVersion:</span><br><span class="line">  buildDate: &quot;2023-01-26T00:47:47Z&quot;</span><br><span class="line">  compiler: gc</span><br><span class="line">  gitCommit: 9176e03c5788e467420376d10a1da2b6de6ff31f</span><br><span class="line">  gitTreeState: clean</span><br><span class="line">  gitVersion: v1.25.6+k3s1</span><br><span class="line">  goVersion: go1.19.5</span><br><span class="line">  major: &quot;1&quot;</span><br><span class="line">  minor: &quot;25&quot;</span><br><span class="line">  platform: linux/amd64</span><br></pre></td></tr></table></figure>
<h3 id="禁用默认traefik"><a href="#禁用默认traefik" class="headerlink" title="禁用默认traefik"></a>禁用默认traefik</h3><h4 id="删除traefik"><a href="#删除traefik" class="headerlink" title="删除traefik"></a>删除traefik</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">kubectl -n kube-system delete helmcharts.helm.cattle.io traefik</span><br><span class="line">kubectl -n kube-system delete helmcharts.helm.cattle.io traefik-crd</span><br></pre></td></tr></table></figure>
<h4 id="关闭开机自动部署traefik"><a href="#关闭开机自动部署traefik" class="headerlink" title="关闭开机自动部署traefik"></a>关闭开机自动部署traefik</h4><ol>
<li>修改服务文件<code>sudo vim /etc/systemd/system/k3s.service</code>,将以下内容追加至ExecStart：<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">--disable traefik --disable traefik-crd</span><br></pre></td></tr></table></figure></li>
<li>清除部署文件中的traefik<br><code>sudo rm /var/lib/rancher/k3s/server/manifests/traefik.yaml</code></li>
<li>重启服务<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sudo systemctl daemon-reload</span><br><span class="line">sudo service k3s restart</span><br></pre></td></tr></table></figure></li>
</ol>
<h2 id="配置私有镜像仓库"><a href="#配置私有镜像仓库" class="headerlink" title="配置私有镜像仓库"></a>配置私有镜像仓库</h2><p>可以配置 Containerd 连接到私有镜像仓库，并使用它们在节点上拉取私有镜像。</p>
<hr>
<p>启动时，K3s 会检查&#x2F;etc&#x2F;rancher&#x2F;k3s&#x2F;中是否存在registries.yaml文件，并指示 containerd 使用文件中定义的镜像仓库。如果你想使用一个私有的镜像仓库，那么你需要在每个使用镜像仓库的节点上以 root 身份创建这个文件。</p>
<hr>
<p>配置registries.yaml（这里使用的是阿里云的镜像服务）</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">mirrors:</span><br><span class="line">  docker.io:</span><br><span class="line">    endpoint:</span><br><span class="line">      - &quot;registry.cn-hangzhou.aliyuncs.com&quot;</span><br><span class="line">configs:</span><br><span class="line">  &quot;registry.cn-hangzhou.aliyuncs.com&quot;:</span><br><span class="line">    auth:</span><br><span class="line">      username: # 这是私有镜像仓库的用户名</span><br><span class="line">      password: # 这是私有镜像仓库的密码</span><br><span class="line">    # 使用tls时需要配置</span><br><span class="line">    tls:</span><br><span class="line">      cert_file: # 镜像仓库中使用的cert文件的路径。</span><br><span class="line">      key_file:  # 镜像仓库中使用的key文件的路径。</span><br><span class="line">      ca_file:   # 镜像仓库中使用的ca文件的路径。</span><br></pre></td></tr></table></figure>
<h2 id="部署项目"><a href="#部署项目" class="headerlink" title="部署项目"></a>部署项目</h2><p><em><strong>本文介绍使用helm部署，所有部署文件已上传至GitHub，地址：<a href="https://github.com/yangh124/cicd">k3s-cicd</a></strong></em></p>
<h3 id="Helm安装"><a href="#Helm安装" class="headerlink" title="Helm安装"></a>Helm安装</h3><ol>
<li>下载所需版本【最新3.11.1】，地址：<a href="https://github.com/helm/helm/releases">Helm下载</a></li>
<li>安装<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 解压安装包</span><br><span class="line">tar -zxf helm-v3.11.1-linux-amd64.tar.gz</span><br><span class="line"># 移至bin目录</span><br><span class="line">mv linux-amd64/helm /usr/local/bin/helm</span><br><span class="line"># 安装完成，查看版本</span><br><span class="line">helm version</span><br></pre></td></tr></table></figure>
<h3 id="配置仓库"><a href="#配置仓库" class="headerlink" title="配置仓库"></a>配置仓库</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 用于安装mysql,redis</span><br><span class="line">helm repo add bitnami https://charts.bitnami.com/bitnami</span><br><span class="line">helm repo update</span><br></pre></td></tr></table></figure>
<h3 id="搜索chart"><a href="#搜索chart" class="headerlink" title="搜索chart"></a>搜索chart</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">helm search repo xxx</span><br></pre></td></tr></table></figure>
<h3 id="Helm使用"><a href="#Helm使用" class="headerlink" title="Helm使用"></a>Helm使用</h3></li>
<li>生成chart部署 <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@VM-16-2-centos ~/mydata/cicd]# helm create test-chart</span><br><span class="line">Creating test-chart</span><br><span class="line">[root@VM-16-2-centos ~/mydata/cicd]# tree test-chart/</span><br><span class="line">test-chart/</span><br><span class="line">├── charts</span><br><span class="line">├── Chart.yaml</span><br><span class="line">├── templates</span><br><span class="line">│   ├── deployment.yaml</span><br><span class="line">│   ├── _helpers.tpl</span><br><span class="line">│   ├── hpa.yaml</span><br><span class="line">│   ├── ingress.yaml</span><br><span class="line">│   ├── NOTES.txt</span><br><span class="line">│   ├── serviceaccount.yaml</span><br><span class="line">│   ├── service.yaml</span><br><span class="line">│   └── tests</span><br><span class="line">│       └── test-connection.yaml</span><br><span class="line">└── values.yaml</span><br><span class="line"></span><br><span class="line">3 directories, 10 files</span><br></pre></td></tr></table></figure></li>
<li>拉取仓库chart部署<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">helm pull bitnami/mysql</span><br></pre></td></tr></table></figure>
<strong>部署命令</strong><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 升级或安装</span><br><span class="line">helm upgrade --install [helm-name] [chart-name]</span><br></pre></td></tr></table></figure></li>
</ol>
<p><strong>TODO</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 给master节点打上标签 ingress=ture</span><br><span class="line">[root@k8s-master ingress-nginx]# kubectl label node master1 ingress=true</span><br><span class="line">node/master1 labeled</span><br><span class="line"></span><br><span class="line"># k8s默认集群中，出于安全考虑，默认配置下Kubernetes不会将Pod调度到Master节点。测试环境无所谓，所以执行下面命令去除master的污点：</span><br><span class="line">[root@k8s-master ingress-nginx]# kubectl taint node master1 node-role.kubernetes.io/master-</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>k3s</tag>
      </tags>
  </entry>
  <entry>
    <title>通过企业微信（微信插件）实现每日天气推送</title>
    <url>/2021/11/06/%E9%80%9A%E8%BF%87%E4%BC%81%E4%B8%9A%E5%BE%AE%E4%BF%A1%EF%BC%88%E5%BE%AE%E4%BF%A1%E6%8F%92%E4%BB%B6%EF%BC%89%E5%AE%9E%E7%8E%B0%E6%AF%8F%E6%97%A5%E5%A4%A9%E6%B0%94%E6%8E%A8%E9%80%81/</url>
    <content><![CDATA[<h2 id="企业微信配置"><a href="#企业微信配置" class="headerlink" title="企业微信配置"></a>企业微信配置</h2><h3 id="进入企业微信官网，点击立即注册"><a href="#进入企业微信官网，点击立即注册" class="headerlink" title="进入企业微信官网，点击立即注册"></a>进入<a href="https://work.weixin.qq.com/">企业微信官网</a>，点击立即注册</h3><p><img src="https://yh-blog-files.oss-cn-hangzhou.aliyuncs.com/2021/11/06/16361632863091.jpg" alt="16361632863091"><br><img src="https://yh-blog-files.oss-cn-hangzhou.aliyuncs.com/2021/11/06/16361633233327.jpg" alt="16361633233327"></p>
<h3 id="登录企业微信管理后台，找到应用管理，点击创建自建应用（例如这里我创建了一个名称为天气推送的应用）"><a href="#登录企业微信管理后台，找到应用管理，点击创建自建应用（例如这里我创建了一个名称为天气推送的应用）" class="headerlink" title="登录企业微信管理后台，找到应用管理，点击创建自建应用（例如这里我创建了一个名称为天气推送的应用）"></a>登录企业微信管理后台，找到应用管理，点击创建自建应用（例如这里我创建了一个名称为天气推送的应用）</h3><p><img src="https://yh-blog-files.oss-cn-hangzhou.aliyuncs.com/2021/11/06/16361635628391.jpg" alt="16361635628391"></p>
<h3 id="点击打开创建的应用，获取开发相关的配置信息（AgentId-Secret）"><a href="#点击打开创建的应用，获取开发相关的配置信息（AgentId-Secret）" class="headerlink" title="点击打开创建的应用，获取开发相关的配置信息（AgentId,Secret）"></a>点击打开创建的应用，获取开发相关的配置信息（AgentId,Secret）</h3><p><img src="https://yh-blog-files.oss-cn-hangzhou.aliyuncs.com/2021/11/06/16361637536484.jpg" alt="16361637536484"><br> AgentId：这个应用的唯一标识<br> Secret：密钥（需要发送到企业微信app才能查看）</p>
<h3 id="到此所有企业微信配置结束"><a href="#到此所有企业微信配置结束" class="headerlink" title="到此所有企业微信配置结束"></a>到此所有企业微信配置结束</h3><h2 id="天气开放平台配置"><a href="#天气开放平台配置" class="headerlink" title="天气开放平台配置"></a>天气开放平台配置</h2><h3 id="进入和风天气开放平台，点击注册"><a href="#进入和风天气开放平台，点击注册" class="headerlink" title="进入和风天气开放平台，点击注册"></a>进入<a href="https://dev.qweather.com/">和风天气开放平台</a>，点击注册</h3><p> <em><strong>注册完成后建议申请认证个人开发者</strong></em>（支持更多接口）<br><img src="https://yh-blog-files.oss-cn-hangzhou.aliyuncs.com/2021/11/06/16361640883550.jpg" alt="16361640883550"></p>
<h3 id="登录控制台，点击应用管理，创建应用，获取到应用的KEY"><a href="#登录控制台，点击应用管理，创建应用，获取到应用的KEY" class="headerlink" title="登录控制台，点击应用管理，创建应用，获取到应用的KEY"></a>登录控制台，点击应用管理，创建应用，获取到应用的KEY</h3><p><img src="https://yh-blog-files.oss-cn-hangzhou.aliyuncs.com/2021/11/06/16361644923902.jpg" alt="16361644923902"></p>
<h2 id="项目开发"><a href="#项目开发" class="headerlink" title="项目开发"></a>项目开发</h2><p>前端项目：<a href="https://github.com/yangh124/weather-push-admin">weather-push-admin</a><br>后台项目：<a href="https://github.com/yangh124/weather-push">weather-push</a></p>
<h2 id="定时任务配置配置"><a href="#定时任务配置配置" class="headerlink" title="定时任务配置配置"></a>定时任务配置配置</h2><h3 id="执行执行初始化sql"><a href="#执行执行初始化sql" class="headerlink" title="执行执行初始化sql"></a>执行执行初始化sql</h3><p>在后台项目resources&#x2F;sql&#x2F;init.sql</p>
<h3 id="运行前后端项目"><a href="#运行前后端项目" class="headerlink" title="运行前后端项目"></a>运行前后端项目</h3><p><img src="https://yh-blog-files.oss-cn-hangzhou.aliyuncs.com/2022/06/25/16561503716829.jpg" alt="16561503716829"></p>
<p><img src="https://yh-blog-files.oss-cn-hangzhou.aliyuncs.com/2022/06/25/16561503961795.jpg" alt="16561503961795"></p>
<h3 id="登录后台"><a href="#登录后台" class="headerlink" title="登录后台"></a>登录后台</h3><p>使用默认账号密码登录：admin 123456<br><img src="https://yh-blog-files.oss-cn-hangzhou.aliyuncs.com/2022/06/25/16561505074675.jpg" alt="16561505074675"></p>
<h3 id="配置地区"><a href="#配置地区" class="headerlink" title="配置地区"></a>配置地区</h3><p>即配置需要发送天气预报的地区<br><strong>注：这里的地区对应企业微信通讯录中的标签</strong></p>
<blockquote>
<p>地区管理 -&gt; 添加<br><img src="https://yh-blog-files.oss-cn-hangzhou.aliyuncs.com/2022/06/25/16561506595631.jpg" alt="16561506595631"></p>
</blockquote>
<h3 id="地区绑定成员"><a href="#地区绑定成员" class="headerlink" title="地区绑定成员"></a>地区绑定成员</h3><blockquote>
<p>成员管理 -&gt; 选择左边的地区 -&gt; 点击添加成员<br><strong>注：这里的成员对应企业微信通讯录中的成员</strong><br><img src="https://yh-blog-files.oss-cn-hangzhou.aliyuncs.com/2022/06/25/16561508273991.jpg" alt="16561508273991"></p>
</blockquote>
<h3 id="创建定时任务"><a href="#创建定时任务" class="headerlink" title="创建定时任务"></a>创建定时任务</h3><p><img src="https://yh-blog-files.oss-cn-hangzhou.aliyuncs.com/2022/06/25/16561517473902.jpg" alt="16561517473902"></p>
<h2 id="最终效果"><a href="#最终效果" class="headerlink" title="最终效果"></a>最终效果</h2><p><img src="https://yh-blog-files.oss-cn-hangzhou.aliyuncs.com/2022/06/25/16561520350860.jpg" alt="16561520350860"></p>
]]></content>
      <categories>
        <category>项目</category>
      </categories>
      <tags>
        <tag>实战</tag>
      </tags>
  </entry>
  <entry>
    <title>数据结构和算法</title>
    <url>/2021/04/24/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E5%92%8C%E7%AE%97%E6%B3%95/</url>
    <content><![CDATA[<h1 id="线性结构和非线性结构"><a href="#线性结构和非线性结构" class="headerlink" title="线性结构和非线性结构"></a>线性结构和非线性结构</h1><pre><code>数据结构包括：线性结构和非线性结构
</code></pre>
<span id="more"></span>
<h2 id="线性结构"><a href="#线性结构" class="headerlink" title="线性结构"></a>线性结构</h2><ul>
<li><pre><code>线性结构作为最常用的数据结构，其特点是数据元素之间存在一对一的线性关系
</code></pre>
</li>
<li><pre><code>线性结构有两种不同的存储结构，即顺序存储结构和链式存储结构。
</code></pre>
</li>
<li><pre><code>顺序存储结构的线性表称为顺序表，顺序表中的存储元素是连续的。
</code></pre>
</li>
<li><pre><code>链式存储结构的线性表称为链表，链表中的存储结构不一定是连续的，元素结点中存放数据元素以及相邻元素的地址信息。
</code></pre>
</li>
<li><pre><code>线性结构常见的有：数组、队列、链表和栈。
</code></pre>
</li>
</ul>
<h2 id="非线性结构"><a href="#非线性结构" class="headerlink" title="非线性结构"></a>非线性结构</h2><pre><code>非线性结构包括：二维数组，多维数组，广义表，树结构，图结构
</code></pre>
<hr>
<p><em>代码实现:  <a href="https://github.com/yangh124/DataStructures">https://github.com/yangh124/DataStructures</a></em></p>
<h1 id="线性结构-1"><a href="#线性结构-1" class="headerlink" title="线性结构"></a>线性结构</h1><h2 id="稀疏数组和队列"><a href="#稀疏数组和队列" class="headerlink" title="稀疏数组和队列"></a>稀疏数组和队列</h2><h3 id="稀疏数组"><a href="#稀疏数组" class="headerlink" title="稀疏数组"></a>稀疏数组</h3><pre><code>当一个数组大部分元素为0，或者为同一个值的数值时，可以使用稀疏数组来保存该数组。
</code></pre>
<p><img src="https://yh-blog-files.oss-cn-hangzhou.aliyuncs.com/2021/04/25/1.png" alt="1"><br><strong>稀疏数组的处理方法是：</strong></p>
<ol>
<li>第一行记录数组一共几行几列，有多少个不同的值</li>
<li>把具有不同值的元素的行列及值记录在一个小规模数组中，从而缩小程序的规模<br><img src="https://yh-blog-files.oss-cn-hangzhou.aliyuncs.com/2021/04/25/2.png" alt="2"></li>
</ol>
<p><strong>二维数组–&gt;稀疏数组思路</strong></p>
<ol>
<li>遍历原始数组，得到数组中有效数据的个数sum</li>
<li>根据sum就可以创建稀疏数组 sparseArr &#x3D; int[sum+1] [3]</li>
<li>将原始的二维数组中的有效数据存入到稀疏数组</li>
</ol>
<p><strong>稀疏数组–&gt;原始的二维数组的思路</strong></p>
<ol>
<li>先读取稀疏数组的第一行，根据第一行的数据，创建原始二维数组，比如上面的 chessArr2 &#x3D; int [11] [11]</li>
<li>在读取稀疏数组后几行的数据，并赋给原始二维数组即可</li>
</ol>
<h3 id="队列"><a href="#队列" class="headerlink" title="队列"></a>队列</h3><ul>
<li>队列是一个有序列表，可以用数组或是链表来实现</li>
<li>遵循<strong>先入先出</strong>的原则，即：先存入队列的数据，要先取出。后存入的队列要后取出</li>
</ul>
<ol>
<li><p>数组模拟队列</p>
<ol>
<li>队列本身是有序列表，若使用数组的结构来存储队列的数据，则队列数组声明如下图，其中maxSize是该队列的最大容量。</li>
<li>因为队列的输出、输入是分别从前后端来处理的，因此需要两个变量front和rear分别记录队列前后端的下标，front会随着数据输出而改变，而rear则是随着数据输入而改变，如图所示：<br> <img src="https://yh-blog-files.oss-cn-hangzhou.aliyuncs.com/2021/04/25/3.png" alt="3"><br>问题分析及优化：</li>
</ol>
</li>
<li><p>目前数组使用一次就不能用，没有达到复用的效果</p>
</li>
<li><p>将这个数组使用算法，改进为一个环形数组（取模 %）</p>
<p> 思路如下：</p>
<ol>
<li>front变量的含义做一个调整：front就指向队列的第一个元素，也就是说arr[front]就是队列的第一个元素 front的初始值&#x3D;0</li>
<li>rear变量的含义做一个调整：rear指向队列的最后一个元素的后一个位置。因为希望空出一个空间作为约定 rear的初始值&#x3D;0</li>
<li>当队列满时，条件为(rear+1)%maxSize&#x3D;&#x3D;front [满]</li>
<li>当队列为空时，条件为 rear&#x3D;front</li>
<li>队列的有效数据的个数 (rear+maxSize-front)%maxSize  &#x2F;&#x2F;rear&#x3D;1 front&#x3D;0</li>
<li>这就是一个环形队列</li>
</ol>
</li>
</ol>
<h3 id="链表（Linked-List）"><a href="#链表（Linked-List）" class="headerlink" title="链表（Linked  List）"></a>链表（Linked  List）</h3><p><strong>链表是有序的列表</strong></p>
<ul>
<li><p>单向链表</p>
<ol>
<li>链表是以结点的方式来存储的，是链式存储</li>
<li>每个结点包含data域，next域（指向下一个结点）</li>
<li>如图：发现链表的各个结点不一定是连续存储的<br><img src="https://yh-blog-files.oss-cn-hangzhou.aliyuncs.com/2021/04/25/4.png" alt="4"><img src="https://yh-blog-files.oss-cn-hangzhou.aliyuncs.com/2021/04/25/5.png" alt="5"></li>
</ol>
</li>
<li><p>双向链表</p>
</li>
<li><p>环形链表：约瑟夫环(Josephus)，如图<br><img src="https://yh-blog-files.oss-cn-hangzhou.aliyuncs.com/2021/04/25/6.png" alt="6"></p>
</li>
</ul>
<h3 id="栈（Stack）"><a href="#栈（Stack）" class="headerlink" title="栈（Stack）"></a>栈（Stack）</h3><ol>
<li>栈是一种<strong>先入后出</strong>的(FILO)的有序列表</li>
<li>栈是限制线性表中元素的插入和删除<strong>只能在线性表的同一端</strong>进行的一种特殊线性表。允许插入和删除的一端，为变化的一端，称为<strong>栈顶</strong>，另一端为固定的一端，称为<strong>栈底</strong>。</li>
<li>根据栈的定义可知，最先放入栈中的元素在栈底，最后放入的元素在栈顶，而删除元素正好相反，最后放入的元素先删除，最先放入的元素最后删除。</li>
<li>出栈（pop）、入栈（push）的概念，如图所示<br><img src="https://yh-blog-files.oss-cn-hangzhou.aliyuncs.com/2021/04/25/7.png" alt="7"></li>
</ol>
<p><strong>栈的应用场景</strong></p>
<ol>
<li>子程序的调用：在跳往子程序前，会先将下个指令的地址存到堆栈中，直到子程序执行完成再将地址取出，已回到原来的程序中。</li>
<li>处理递归调用：和子程序的调用类似，只是除了存储下一个指令的地址外，也将参数、局部变量等数据存入堆栈中。</li>
<li>表达式的转换（中缀表达式转后缀表达式）与求值（实际解决）。</li>
<li>二叉树的遍历。</li>
<li>图形的深度优先搜索算法（depth-first）<br><strong>使用栈完成计算一个表达式的结果：3 + 2 <code>*</code> 6 - 2&#x3D;?</strong><br><img src="https://yh-blog-files.oss-cn-hangzhou.aliyuncs.com/2021/04/25/8.png" alt="8"></li>
</ol>
<p>实现思路：</p>
<ol>
<li>通过一个index值（索引），来遍历我们的表达式</li>
<li>如果我们发现是一个数字，就直接入数栈</li>
<li>如果发现是一个运算符：<ol>
<li>如果当前符号栈为空，就直接入符号栈</li>
<li>如果符号栈中已存在符号，就和栈顶的符号进行比较，<strong>如果当前的操作符的优先级小于或等于栈顶的运算符</strong>，就需要从数栈中pop出俩数，从符号栈中pop出一个运算符，进行运算，将结果push入数栈，然后将当前运算符push入运算符栈；如果<strong>当前的操作符的优先级大于栈顶的运算符</strong>，就直接将运算符push入运算符栈。</li>
<li>当表达式扫描完后，就顺序的从数栈和运算符栈中pop出数据进行运算并将计算结果push入数栈，最终在数栈中的值就是计算的结果</li>
</ol>
</li>
</ol>
<p><strong>前缀、中缀、后缀表达式（逆波兰表达式）</strong><br>     <strong>前缀表达式</strong></p>
<pre><code>1. 前缀表达式又称波兰式，前缀表达式的运算符位于操作数之前
2. 前缀表达式的计算机求值
</code></pre>
<p>(3+4)*5-6 前缀表达式就是 - <code>*</code> + 3 4 5 6</p>
<p>从右至左扫描表达式，遇到数字时，将数字压入栈，遇到运算符时，弹出栈顶的两个数，用运算符对它们进行相应的计算（栈顶元素和次栈顶元素），并将结果入栈；重复上述过程直到表达式最左端，最后运算得出的值即为表达式的结果</p>
<p>例如：(3+4)*5-6 的对应的前缀表达式是 - <code>*</code> + 3 4 5 6，计算的过程步骤如下：</p>
<pre><code>1. 从右至左扫描，将6、5、4、3压入栈
2. 遇到+运算符，因此弹出3和4，计算得7，再将7入栈
3. 接下来是`*`运算，因此弹出7和5，计算的35，再将35入栈
4. 最后为-运算符，计算35-6，得29，由此得到最终结果 
</code></pre>
<p><strong>中缀表达式</strong></p>
<pre><code>中缀表达式就是常见的运算表达式，如(3+4)`*`5-6
中缀表达式的求值是我们人最熟悉的，但对计算机来说却不好操作，因此，在计算结果时，往往会将中缀表达式转成其它表达式操作（一般转成后缀表达式）
</code></pre>
<p><strong>后缀表达式</strong></p>
<pre><code>1. 后缀表达式又称为逆波兰表达式，与前缀表达式相似，只是运算符位于操作数之后
2. 举例说明：(3+4)*5-6对应的后缀表达式就是 3 4 + 5 `*` 6 -
</code></pre>
<p><img src="https://yh-blog-files.oss-cn-hangzhou.aliyuncs.com/2021/04/25/9.png" alt="9"></p>
<p><strong>后缀表达式的计算机求值</strong></p>
<p><strong>从左至右</strong>扫描表达式，遇到数字时，将数字压入堆栈，遇到运算符时，弹出栈顶的两个数，运算符对它们做相应的计算（次顶元素和栈顶元素），并将结果入栈。重复上述过程直到表达式最右端，最后运算得出的值即为表达式的结果</p>
<p>例如：(3+4)<code>*</code>5-1. 例如：(3+4)<code>*</code>5-6对应的后缀表达式就是3 4 + 5 <code>*</code> 6 -，针对后缀表达式的步骤如下：</p>
<pre><code>1. 从左至右扫描，将3和4压入栈
2. 遇到+运算符，因此弹出4和3（4为栈顶元素，3为次顶元素），计算出3+4的值，得7，再将7入栈
3. 将5入栈
4. 接下来是*运算符，因此弹出5和7，计算出7*5=35，将35入栈
5. 将6入栈
6. 最后是-运算符，计算出35-6的值，即29，由此得出最终结果
</code></pre>
<p><strong>中缀表达式转后缀表达式</strong><br><code>1 + ( ( 2+3 ) * 4) - 5</code><br>  <img src="https://yh-blog-files.oss-cn-hangzhou.aliyuncs.com/2021/04/25/10.png" alt="10"></p>
<p>思路：</p>
<ol>
<li>初始化两个栈：运算符栈s1和存储中间结果结果的栈s2</li>
<li>从左至右扫描中缀表达式</li>
<li>遇到操作数时，将其压入s2</li>
<li>遇到运算符时，比较其与s1栈顶运算符优先级<ol>
<li>如果s1为空，或栈顶运算符为”(“，则直接将此运算符入栈</li>
<li>否则，若优先级比栈顶运算符高，也将运算符压入s1</li>
<li>否则，将s1栈顶的运算符弹出并压入到s2中，再次转到(d-i)与s1中新的栈顶运算符相比较（相当于调换俩运算符位置）</li>
</ol>
</li>
<li>遇到括号时：<ol>
<li>如果是左括号”(“，则直接压入s1</li>
<li>如果是右括号”)”，则依次弹出s1栈顶的运算符，并压入s2，直到遇到左括号为止，此时将这一对括号丢弃</li>
</ol>
</li>
<li>重复步骤b-e，直到表达式的最右边</li>
<li>将s1中剩余的运算符依次弹出并压入s2</li>
<li>依次弹出s2中的元素并输出，结果的逆序即为中缀表达式的后缀表达式</li>
</ol>
<h2 id="递归"><a href="#递归" class="headerlink" title="递归"></a>递归</h2><ul>
<li>递归的应用场景<br>看个实际应用场景，迷宫问题（回溯），递归（Recursion）</li>
</ul>
<p><img src="https://yh-blog-files.oss-cn-hangzhou.aliyuncs.com/2021/04/25/11.png" alt="11"></p>
<ul>
<li>递归能解决什么问题</li>
</ul>
<ol>
<li>各种数学问题如：8皇后问题(在一个8x8的国际象棋上摆8个皇后，使它们不能相互攻击，即：任意两个皇后不能处于同一行、同一列或同一斜线，求多少种摆法（92种）)，汉诺塔，阶乘问题，迷宫问题，球和篮子的问题（Google编程大赛）</li>
<li>各种算法中也会使用到递归，比如快排，归并排序，二分查找，分治算法等</li>
<li>将用栈解决的问题-&gt;递归代码比较简洁</li>
</ol>
<ul>
<li><p>递归的概念<br>  简单的说：递归就是方法自己调用自己，每次调用时传入不同的变量，递归有助于编程者解决复杂的问题，同时可以让代码变得简洁。<br><img src="https://yh-blog-files.oss-cn-hangzhou.aliyuncs.com/2021/04/25/12.png" alt="12"></p>
</li>
<li><p>递归需要遵守的规则</p>
</li>
</ul>
<ol>
<li>执行一个方法时，就创建一个新的受保护的独立空间（栈空间）</li>
<li>方法的局部变量是独立的，不会相互影响，比如n变量</li>
<li>如果方法中使用的是引用类型变量（比如数组），就会共享该引用类型的数据</li>
<li>递归必须向退出递归的条件逼近，否则就是无限递归，出现StackOverflowError</li>
<li>当一个方法执行完毕，或者遇到return，就会返回，遵守谁调用，就将结果返回给谁，同时当方法执行完毕或者返回时，该方法也就执行完毕</li>
</ol>
<ul>
<li>递归-八皇后问题<br>  八皇后问题算法思路分析<br>  1. 第一个皇后先放第一行第一列。<br>  2. 第二个皇后放在第二行第一列、然后判断是否ok，如果不ok，继续放在第二列、第三列…，依次把所有列都放完，找到一个合适的位置。<br>  3. 继续第三个皇后，还是第一列、第二列、第三列…，直到第8个皇后也能放在一个不冲突的位置。<br>  4. 当放完所有皇后时，得到一个正确解，在栈回退到上一个栈时，就会开始回溯，即将第一个皇后放到第一行第一列的所有正确解全部得到。<br>  5. 然后把第一个皇后放在第一行第二列，重复1、2、3、4步骤<br>  <strong>说明：</strong><br>  * 理论上应该创建一个二维数组来表示棋盘，但是实际上可以通过算法，用一个一维数组即可解决问题，arr[8] &#x3D; {0,4,7,5,2,6,1,3}。<br>  * 对应arr下标表示第几行和即第几个皇后，arr[i] &#x3D; val，val表示第i+1个皇后，放在第i+1行的第val+1列</li>
</ul>
<h2 id="排序算法"><a href="#排序算法" class="headerlink" title="排序算法"></a>排序算法</h2><p><strong>介绍：</strong><br>    排序也称排序算法，排序是将一组数据，按指定的顺序进行排列的过程。</p>
<p><strong>排序的分类：</strong></p>
<ul>
<li>内部排序：将需要处理的所有数据都加载到内存中进行排序。</li>
<li>外部排序：数据量过大时，无法全部加载到内存中，需要借助于外部存储进行排序。</li>
</ul>
<p><strong>常见排序算法：</strong></p>
<ol>
<li>内部排序（使用内存）<ol>
<li>插入排序<ol>
<li>直接插入排序</li>
<li>希尔排序</li>
</ol>
</li>
</ol>
</li>
<li>选择排序<ol>
<li>简单选择排序</li>
<li>堆排序</li>
</ol>
</li>
<li>交换排序<ol>
<li>冒泡排序</li>
<li>快速排序</li>
</ol>
</li>
<li>归并排序</li>
<li>基数排序</li>
<li>外部排序（使用内存和外存结合）</li>
</ol>
<p><strong>算法的时间复杂度</strong><br>时间频度：<br><strong>一个算法花费的时间与算法中语句的执行次数成正比，那个算法中语句执行次数多，它话费时间就多。一个算法中的语句执行次数称为语句频度或者时间频度。记为T(n)。</strong></p>
<ul>
<li>忽略常数项</li>
<li>忽略低次项</li>
<li>忽略系数<br><img src="https://yh-blog-files.oss-cn-hangzhou.aliyuncs.com/2021/04/25/13.png" alt="13"><br><img src="https://yh-blog-files.oss-cn-hangzhou.aliyuncs.com/2021/04/25/14.png" alt="14"><br><img src="https://yh-blog-files.oss-cn-hangzhou.aliyuncs.com/2021/04/25/15.png" alt="15"><br><img src="https://yh-blog-files.oss-cn-hangzhou.aliyuncs.com/2021/04/25/16.png" alt="16"></li>
</ul>
<p><strong>时间复杂度：</strong></p>
<ol>
<li>一般情况下，算法中的基本操作语句的重复执行次数是问题规模n的某个函数，用T(n)表示，若有某个辅助函数f(n)，使得当n趋近于无穷大时，T(n)&#x2F;f(n)的极限值为不等于零的常数，则称f(n)是T(n)的同数量级函数。记作T(n)&#x3D;O(f(n))，称O(f(n))为算法的渐进时间复杂度，简称时间复杂度</li>
<li>T(n)不同，但是时间复杂度可能相同。如T(n)&#x3D;n²+7n+6与T(n)&#x3D;3n²+2n+2它们的T(n)不同，但是时间复杂度相同，都为O(n²)</li>
<li>计算时间复杂度的方法：</li>
</ol>
<ul>
<li>用常数1代替运行时间中的所有加法常数  T(n)&#x3D;3n²+2n+2  &#x3D;&gt;  T(n)&#x3D;3n²+2n+1</li>
<li>函数只保留最高阶项 				    T(n)&#x3D;3n²+2n+1  &#x3D;&gt;  T(n)&#x3D;3n²</li>
<li>去除最高阶项的系数				    T(n)&#x3D;3n²  &#x3D;&gt;  T(n)&#x3D;n²  &#x3D;&gt;  O(n²)</li>
</ul>
<p><strong>常见的时间复杂度：</strong></p>
<ul>
<li>常数阶O(1)</li>
<li>对数阶O(log n)</li>
<li>线性阶O(n)</li>
<li>线性对数阶O(n log n)</li>
<li>平方阶O(n²)</li>
<li>立方阶O(n³)</li>
<li>k次方阶O(n^k)</li>
<li>指数阶O(2^n)<br><img src="https://yh-blog-files.oss-cn-hangzhou.aliyuncs.com/2021/04/25/17.png" alt="17"></li>
</ul>
<p><strong>说明：</strong><br>    常见的算法时间复杂度由小到大依次为：O(1)&lt;O(log n)&lt;O(n)&lt;O(n log n)&lt;O(n²)&lt;O(n³)&lt;O(n^k)&lt;(2^n)，随着问题规模n不断增大，时间复杂度不断增大，算法的执行效率不断降低</p>
<h3 id="冒泡排序"><a href="#冒泡排序" class="headerlink" title="冒泡排序"></a>冒泡排序</h3><p>冒泡排序（Bubble Sorting）的基本思想是：通过对待排序序列从前向后（从下标较小的元素开始），依次比较相邻元素的值，若发现逆序则交换位置，使值较大的元素逐渐从前移向后部，就想水底的气泡一样逐渐上冒。</p>
<p><strong>因为排序的过程中，各元素不断接近自己的位置，如果一趟比较下来没有进行过交换，就说明序列有序，因此要在排序过程中设置一个标志flag判断元素是否进行过交换。从而减少不必要的比较。</strong></p>
<p>原始数组：[9，3，-1，10，20]<br>第一趟排序</p>
<ul>
<li>3，9，-1，10，20	&#x2F;&#x2F;如果相邻的元素逆序就交换</li>
<li>3，-1，9，10，20</li>
<li>3，-1，9，10，20</li>
<li>3，-1，9，10，<em>20</em><br>第二趟排序</li>
<li>-1，3，9，10，<em>20</em></li>
<li>-1，3，9，10，<em>20</em></li>
<li>-1，3，9，<em>10</em>，<em>20</em><br>第三趟排序</li>
<li>-1，3，9，<em>10</em>，<em>20</em></li>
<li>-1，3，<em>9</em>，<em>10</em>，<em>20</em><br>第四趟排序</li>
<li>-1，<em>3</em>，<em>9</em>，<em>10</em>，<em>20</em></li>
</ul>
<p><strong>小结：</strong></p>
<ol>
<li>一共进行数组大小减一次的循环</li>
<li>每一趟排序的次数在主键减小</li>
<li>如果发现在某一趟排序中，没有发生一次交换，可以提前结束，排序完成</li>
</ol>
<h3 id="选择排序"><a href="#选择排序" class="headerlink" title="选择排序"></a>选择排序</h3><pre><code>选择排序（Select Sorting）的思想：第一次从array[0]~array[n-1]中选取最小值，与array[0]交换，第二次从array[1]~array[n-1]中选取最小值，与array[1]交换，第三次从array[2]~array[n-1]中选取最小值，与array[2]交换，......，第n-1次从array[n-2]~array[n-1]中选取最小值，与array[n-2]交换，总共通过n-1次，最终得到一个有序序列。
</code></pre>
<p><img src="https://yh-blog-files.oss-cn-hangzhou.aliyuncs.com/2021/04/25/18.png" alt="18"></p>
<p>原始数组：[101，34，119，1]<br>第一轮排序：<em>1</em>，34，119，101<br>第二轮排序：<em>1</em>，<em>34</em>，119，101<br>第三轮排序：<em>1</em>，<em>34</em>，<em>101</em>，119</p>
<p><strong>说明：</strong></p>
<ol>
<li>一共进行数组大小减一次的循环</li>
<li>每一轮排序，又是一个循环，循环规则（见代码）</li>
</ol>
<ul>
<li><pre><code>先假定当前数为最小数
</code></pre>
</li>
<li><pre><code>然后依次和后面的数进行比较，如果发现有比当前数更小的数，就重新确定最小数，并得到下标
</code></pre>
</li>
<li><pre><code>直到遍历结束，就得到本轮的最小数和下标
</code></pre>
</li>
<li><pre><code>交换（见代码）
</code></pre>
</li>
</ul>
<h3 id="插入排序"><a href="#插入排序" class="headerlink" title="插入排序"></a>插入排序</h3><pre><code>插入排序属于内部排序法，是对于欲排序的元素以插入的方式找寻该元素的适当位置，以达到排序的目的。
插入排序（Insertion Sorting）的基本思想：把n个待排序的元素看成为一个有序表和一个无序表，开始时有序表只包含一个元素，无序表包含n-1个元素，排序过程中每次从无序表中取出第一个元素，把它的排序码依次与有序表元素的排序码进行比较，将它插入到有序表中的适当位置，使之成为新的有序表。
</code></pre>
<p><img src="https://yh-blog-files.oss-cn-hangzhou.aliyuncs.com/2021/04/25/19.png" alt="19"></p>
<h3 id="希尔排序"><a href="#希尔排序" class="headerlink" title="希尔排序"></a>希尔排序</h3><p>介绍：<br>    希尔排序是希尔（Donald Shell）于1959年提出的一种排序算法。希尔排序也是一种插入排序，它是简单的插入排序经过改进之后的一个更高效的版本，也称为缩小增量排序<br>基本思想：<br>    希尔排序是把记录按下标的一定增量分组，对每组使用直接插入排序算法的排序；随着增量逐渐减少，每组包含的关键词越来越多，当增量减至1时，整个文件恰被分成一组，算法便中止<br><img src="https://yh-blog-files.oss-cn-hangzhou.aliyuncs.com/2021/04/25/20.png" alt="20"><br>经过上面的”宏观调控“，整个数组已经基本有序。<br>此时，仅仅需要对以上数组简单微调，即可排序完成。</p>
<h3 id="快速排序"><a href="#快速排序" class="headerlink" title="快速排序"></a>快速排序</h3><pre><code>快速排序（quick sort）是对冒泡排序的一种改进。
</code></pre>
<p><strong>基本思想是：</strong><br>    通过一趟排序将要排序的的数据分割成独立的两部分，其中一部分的所有数据都比另外一部分的所有数据都小，然后再按此方法对两部分数据分别进行快速排序，整个排序过程可以递归进行，以此达到整个数据变成有序序列<br><img src="https://yh-blog-files.oss-cn-hangzhou.aliyuncs.com/2021/04/25/jie-tu.png" alt="21"></p>
<h3 id="归并排序"><a href="#归并排序" class="headerlink" title="归并排序"></a>归并排序</h3><p>介绍：<br>    归并排序(merge-sort)是利用<strong>归并</strong>的思想实现的排序方法，该算法采用经典的<strong>分治</strong>(divide-and-conquer)策略(分治法将问题分(divide)成一些小的问题然后递归求解，而治(conquer)的阶段则将分的阶段得到的各答案“修补”在一起，即分而治之)。<br><img src="https://yh-blog-files.oss-cn-hangzhou.aliyuncs.com/2021/05/06/16203055843782.jpg"><br><img src="https://yh-blog-files.oss-cn-hangzhou.aliyuncs.com/2021/05/06/16203060638697.jpg"></p>
<h3 id="基数排序"><a href="#基数排序" class="headerlink" title="基数排序"></a>基数排序</h3><p>基数排序（桶排序）介绍：</p>
<ol>
<li>基数排序（radix sort）属于“分配式排序”（distribution sort），又称为“桶子法”（bucket sort）或bin sort，顾名思义，它是通过键值的各个位的值，将要排序的元素分配至某些“桶”中，达到排序的作用。</li>
<li>基数排序法是属于稳定性的排序，基数排序法是效率高的稳定性排序法。</li>
<li>基数排序是桶排序的扩展。</li>
<li>基数排序是1887年赫尔曼.何乐礼发明的。他是这样实现的：将整数按位数切割成不同数字，然后按每个位数分别比较。</li>
</ol>
<p>基本思想：</p>
<pre><code>将所有待比较数值统一为同样的数位长度，数位较短的数前面补零。然后，从低位开始，依次进行排序。这样从最低位排序一直到最高位排序完成以后，数列就变成一个有序序列。
</code></pre>
<p><img src="https://yh-blog-files.oss-cn-hangzhou.aliyuncs.com/2021/05/10/16206526234760.jpg"><br><img src="https://yh-blog-files.oss-cn-hangzhou.aliyuncs.com/2021/05/10/16206526525823.jpg"><br>基数排序的说明</p>
<ol>
<li>基数排序是对传统排序的扩展，速度很快</li>
<li>基数排序是经典的空间换时间的方式，占用内存很大，当对海量数据进行排序时，容易造成OOM</li>
<li>基数排序是稳定的。（注：假定在待排序的记录序列中，存在多个具有相同关键字的记录，若经过排序，这些记录的相对序列保持不变，则称这种排序算法是稳定的，否则称为不稳定）</li>
</ol>
<h3 id="常用排序算法总结与对比"><a href="#常用排序算法总结与对比" class="headerlink" title="常用排序算法总结与对比"></a>常用排序算法总结与对比</h3><p><img src="https://yh-blog-files.oss-cn-hangzhou.aliyuncs.com/2021/05/12/16208263189347.jpg"></p>
<h2 id="查找算法"><a href="#查找算法" class="headerlink" title="查找算法"></a>查找算法</h2><p>查找算法介绍：<br>    在Java中，我们常用的查找有四种：<br>    1. 顺序（线性）查找<br>    2. 二分查找&#x2F;折半查找<br>    3. 插值查找<br>    4. 斐波那契查找</p>
<h3 id="线性查找"><a href="#线性查找" class="headerlink" title="线性查找"></a>线性查找</h3><p>可以是无序数列<br>for循环查找…..</p>
<h3 id="二分查找"><a href="#二分查找" class="headerlink" title="二分查找"></a>二分查找</h3><p>必须是有序数列  {1,8,89,1000,1234}<br>二分查找的思路分析</p>
<ol>
<li>首先确定该数组的中间下标    mid&#x3D;(left+right)&#x2F;2</li>
<li>然后让需要查找的数findVal和arr[mid]比较<ol>
<li>findVal&gt;arr[mid]，说明要查找的数在mid的右边，因此需要递归向右查找</li>
<li>findVal&lt;arr[mid]，说明要查找的数在mid的左边，因此需要递归向左查找</li>
<li>findVal&#x3D;&#x3D;arr[mid]说明找到，返回</li>
</ol>
</li>
</ol>
<p>什么时候结束退出递归呢？</p>
<ul>
<li>找到结束递归</li>
<li>递归完整个数组，仍然没有找到，也需要退出递归，当left&gt;right退出</li>
</ul>
<h3 id="插值查找"><a href="#插值查找" class="headerlink" title="插值查找"></a>插值查找</h3><p>介绍：</p>
<ol>
<li>插值查找算法类似于二分查找，不同的是插值查找每次从<strong>自适应mid处</strong>开始查找。</li>
<li>将折半查找中的求mid索引的公式进行修改，low表示左边下标left，high表示右边下标right，a为有序数组，key为要查找的元素。<br> <img src="https://yh-blog-files.oss-cn-hangzhou.aliyuncs.com/2021/05/15/16210487159358.jpg"></li>
<li>此时mid就称为插值索引。</li>
<li>插值查找算法的举例说明：<br> <img src="https://yh-blog-files.oss-cn-hangzhou.aliyuncs.com/2021/05/15/16210493519244.jpg"><br>注意：<ul>
<li>对于数据量较大，关键字分布不均匀的查找表来说，采用插值查找速度较快。</li>
<li>关键字分布不均匀的情况下，该方法不一定比二分查找要好</li>
</ul>
</li>
</ol>
<h3 id="斐波那契（黄金分割法）查找算法"><a href="#斐波那契（黄金分割法）查找算法" class="headerlink" title="斐波那契（黄金分割法）查找算法"></a>斐波那契（黄金分割法）查找算法</h3><p>原理：<br>    斐波那契查找原理与前两种相似，仅仅改变了中间结点(mid )的位置，mid不再是中间或者插值得到，而是位于黄金分割点附近，即mid&#x3D;low+F(k-1)-1（F代表斐波那契数列），如下图所示：<br><img src="https://yh-blog-files.oss-cn-hangzhou.aliyuncs.com/2021/05/15/16210528253673.jpg"><br>对F(k-1)-1的理解</p>
<ol>
<li>有斐波那契数列F[k]&#x3D;F[k-1]+F[K-2]的性质，可以得到 <strong>F[k]-1&#x3D;(F[k-1]-1)+(F(k-2)-1)+1</strong><br> 该式说明：只要顺序表的长度为<strong>F[k]-1</strong>，则可以将该表分成长度为F[k-1]-1和F[k-2]-1的两段，即如上图所示。从而得出mid&#x3D;low+F(k-1)-1</li>
<li>类似的，每一个字段也可以用相同的方式分割。</li>
<li>但顺序表的长度n不一定刚好等于F[k]-1，所以需要将原来的顺序表长度n增加至F[k]-1。这里k值只要使得F[k]-1恰好大于或等于n即可，有以下代码得到，顺序表长度增加后，新增的位置（从n-1到F[K]-1位置），都赋为n位置即可。</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">while(n &gt; fib(k)-1)</span><br><span class="line">    k++;</span><br></pre></td></tr></table></figure>

<h2 id="哈希表"><a href="#哈希表" class="headerlink" title="哈希表"></a>哈希表</h2><p>介绍：<br>    散列表（Hash table，也叫哈希表），是根据关键码值（key value）而直接进行访问的数据结构。也就是说，它通过把关键码值映射到表中的一个位置来访问记录，以加快查找的速度。这个映射函数叫做散列函数，存放记录的数组叫做散列表。<br><img src="https://yh-blog-files.oss-cn-hangzhou.aliyuncs.com/2021/05/16/16211523688516.jpg"><br><img src="https://yh-blog-files.oss-cn-hangzhou.aliyuncs.com/2021/05/16/16211535095885.jpg"></p>
<h2 id="树结构"><a href="#树结构" class="headerlink" title="树结构"></a>树结构</h2><p>为什么需要树这种数据结构？</p>
<ol>
<li>数组存储方式分析<ul>
<li>优点：通过下标方式访问元素，速度快。对于有序数组，还可以使用二分查找提高检索效率。</li>
<li>缺点：如果要检索某个具体值，或者插入新值会整体移动，效率较低</li>
</ul>
</li>
<li>链式存储方式分析<ul>
<li>优点：在一定程度上对数组方式有优化（比如：插入一个数值结点，只需要将插入结点，链接到链表中即可，删除效率也很好）。</li>
<li>缺点：在进行检索时，效率仍然较低（需要从头结点开始遍历）</li>
</ul>
</li>
<li>树存储方式分析<br> 能够提高数据存储，读取效率，比如利用二叉排序树（binary sort tree），既可以保证数据的检索速度，同时也可以保证数据的插入，删除，修改的数据。</li>
</ol>
<h3 id="二叉树"><a href="#二叉树" class="headerlink" title="二叉树"></a>二叉树</h3><p><img src="https://yh-blog-files.oss-cn-hangzhou.aliyuncs.com/2021/05/19/16214290521689.jpg"></p>
<h4 id="二叉树的概念"><a href="#二叉树的概念" class="headerlink" title="二叉树的概念"></a>二叉树的概念</h4><ol>
<li>树有很多种，每个结点最多只能有两个子结点的一种形式称为二叉树。</li>
<li>二叉树的子结点分为左结点和右结点。<br><img src="https://yh-blog-files.oss-cn-hangzhou.aliyuncs.com/2021/05/19/16214293221251.jpg"></li>
<li>如果该二叉树的所有叶子结点都在最后一层，并且结点总数&#x3D;2^n-1，n为层数，则我们称为满二叉树。</li>
<li>如果该二叉树的所有叶子结点都在最后一层或者倒数第二层，而且最后一层的叶子结点在左边连续，倒数第二层的结点在右边连续，我们称为完全二叉树。<br><img src="https://yh-blog-files.oss-cn-hangzhou.aliyuncs.com/2021/05/19/16214297839734.jpg"></li>
</ol>
<h4 id="二叉树遍历"><a href="#二叉树遍历" class="headerlink" title="二叉树遍历"></a>二叉树遍历</h4><p>使用前序，中序和后序进行遍历。</p>
<ul>
<li>前序遍历：<strong>先输出父结点</strong>，再遍历左子树和右子树。</li>
<li>中序遍历：先遍历左子树，<strong>再输出父结点</strong>，再遍历右子树。</li>
<li>后序遍历：先遍历左子树，再遍历右子树，<strong>最后输出父结点</strong>。</li>
</ul>
<p>小结：看输出父结点的顺序，就确定是前序，中序还是后序了。</p>
<p>遍历步骤：</p>
<ol>
<li>创建一颗二叉树</li>
<li>前序遍历<ol>
<li>先输出当前结点（root结点）</li>
<li>如果左子结点不为空，则递归继续前序遍历</li>
<li>如果右子结点不为空，则递归继续前序遍历</li>
</ol>
</li>
<li>中序遍历<ol>
<li>如果当前结点的左子结点不为空，则递归中序遍历</li>
<li>输出当前结点</li>
<li>如果当前结点右子结点不为空，则递归中序遍历</li>
</ol>
</li>
<li>后序遍历<ol>
<li>如果当前结点的左子结点不为空，则递归后序遍历</li>
<li>如果当前结点右子结点不为空，则递归后序遍历 </li>
<li>输出当前结点</li>
</ol>
</li>
</ol>
<h4 id="二叉树删除结点"><a href="#二叉树删除结点" class="headerlink" title="二叉树删除结点"></a>二叉树删除结点</h4><p>规定：</p>
<ol>
<li>如果删除的结点是叶子结点，则删除该结点</li>
<li>如果删除的结点是非叶子结点，则删除该子树</li>
</ol>
<p>思路:</p>
<ol>
<li>因为二叉树是单向的，所以我们是判断当前结点的子结点是否需要删除，而不是直接判断当前结点是否需要删除。</li>
<li>如果当前结点的左子结点不为空，并且左子结点为要删除的结点，就将this.left&#x3D;null;并且返回（结束递归）。</li>
<li>如果当前结点的右子结点不为空，并且右子结点为要删除的结点，就将this.right&#x3D;null;并且返回（结束递归）。</li>
<li>如果第2步和第3步没有删除结点，那么就需要向左子树进行递归删除。</li>
<li>如果第4步没有删除结点，则应该向右子树进行递归删除。</li>
<li>考虑树是空树，如果只有一个root结点，则等价将二叉树置空</li>
</ol>
<h4 id="顺序存储二叉树"><a href="#顺序存储二叉树" class="headerlink" title="顺序存储二叉树"></a>顺序存储二叉树</h4><p>顺序储存二叉树概念</p>
<p>基本说明：<br>    从数据储存来看，数组存储方式和树的存储方式可以相互转换，即数组可以转换成树，树也可以转换成数组，如图所示。<br><img src="https://yh-blog-files.oss-cn-hangzhou.aliyuncs.com/2021/05/31/16224667732317.jpg"><br>要求：</p>
<ol>
<li>图中的二叉树的结点，要求以数组的方式来存放 arr&#x3D;[1,2,3,4,5,6,7]</li>
<li>要求遍历数组时，仍然可以以前序遍历、中序遍历和后序遍历的方式完成结点遍历</li>
</ol>
<p><strong>顺序存储二叉树的特点：</strong></p>
<pre><code>1. 顺序二叉树通常只考虑完全二叉树
2. 第n个元素的左子结点为2*n+1
3. 第n个元素的右子结点为2*n+2
4. 第n个元素的父结点为(n-1)/2
5. n:表示二叉树的第几个元素（按0开始编号），如上图所示
</code></pre>
<h4 id="线索化二叉树"><a href="#线索化二叉树" class="headerlink" title="线索化二叉树"></a>线索化二叉树</h4><p><img src="https://yh-blog-files.oss-cn-hangzhou.aliyuncs.com/2021/06/01/16225509191510.jpg"><br><strong>中序遍历结果应该为{8,3,10,1,14,6}</strong><br>线索化二叉树基本介绍：</p>
<pre><code>1. n个结点的二叉链表中含有n+1(公式:2n-(n-1)=n+1)个空指针域。利用二叉链表中的空指针域，存放指向该结点在某种遍历次序下的前驱和后继结点的指针（这种附加指针称为“线索”）。
2. 这种加上了线索的二叉链表称为线索链表，相应的二叉树称为线索二叉树（Threaded BinaryTree）。根据线索性质的不同，线索二叉树可分为前序线索二叉树、中序线索二叉树和后序线索二叉树三种。
3. 一个结点的前一个结点，称为前驱结点。
4. 一个结点的后一个结点，称为后继结点。
</code></pre>
<p><img src="https://yh-blog-files.oss-cn-hangzhou.aliyuncs.com/2021/06/01/16225524548765.jpg"><br><strong>说明：当线索化二叉树后，结点的属性left和right，有如下情况：</strong><br>    1. left指向的是左子树，也可能是指向的前驱结点。比如1结点left指向的左子树，而10结点的left指向的是前驱结点。<br>    2. right指向的是右子树，也可能是指向后继结点，比如1结点的right指向的是右子树，而10结点的right指向的是后继结点。</p>
<h3 id="树结构的实际应用"><a href="#树结构的实际应用" class="headerlink" title="树结构的实际应用"></a>树结构的实际应用</h3><h4 id="堆排序"><a href="#堆排序" class="headerlink" title="堆排序"></a>堆排序</h4><p>堆排序基本介绍</p>
<ol>
<li>堆排序是利用堆这种数据结构而设计的一种排序算法，堆排序是一种选择排序，它的最好最坏平均时间复杂度都为O(nlogn)，它是不稳定排序。</li>
<li>堆是具有以下性质的完全二叉树：每个结点的值都大于或等于其左右孩子结点的值，称为大顶堆，注意：没有要求结点的左右孩子结点的值的大小关系。</li>
<li>每个结点的 值都小于或等于其左右孩子结点的值，称为小顶堆。</li>
<li>大顶堆举例说明<br> <img src="https://yh-blog-files.oss-cn-hangzhou.aliyuncs.com/2021/06/06/16229482774304.jpg"></li>
<li>小顶堆举例说明<br><img src="https://yh-blog-files.oss-cn-hangzhou.aliyuncs.com/2021/06/06/16229484938865.jpg"></li>
<li>一般升序采用大顶堆，降序采用小顶堆</li>
</ol>
<p>堆排序基本思想</p>
<pre><code>1. 将待排序数列构造成一个大顶堆。
2. 此时，真个序列的最大值就是堆顶的根结点。
3. 将其与末尾元素进行交换，此时末尾就是最大值。
4. 然后将剩余n-1个元素重新构造成一个堆，这样会得到n个元素的次小值。如此反复执行，便能得到一个有序序列了。
</code></pre>
<p>步骤：</p>
<ul>
<li>步骤一：构造初始堆。将给定的无需序列构造成一个大定堆（一般升序用大顶堆。降序用小顶堆）。<br>  原始数组：[4,6,8,5,9]<ol>
<li>假设给定无序序列结构如下<br> <img src="https://yh-blog-files.oss-cn-hangzhou.aliyuncs.com/2021/06/06/16229495441333.jpg"></li>
<li>此时我们从最后一个非叶子结点开始（第一个非叶子结点arr.length&#x2F;2-1&#x3D;5&#x2F;2-1&#x3D;1，也就是6），从左至右，从上至下进行调整。<br>  <img src="https://yh-blog-files.oss-cn-hangzhou.aliyuncs.com/2021/06/06/16229498353433.jpg"></li>
<li>找到下一个非叶子结点4，由于4，9，8中9最大，4和9交换<br>  <img src="https://yh-blog-files.oss-cn-hangzhou.aliyuncs.com/2021/06/06/16229502630483.jpg"></li>
<li>这时，交换导致了子树4，5，6结构混乱，继续调整，4，5，6中6最大，交换4和6.<br>  <img src="https://yh-blog-files.oss-cn-hangzhou.aliyuncs.com/2021/06/06/16229504070770.jpg"><br>  此时，我们就将一个无序序列构造成一个大顶堆。</li>
</ol>
</li>
<li>步骤二：将堆顶元素与末尾元素进行交换，使末尾元素最大。然后继续调整堆，再将堆顶元素与末尾元素交换，得到第二大元素。如此反复进行交换、重建、交换。<ol>
<li>将堆顶元素9和末尾元素4进行交换<br>  <img src="https://yh-blog-files.oss-cn-hangzhou.aliyuncs.com/2021/06/06/16229527328129.jpg"></li>
<li>重新调整结构，使其满足堆定义<br>  <img src="https://yh-blog-files.oss-cn-hangzhou.aliyuncs.com/2021/06/06/16229528080292.jpg"></li>
<li>再将堆顶元素8与末尾元素5进行交换，得到第二大元素8<br>  <img src="https://yh-blog-files.oss-cn-hangzhou.aliyuncs.com/2021/06/06/16229528997349.jpg"></li>
<li>后续过程，继续进行调整，交换，反复进行，最终使整个序列有序<br>  <img src="https://yh-blog-files.oss-cn-hangzhou.aliyuncs.com/2021/06/06/16229530006244.jpg"><br>总结：</li>
<li>将无需序列构建成一个堆，根据升序或者降序选择大顶堆或小顶堆。</li>
<li>将堆顶元素与末尾元素交换，将最大（小）元素“沉”到数组末端。</li>
<li>重新调整结构，使其满足堆定义，然后继续交换堆顶元素与当前末尾元素，反复执行调整交换，直到整个序列有序。<br><img src="https://yh-blog-files.oss-cn-hangzhou.aliyuncs.com/2021/06/10/16233341037899.jpg"></li>
</ol>
</li>
</ul>
<h4 id="赫夫曼树"><a href="#赫夫曼树" class="headerlink" title="赫夫曼树"></a>赫夫曼树</h4><p>基本介绍</p>
<ol>
<li>给定n个权值作为n个叶子结点，构造一棵二叉树，若该树的带权路径长度（WPL）达到最小，称这样的二叉树为最优二叉树，也称为赫夫曼树（Huffman Tree）,还有的书翻译为霍夫曼树。</li>
<li>赫夫曼树是带权路径长度最短的树，权值较大的结点离根较近。结点</li>
</ol>
<p>赫夫曼树几个重要概念和举例说明</p>
<ol>
<li><strong>路径和路径长度</strong>：在一棵树中，从一个结点往下可以达到的孩子或孙子结点之间的通路，称为路径。通路中分支的数目称为路径长度。若规定根结点的层数为1，则从根结点到第L层结点的路径长度为L-1。</li>
<li><strong>结点的权及带权路径长度</strong>：若将树中结点赋予一个有着某种意义的数值，则这个数值称为该结点的权。结点的带权路径长度为：从根结点到该结点之间的路径长度为该结点的权的乘积。</li>
<li><strong>树的带权路径长度</strong>：树的带权路径长度规定为所有<strong>叶子结点</strong>的带权路径长度之和。记为WPL（weighted path length），权值越大的结点离根结点越近的二叉树才是最优二叉树。</li>
<li><strong>WPL最小的就是赫夫曼树。</strong><br><img src="https://yh-blog-files.oss-cn-hangzhou.aliyuncs.com/2021/06/20/16241642468630.jpg"></li>
</ol>
]]></content>
      <categories>
        <category>基础</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>算法</tag>
      </tags>
  </entry>
  <entry>
    <title>索引的创建与设计原则</title>
    <url>/2022/01/15/%E7%B4%A2%E5%BC%95%E7%9A%84%E5%88%9B%E5%BB%BA%E4%B8%8E%E8%AE%BE%E8%AE%A1%E5%8E%9F%E5%88%99/</url>
    <content><![CDATA[<h2 id="索引的声明与使用"><a href="#索引的声明与使用" class="headerlink" title="索引的声明与使用"></a>索引的声明与使用</h2><h3 id="索引的分类"><a href="#索引的分类" class="headerlink" title="索引的分类"></a>索引的分类</h3><ul>
<li>从<strong>功能逻辑</strong>上说，索引主要有四种，分别为普通索引、唯一索引、主键索引、全文索引。</li>
<li>按照<strong>物理实现方式</strong>，索引可以分为两种：聚簇索引和非聚簇索引。</li>
<li>按照<strong>作用字段个数</strong>进行划分，分成单列索引和联合索引。<h2 id="MySQL8-0索引新特性"><a href="#MySQL8-0索引新特性" class="headerlink" title="MySQL8.0索引新特性"></a>MySQL8.0索引新特性</h2><h3 id="支持降序索引"><a href="#支持降序索引" class="headerlink" title="支持降序索引"></a>支持降序索引</h3>降序索引以降序存储键值。虽然在语法上，从MySQL4版本开始就支持降序索引语法了。但实际上该DESC定义是被忽略的，直到MySQL8才开始真正支持降序索引（仅限于InnoDB存储引擎）。<br>MySQL在8.0之前创建仍然是升序索引，使用时进行反向扫描，这大大降低了数据库的效率。<br><code> CREATE TABLE ts1(a int,b int,index idx_a_b(a ASC,b DESC))</code><h3 id="隐藏索引"><a href="#隐藏索引" class="headerlink" title="隐藏索引"></a>隐藏索引</h3><code> ALTER TABLE tablename ALTER INDEX index_name INVISIBLE; #隐藏索引</code><br><code> ALTER TABLE tablename ALTER INDEX index_name VISIBLE; #显示索引</code><br><strong>隐藏显示索引可用与查看使用索引的效率提升</strong><h2 id="索引的设计原则"><a href="#索引的设计原则" class="headerlink" title="索引的设计原则"></a>索引的设计原则</h2><h3 id="数据准备"><a href="#数据准备" class="headerlink" title="数据准备"></a>数据准备</h3>创建表<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 课程表</span><br><span class="line">CREATE TABLE `course` (</span><br><span class="line">  `id` int NOT NULL AUTO_INCREMENT,</span><br><span class="line">  `course_id` int NOT NULL,</span><br><span class="line">  `course_name` varchar(50) COLLATE utf8mb4_unicode_ci DEFAULT NULL,</span><br><span class="line">  PRIMARY KEY (`id`)</span><br><span class="line">) ENGINE=InnoDB AUTO_INCREMENT=101 DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci;</span><br><span class="line"></span><br><span class="line"># 学生表</span><br><span class="line">CREATE TABLE `student_info` (</span><br><span class="line">  `id` int NOT NULL AUTO_INCREMENT,</span><br><span class="line">  `student_id` int NOT NULL,</span><br><span class="line">  `name` varchar(50) COLLATE utf8mb4_unicode_ci DEFAULT NULL,</span><br><span class="line">  `course_id` int NOT NULL,</span><br><span class="line">  `class_id` int DEFAULT NULL,</span><br><span class="line">  `create_time` datetime DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,</span><br><span class="line">  PRIMARY KEY (`id`)</span><br><span class="line">) ENGINE=InnoDB AUTO_INCREMENT=1000001 DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci;</span><br></pre></td></tr></table></figure>
生成随机数函数<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 生成随机数函数</span><br><span class="line">CREATE DEFINER=`root`@`%` FUNCTION `rand_num`( from_num INT,to_num INT) RETURNS int</span><br><span class="line">BEGIN</span><br><span class="line">	DECLARE</span><br><span class="line">		i INT DEFAULT 0;</span><br><span class="line">	SET i = FLOOR(from_num+RAND()*(to_num-from_num +1));</span><br><span class="line">	RETURN i;</span><br><span class="line">END</span><br></pre></td></tr></table></figure>
生成随机字符串函数<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">## 生成随机字符串</span><br><span class="line">CREATE DEFINER=`root`@`%` FUNCTION `rand_string`(n INT) RETURNS varchar(255) CHARSET utf8mb4 COLLATE utf8mb4_unicode_ci</span><br><span class="line">BEGIN</span><br><span class="line">    DECLARE chars_str varchar(100) DEFAULT &#x27;abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789&#x27;;</span><br><span class="line">    DECLARE return_str varchar(255) DEFAULT &#x27;&#x27;;</span><br><span class="line">    DECLARE i INT DEFAULT 0;</span><br><span class="line">    WHILE i &lt; n DO</span><br><span class="line">        SET return_str = concat(return_str,substring(chars_str , FLOOR(1 + RAND()*62 ),1));</span><br><span class="line">        SET i = i +1;</span><br><span class="line">    END WHILE;</span><br><span class="line">    RETURN return_str;</span><br><span class="line">END</span><br></pre></td></tr></table></figure>
生成课程表数据储存过程<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 生成课程表数据储存过程</span><br><span class="line">CREATE DEFINER=`root`@`%` PROCEDURE `insert_course`( max_num INT )</span><br><span class="line">BEGIN</span><br><span class="line">	DECLARE</span><br><span class="line">		i INT DEFAULT 0;</span><br><span class="line">	</span><br><span class="line">	SET autocommit = 0;</span><br><span class="line">	REPEAT</span><br><span class="line">			</span><br><span class="line">			SET i = i + 1;</span><br><span class="line">		INSERT INTO course ( course_id, course_name )</span><br><span class="line">		VALUES</span><br><span class="line">			(</span><br><span class="line">				rand_num ( 10000, 10100 ),</span><br><span class="line">			rand_string ( 6 ));</span><br><span class="line">		UNTIL i = max_num </span><br><span class="line">	END REPEAT;</span><br><span class="line">	COMMIT;</span><br><span class="line">	</span><br><span class="line">END</span><br></pre></td></tr></table></figure>
生成学生表数据存储过程<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 生成学生表存储过程</span><br><span class="line">CREATE DEFINER=`root`@`%` PROCEDURE `insert_stu`( max_num INT )</span><br><span class="line">BEGIN</span><br><span class="line">	DECLARE</span><br><span class="line">		i INT DEFAULT 0;</span><br><span class="line">	</span><br><span class="line">	SET autocommit = 0;</span><br><span class="line">	REPEAT</span><br><span class="line">			</span><br><span class="line">			SET i = i + 1;</span><br><span class="line">		INSERT INTO student_info ( course_id, class_id,student_id,name ) VALUES(</span><br><span class="line">		rand_num(10000,10100),rand_num(10000,10200),rand_num(10000,20000),rand_string(6)</span><br><span class="line">		);</span><br><span class="line">		UNTIL i = max_num </span><br><span class="line">	END REPEAT;</span><br><span class="line">	COMMIT;</span><br><span class="line">	</span><br><span class="line">END</span><br></pre></td></tr></table></figure>
调用存储过程<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">CALL insert_stu(1000000);</span><br><span class="line">CALL insert_course(100);</span><br></pre></td></tr></table></figure>
<h3 id="哪些情况适合创建索引"><a href="#哪些情况适合创建索引" class="headerlink" title="哪些情况适合创建索引"></a>哪些情况适合创建索引</h3></li>
</ul>
<ol>
<li>字段的数值有唯一性限制：<blockquote>
<p>业务上具有唯一特性的字段，即使是组合字段，也必须创建组合索引（来源：Alibaba）</p>
</blockquote>
</li>
<li>频繁作为where查询条件的字段</li>
<li>经常 group by 和 order by 的字段</li>
<li>update、delete的where条件</li>
<li>distinct字段需要创建索引</li>
<li>多表join连接操作时，创建索引的注意事项<blockquote>
<p>连接表尽量不超过3张；对where条件创建索引，并且该字段在多张表中的类型必须一致（隐式转换（使用了函数，索引失效））；</p>
</blockquote>
</li>
<li>使用列的类型小的创建索引</li>
<li>使用字符串前缀创建索引</li>
<li>区分度高（散列性高）的列适合创建索引</li>
<li>使用最频繁的列放到联合索引的左侧</li>
<li>在多个列都要创建索引时，联合索引优于单值索引</li>
</ol>
<h3 id="哪些情况不适合创建索引"><a href="#哪些情况不适合创建索引" class="headerlink" title="哪些情况不适合创建索引"></a>哪些情况不适合创建索引</h3><ol>
<li>在where中使用不到的字段不要创建索引</li>
<li>数据量小的表最好不要创建索引</li>
<li>有大量重复数据的列不要建立索引</li>
<li>避免对经常更新的表创建过多的索引</li>
<li>不建议用无序的值作为索引</li>
<li>删除不再使用的或者很少使用的索引</li>
<li>不要定义冗余或重复的索引<h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2>索引是一把双刃剑，可以提高查询效率，但是也会降低插入和更新的速度并占用磁盘空间。</li>
</ol>
]]></content>
      <categories>
        <category>后端</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
</search>
